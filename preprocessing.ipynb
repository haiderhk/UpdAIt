{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a List containing links of all articles (Including featured article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from utils import get_website_html\n",
    "from scraper import get_featured_article_link, get_articles_links, get_article_titles, get_formatted_article_text\n",
    "\n",
    "BASE_URL = \"https://www.deeplearning.ai\"\n",
    "THE_BATCH_URL = \"https://www.deeplearning.ai/the-batch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_page_html = get_website_html(THE_BATCH_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid article link (It is probably a featured article)...continuing\n",
      "0 --> https://www.deeplearning.ai/the-batch/issue-280/\n",
      "1 --> https://www.deeplearning.ai/the-batch/issue-279/\n",
      "2 --> https://www.deeplearning.ai/the-batch/issue-278/\n",
      "3 --> https://www.deeplearning.ai/the-batch/issue-277/\n",
      "4 --> https://www.deeplearning.ai/the-batch/issue-276/\n",
      "5 --> https://www.deeplearning.ai/the-batch/issue-275/\n",
      "6 --> https://www.deeplearning.ai/the-batch/issue-274/\n",
      "7 --> https://www.deeplearning.ai/the-batch/issue-273/\n",
      "8 --> https://www.deeplearning.ai/the-batch/issue-272/\n",
      "9 --> https://www.deeplearning.ai/the-batch/issue-271/\n",
      "10 --> https://www.deeplearning.ai/the-batch/issue-270/\n",
      "11 --> https://www.deeplearning.ai/the-batch/issue-269/\n",
      "12 --> https://www.deeplearning.ai/the-batch/issue-268/\n",
      "13 --> https://www.deeplearning.ai/the-batch/issue-267/\n",
      "14 --> https://www.deeplearning.ai/the-batch/issue-266/\n"
     ]
    }
   ],
   "source": [
    "unfeatured_articles_links = get_articles_links(home_page_html)\n",
    "\n",
    "for index, link in enumerate(unfeatured_articles_links):\n",
    "    print(f\"{index} --> {link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.deeplearning.ai/the-batch/issue-281/\n"
     ]
    }
   ],
   "source": [
    "featured_article_link = get_featured_article_link(home_page_html)\n",
    "print(featured_article_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles:  16\n",
      "0 --> https://www.deeplearning.ai/the-batch/issue-281/\n",
      "1 --> https://www.deeplearning.ai/the-batch/issue-280/\n",
      "2 --> https://www.deeplearning.ai/the-batch/issue-279/\n",
      "3 --> https://www.deeplearning.ai/the-batch/issue-278/\n",
      "4 --> https://www.deeplearning.ai/the-batch/issue-277/\n",
      "5 --> https://www.deeplearning.ai/the-batch/issue-276/\n",
      "6 --> https://www.deeplearning.ai/the-batch/issue-275/\n",
      "7 --> https://www.deeplearning.ai/the-batch/issue-274/\n",
      "8 --> https://www.deeplearning.ai/the-batch/issue-273/\n",
      "9 --> https://www.deeplearning.ai/the-batch/issue-272/\n",
      "10 --> https://www.deeplearning.ai/the-batch/issue-271/\n",
      "11 --> https://www.deeplearning.ai/the-batch/issue-270/\n",
      "12 --> https://www.deeplearning.ai/the-batch/issue-269/\n",
      "13 --> https://www.deeplearning.ai/the-batch/issue-268/\n",
      "14 --> https://www.deeplearning.ai/the-batch/issue-267/\n",
      "15 --> https://www.deeplearning.ai/the-batch/issue-266/\n"
     ]
    }
   ],
   "source": [
    "all_articles_links = [featured_article_link] + unfeatured_articles_links\n",
    "print(\"Total number of articles: \", len(all_articles_links))\n",
    "for i, article in enumerate(all_articles_links):\n",
    "    print(f\"{i} --> {article}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list containing the titles of all articles.\n",
    "#### The order will be the same as the links in all_articles_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total titles: 16\n",
      "0 --> Top AI Stories of 2024! Agents Rise, Prices Fall, Models Shrink, Video Takes Off, Acquisitions Morph\n",
      "1 --> Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, Gemini 2.0 Flash Accelerates Multimodal Modeling, LLMs Propose Research Ideas\n",
      "2 --> Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs\n",
      "3 --> AI Agents Spend Real Money, Breaking Jailbreaks, Mistral Goes Big and Multimodal, AI’s Growing E-Waste Problem\n",
      "4 --> DeepSeek Takes On OpenAI, Robots Fold Laundry, Amazon and Anthropic Expand Partnership, More Efficient Object Detection\n",
      "5 --> Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, Transformer Training Streamlined\n",
      "6 --> Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot\n",
      "7 --> AI Controls Desktops, Agents Train Algorithms, Does Anyone Comply With the EU’s AI Act?, Robots on the Loading Dock\n",
      "8 --> Trick or treat! AI Devours Energy, Innovation Can’t Win, Models Collapse, Benchmark Tests Are Meaningless, No Work for Coders\n",
      "9 --> AI Giants Go Nuclear, A Tech Bromance Turns Turbulent, Mistral Sharpens the Edge, Cheaper Video Generation\n",
      "10 --> Bogus Apps, AI Boomtown, Better Embeddings, 2024 Highlights\n",
      "11 --> How Meta’s Movie Gen Does It, AI’s Criminal Underground, Court Says LAION is Legal, OpenAI’s New Voice API\n",
      "12 --> Llama Goes Multimodal, Pros Embrace Generative Video, Military AI Guidelines, LLMs That Read Spreadsheets\n",
      "13 --> Hollywood Embraces Video Gen, New Restrictions on Deepfakes, More Open Source Models, Robot Server\n",
      "14 --> Models Built for Reasoning, High Gear for Llama 3.1, Brains for Warehouse Robots, Stopping LLMs From Plagiarizing\n",
      "15 --> Nations Sign Binding AI Treaty, Waymo Reveals Safety Record, 2D to 3D Goes Mainstream, Balancing Web Data Distributions\n"
     ]
    }
   ],
   "source": [
    "all_articles_titles = get_article_titles(home_page_html)\n",
    "print(f\"Total titles: {len(all_articles_titles)}\")\n",
    "for i, title in enumerate(all_articles_titles):\n",
    "    print(f\"{i} --> {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Chunks of each Article (Docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing each article's text in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-281/\n",
      "Saved: formatted_articles/article_0_the-batch_issue-281.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-280/\n",
      "Saved: formatted_articles/article_1_the-batch_issue-280.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-279/\n",
      "Saved: formatted_articles/article_2_the-batch_issue-279.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-278/\n",
      "Saved: formatted_articles/article_3_the-batch_issue-278.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-277/\n",
      "Saved: formatted_articles/article_4_the-batch_issue-277.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-276/\n",
      "Saved: formatted_articles/article_5_the-batch_issue-276.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-275/\n",
      "Saved: formatted_articles/article_6_the-batch_issue-275.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-274/\n",
      "Saved: formatted_articles/article_7_the-batch_issue-274.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-273/\n",
      "Saved: formatted_articles/article_8_the-batch_issue-273.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-272/\n",
      "Saved: formatted_articles/article_9_the-batch_issue-272.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-271/\n",
      "Saved: formatted_articles/article_10_the-batch_issue-271.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-270/\n",
      "Saved: formatted_articles/article_11_the-batch_issue-270.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-269/\n",
      "Saved: formatted_articles/article_12_the-batch_issue-269.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-268/\n",
      "Saved: formatted_articles/article_13_the-batch_issue-268.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-267/\n",
      "Saved: formatted_articles/article_14_the-batch_issue-267.txt\n",
      "Fetching article text with link:  https://www.deeplearning.ai/the-batch/issue-266/\n",
      "Saved: formatted_articles/article_15_the-batch_issue-266.txt\n"
     ]
    }
   ],
   "source": [
    "def save_all_articles_text(all_articles_links):\n",
    "    for index, link in enumerate(all_articles_links):\n",
    "        article_text = get_formatted_article_text(link)\n",
    "        slug = re.sub(r'https?://[^/]+/', '', link)  # remove scheme and domain\n",
    "        slug = slug.strip(\"/\").replace(\"/\", \"_\")     # turn '/the-batch/issue-281/' -> 'the-batch_issue-281'\n",
    "        file_name = f\"article_{index}_{slug}.txt\"\n",
    "        file_path = os.path.join(\"formatted_articles\", file_name)\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(article_text)\n",
    "            print(f\"Saved: {file_path}\\n\")\n",
    "        time.sleep(1) # Delay to not overwhelm the server :)\n",
    "        \n",
    "\n",
    "save_all_articles_text(all_articles_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the article into Chunks using MarkdownTextSplitter and Saving to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-3-small\")\n",
    "\n",
    "vector_store = Chroma(collection_name=\"articles_collection\", embedding_function=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'parse_article_index' from 'utils' (/Users/haider/Local/Portfolio_Projects/UpdAIt/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_article_chunks, parse_article_index, create_metadata\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformatted_articles\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# print(\"Skipping: \", filename)\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'parse_article_index' from 'utils' (/Users/haider/Local/Portfolio_Projects/UpdAIt/utils.py)"
     ]
    }
   ],
   "source": [
    "from utils import get_article_chunks, parse_article_index, create_metadata\n",
    "\n",
    "for filename in os.listdir(\"formatted_articles\"):\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        # print(\"Skipping: \", filename)\n",
    "        continue\n",
    "    print(filename)\n",
    "    filepath = os.path.join(\"formatted_articles\", filename)\n",
    "    with open(filepath, \"r\") as myfile:\n",
    "        print(myfile.name)\n",
    "        article_text = myfile.read()\n",
    "        docs = get_article_chunks(article_text)\n",
    "        article_index = parse_article_index(myfile.name)\n",
    "        print(article_index)\n",
    "        print(f\"Length of docs of article with index {article_index} = {len(docs)}\")\n",
    "        metadatas, ids = create_metadata(docs, article_index)\n",
    "        print(ids)\n",
    "    vector_store.add_texts(texts=docs, ids=ids, metadatas=metadatas)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* ## Innovation Can’t Win\n",
      "Politicians and pundits have conjured visions of doom to convince lawmakers to clamp down on AI. What if terrified legislators choke off innovation in AI?\n",
      "The fear: Laws and treaties that purportedly were intended to prevent harms wrought by AI are making developing new models legally risky and prohibitively expensive. Without room to experiment, AI’s benefits will be strangled by red tape.\n",
      "Horror stories: At least one law that would have damaged AI innovation and open source has been blocked, but another is already limiting access to technology and raising costs for companies, developers, and users worldwide. More such efforts likely are underway.\n",
      "- California SB 1047 would have held developers of models above a certain size (requiring 10 26 floating-point operations or cost $100 million to train) liable for unintended harms caused by their models, such as helping to perpetrate thefts, cyberattacks, or design weapons of mass destruction. The bill required such systems to include a “kill switch” that would enable developers to disable them in an emergency – a problematic requirement for open-weights models that could be modified and deployed anywhere. Governor Gavin Newsom vetoed the bill in October, arguing that it didn’t target real risks and that it could have unintended consequences, but legislators may yet introduce (and the governor could sign) a modified bill.\n",
      "* - The European Union’s AI Act, implemented in August 2024, restricts applications deemed high-risk, such as face recognition and predictive policing. It subjects models to strict scrutiny in essential fields like education, employment, and law enforcement. It also requires developers to provide detailed information about their models’ algorithms and data sources. But critics argue that it could stifle European companies’ early-stage research. Meta restricted Llama 3’s vision capabilities in the EU, which may run afoul of the union’s privacy laws, and Apple delayed launching AI features in Europe due to regulatory uncertainties. Meta, Apple, Anthropic, TikTok, and other leading companies did not sign the EU’s Artificial Intelligence Pact, which would have committed them to comply with certain provisions of the AI Act before they take effect.\n",
      "- In September, the U.S, UK, and many countries in Europe and elsewhere signed the Framework Convention on Artificial Intelligence and Human Rights, Democracy, and the Rule of Law. This treaty, which will take effect by the end of the year, requires that AI models respect democracy and human rights. It’s legally binding on signatories and may be enforceable by the council’s international Court of Human Rights. In practical terms, though, each member can impose its own definition of democracy and human rights, potentially creating a patchwork of legal uncertainties and burdens for AI companies worldwide.\n",
      "- China has passed a number of laws that focus on reducing AI’s potential harms by exerting strong government control. Key laws require companies to label AI-generated output and disclose training sets and algorithms to the government, and mandate that AI-generated media align with government policies on inappropriate speech. Some companies, like OpenAI and Anthropic, have restricted their offerings in China.\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"What was the law that prevented the advancements in open source AI?\",\n",
    "    k = 2\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article_link': 'https://www.deeplearning.ai/the-batch/issue-273/', 'article_title': 'Trick or treat! AI Devours Energy, Innovation Can’t Win, Models Collapse, Benchmark Tests Are Meaningless, No Work for Coders', 'chunk_heading': 'Innovation Can’t Win', 'chunk_index': 5}\n"
     ]
    }
   ],
   "source": [
    "print(results[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying using Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

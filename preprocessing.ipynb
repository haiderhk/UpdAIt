{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a List containing links of all articles (Including featured article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_website_html\n",
    "from scraper import get_featured_article_link, get_articles_links, get_article_titles\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "BASE_URL = \"https://www.deeplearning.ai\"\n",
    "THE_BATCH_URL = \"https://www.deeplearning.ai/the-batch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_page_html = get_website_html(THE_BATCH_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid article link (It is probably a featured article)...continuing\n",
      "0 --> https://www.deeplearning.ai/the-batch/issue-280/\n",
      "1 --> https://www.deeplearning.ai/the-batch/issue-279/\n",
      "2 --> https://www.deeplearning.ai/the-batch/issue-278/\n",
      "3 --> https://www.deeplearning.ai/the-batch/issue-277/\n",
      "4 --> https://www.deeplearning.ai/the-batch/issue-276/\n",
      "5 --> https://www.deeplearning.ai/the-batch/issue-275/\n",
      "6 --> https://www.deeplearning.ai/the-batch/issue-274/\n",
      "7 --> https://www.deeplearning.ai/the-batch/issue-273/\n",
      "8 --> https://www.deeplearning.ai/the-batch/issue-272/\n",
      "9 --> https://www.deeplearning.ai/the-batch/issue-271/\n",
      "10 --> https://www.deeplearning.ai/the-batch/issue-270/\n",
      "11 --> https://www.deeplearning.ai/the-batch/issue-269/\n",
      "12 --> https://www.deeplearning.ai/the-batch/issue-268/\n",
      "13 --> https://www.deeplearning.ai/the-batch/issue-267/\n",
      "14 --> https://www.deeplearning.ai/the-batch/issue-266/\n"
     ]
    }
   ],
   "source": [
    "unfeatured_articles_links = get_articles_links(home_page_html)\n",
    "\n",
    "for index, link in enumerate(unfeatured_articles_links):\n",
    "    print(f\"{index} --> {link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.deeplearning.ai/the-batch/issue-281/\n"
     ]
    }
   ],
   "source": [
    "featured_article_link = get_featured_article_link(home_page_html)\n",
    "print(featured_article_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles:  16\n",
      "0 --> https://www.deeplearning.ai/the-batch/issue-281/\n",
      "1 --> https://www.deeplearning.ai/the-batch/issue-280/\n",
      "2 --> https://www.deeplearning.ai/the-batch/issue-279/\n",
      "3 --> https://www.deeplearning.ai/the-batch/issue-278/\n",
      "4 --> https://www.deeplearning.ai/the-batch/issue-277/\n",
      "5 --> https://www.deeplearning.ai/the-batch/issue-276/\n",
      "6 --> https://www.deeplearning.ai/the-batch/issue-275/\n",
      "7 --> https://www.deeplearning.ai/the-batch/issue-274/\n",
      "8 --> https://www.deeplearning.ai/the-batch/issue-273/\n",
      "9 --> https://www.deeplearning.ai/the-batch/issue-272/\n",
      "10 --> https://www.deeplearning.ai/the-batch/issue-271/\n",
      "11 --> https://www.deeplearning.ai/the-batch/issue-270/\n",
      "12 --> https://www.deeplearning.ai/the-batch/issue-269/\n",
      "13 --> https://www.deeplearning.ai/the-batch/issue-268/\n",
      "14 --> https://www.deeplearning.ai/the-batch/issue-267/\n",
      "15 --> https://www.deeplearning.ai/the-batch/issue-266/\n"
     ]
    }
   ],
   "source": [
    "all_articles_links = [featured_article_link] + unfeatured_articles_links\n",
    "print(\"Total number of articles: \", len(all_articles_links))\n",
    "for i, article in enumerate(all_articles_links):\n",
    "    print(f\"{i} --> {article}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list containing the titles of all articles.\n",
    "#### The order will be the same as the links in all_articles_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total titles: 16\n",
      "0 --> Top AI Stories of 2024! Agents Rise, Prices Fall, Models Shrink, Video Takes Off, Acquisitions Morph\n",
      "1 --> Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, Gemini 2.0 Flash Accelerates Multimodal Modeling, LLMs Propose Research Ideas\n",
      "2 --> Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs\n",
      "3 --> AI Agents Spend Real Money, Breaking Jailbreaks, Mistral Goes Big and Multimodal, AI’s Growing E-Waste Problem\n",
      "4 --> DeepSeek Takes On OpenAI, Robots Fold Laundry, Amazon and Anthropic Expand Partnership, More Efficient Object Detection\n",
      "5 --> Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, Transformer Training Streamlined\n",
      "6 --> Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot\n",
      "7 --> AI Controls Desktops, Agents Train Algorithms, Does Anyone Comply With the EU’s AI Act?, Robots on the Loading Dock\n",
      "8 --> Trick or treat! AI Devours Energy, Innovation Can’t Win, Models Collapse, Benchmark Tests Are Meaningless, No Work for Coders\n",
      "9 --> AI Giants Go Nuclear, A Tech Bromance Turns Turbulent, Mistral Sharpens the Edge, Cheaper Video Generation\n",
      "10 --> Bogus Apps, AI Boomtown, Better Embeddings, 2024 Highlights\n",
      "11 --> How Meta’s Movie Gen Does It, AI’s Criminal Underground, Court Says LAION is Legal, OpenAI’s New Voice API\n",
      "12 --> Llama Goes Multimodal, Pros Embrace Generative Video, Military AI Guidelines, LLMs That Read Spreadsheets\n",
      "13 --> Hollywood Embraces Video Gen, New Restrictions on Deepfakes, More Open Source Models, Robot Server\n",
      "14 --> Models Built for Reasoning, High Gear for Llama 3.1, Brains for Warehouse Robots, Stopping LLMs From Plagiarizing\n",
      "15 --> Nations Sign Binding AI Treaty, Waymo Reveals Safety Record, 2D to 3D Goes Mainstream, Balancing Web Data Distributions\n"
     ]
    }
   ],
   "source": [
    "all_articles_titles = get_article_titles(home_page_html)\n",
    "print(f\"Total titles: {len(all_articles_titles)}\")\n",
    "for i, title in enumerate(all_articles_titles):\n",
    "    print(f\"{i} --> {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Chunks of each Article (Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(docs):\n",
    "    headings = []\n",
    "    chunk_index = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    for index, doc in enumerate(docs):\n",
    "        if doc.startswith('##'):\n",
    "            pattern = re.compile(r'^##\\s+(.*)$', re.MULTILINE)\n",
    "            match = pattern.search(doc)\n",
    "            heading = match.group(1)\n",
    "            headings.append(match.group(1))\n",
    "            metadatas.append({\"Heading\": heading, \"source\": index})\n",
    "        else:\n",
    "            words = doc.split()\n",
    "            first_four = words[:4]\n",
    "            heading = ' '.join(first_four)\n",
    "            headings.append(heading)\n",
    "            metadatas.append({\"Heading\": heading, \"source\": index})\n",
    "\n",
    "        chunk_index.append(f\"Chunk #{index}\")\n",
    "    # metadatas[\"Headings\"] = headings\n",
    "    # metadatas[\"Indexes\"] = chunk_index\n",
    "        ids.append(f\"id{index}\")\n",
    "    return metadatas, ids\n",
    "\n",
    "metadatas, ids = create_metadata(docs)\n",
    "# print(f\"Headings: \\n{metadatas[\"Headings\"]}\\n\\nChunk Indexes: \\n{metadatas[\"Indexes\"]}\")\n",
    "print(metadatas)\n",
    "print(ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, os\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from scraper import get_featured_article\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featured Article URL: https://www.deeplearning.ai/the-batch/issue-281/\n",
      "Successfully fetched the featured article page!\n",
      "Formatted Content for LLM:\n",
      "\n",
      "\n",
      "Article:\n",
      " ## Introduction\n",
      "Dear friends,\n",
      "Is AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.\n",
      "Consider this: GPT-4 was released March 2023. Since then, models have become much faster, cheaper, sometimes smaller, more multimodal, and better at reasoning, and many more open weight versions are available — so progress has been fantastic! (Claims that AI is “hitting a wall” seem extremely ill-informed.) But more significantly, many applications that  already were theoretically possible using the March 2023 version of GPT-4 — in areas such as customer service, question answering, and process automation — now have significant early momentum.\n",
      "I’m confident 2025 will see even faster and more exciting advances than 2024 in both AI technology and applications. Looking back, the one thing that could have stopped AI was bad, anti-competitive regulation that would have put onerous burdens on developers, particularly of open models. So long as we remain vigilant and hold off these anti-innovation forces, we’ll keep up or even further accelerate progress.\n",
      "I’m also seeing a widening gap between those at the cutting edge (which includes many readers of The Batch !) and those who have not yet tried out ChatGPT even once (yes, a lot of people are still in this group!). As technology changes around us, we all have to keep up to remain relevant and be able to make significant contributions. I’m committed to making sure DeepLearning.AI continues to help you learn the most useful and important AI technologies. If you’re making New Year’s resolutions, I hope you’ll include us in your learning plan!\n",
      "AI is the most important technological change happening in the world right now. I’m thrilled to be working in this exciting sector alongside you, and I’m grateful for your efforts to learn about and apply it to better the lives of yourself and others.\n",
      "Happy holidays!\n",
      "Andrew\n",
      "\n",
      "## A Blizzard of Progress\n",
      "What a year! AI made dramatic advances in 2024. Agentic systems improved their abilities to reason, use tools, and control desktop applications. Smaller models proliferated, many of them more capable and less expensive than their larger forbears. While some developments raised worries , far more sparked wonder and optimism. As in the waning days of earlier years , we invite you to pour a cup of hot cocoa and consider the high points of the last 12 months.\n",
      "\n",
      "## Agents Ascendant\n",
      "The AI community laid the foundation for systems that can act by prompting large language models iteratively, leading to much higher performance across a range of applications.\n",
      "What happened: AI gained a new buzzword — agentic — as researchers, tool vendors, and model builders equipped large language models (LLMs) to make choices and take actions to achieve goals. These developments set the stage for an upswell of agentic activity in the coming year and beyond.\n",
      "Driving the story: Several tools emerged to help developers build agentic workflows.\n",
      "- Microsoft primed the pump for agentic development tools in late 2023 with Autogen, an open source conversational framework that orchestrates collaboration among multiple agents. (Learn how to take advantage of it in our short course “ AI Agentic Design Patterns with Autogen .”) In late 2024, part of the Autogen team split off to build AG2 based on a fork of the code base.\n",
      "- In October 2023, CrewAI released its open source Python framework for building and managing multi-agent systems. Agents can be assigned roles and goals, gain access to tools like web search, and collaborate with each other. (DeepLearning.AI’s short courses “ Multi-Agent Systems with crewAI ” and “ Practical Multi AI-Agents and Advanced Use Cases with crewAI ” can give you a fast start.)\n",
      "- In January, LangChain, a provider of development tools, introduced LangGraph, which orchestrates agent behaviors using cyclical graphs. The framework enables LLM-driven agents to receive inputs, reason over them, decide on actions, use tools, evaluate the results, and repeat these steps to improve results. (Our short course “ AI Agents in LangGraph ” offers an introduction.)\n",
      "- In September, Meta introduced Llama Stack for building agentic applications based on Llama models. Llama Stack provides memory, conversational skills, orchestration services, and ethical guardrails.\n",
      "- Throughout the year, integrated development environments implemented agentic workflows to generate code. For instance, Devin and OpenHands accept natural-language instructions to generate prototype programs. Replit Agent, Vercel’s V0, and Bolt streamline projects by automatically writing code, fixing bugs, and managing dependencies.\n",
      "- Meanwhile, a number of LLM makers supported agentic workflows by implementing tool use and function calling. Anthropic added computer use , enabling Claude 3.5 Sonnet to control users’ computers directly.\n",
      "- Late in the year, OpenAI rolled out its o1 models and the processing-intensive o1 pro mode, which use agentic loops to work through prompts step by step. DeepSeek-R1 and Google Gemini 2.0 Flash Thinking Mode followed with similar agentic reasoning. In the final days of 2024, OpenAI announced o3 and o3-preview, which further extend o1’s agentic reasoning capabilities with impressive reported results.\n",
      "Behind the news: Techniques for prompting LLMs in more sophisticated ways began to take off in 2022. They coalesced in moves toward agentic AI early this year. Foundational examples of this body of work include:\n",
      "- Chain of Thought prompting, which asks LLMs to think step by step\n",
      "- Self-consistency , which prompts a model to generate several responses and pick the one that’s most consistent with the others\n",
      "- ReAc t, which interleaves reasoning and action steps to accomplish a goal\n",
      "- Self-Refine , which enables an agent to reflect on its own output\n",
      "- Reflexion , which enables a model to act, evaluate, reflect, and repeat.\n",
      "- Test-time compute , which increases the amount of processing power allotted to inference\n",
      "Where things stand: The agentic era is upon us! Regardless of how well scaling laws continue to drive improved performance of foundation models, agentic workflows are making AI systems increasingly helpful, efficient, and personalized.\n",
      "\n",
      "## Prices Tumble\n",
      "Fierce competition among model makers and cloud providers drove down the price of access to state-of-the-art models.\n",
      "What happened: AI providers waged a price war to attract paying customers. A leading indicator: From March 2023 to November 2024, OpenAI cut the per-token prices of cloud access to its models by nearly 90 percent even as performance improved, input context windows expanded, and the models became capable of processing images as well as text.\n",
      "Driving the story: Factors that pushed down prices include open source, more compute-efficient models, and excitement around agentic workflows that consume more tokens at inference. OpenAI’s GPT-4 Turbo set a baseline when it debuted in late 2023 at $10.00/$30.00 per million tokens of input/output. Top model makers slashed prices in turn: Google and OpenAI at the higher end of the market, companies in China at the lower end, and Amazon at both. Meanwhile, startups with specialized hardware offered open models at prices that dramatically undercut the giants.\n",
      "- Competitive models with open weights helped drive prices down by enabling cloud providers to offer high-performance models without bearing the cost of developing or licensing them. Meta released Llama 3 70B in April, and various cloud providers offered it at an average price of $0.78/$0.95 per million input/output tokens. Llama 3.1 405B followed in July 2024; Microsoft Azure priced it at almost half the price of GPT-4 Turbo ($5.33/$16.00).\n",
      "- Per-token prices for open weights models tumbled in China. In May, DeepSeek released DeepSeek V2 and soon dropped the price to $0.14/$0.28 per million tokens of input/output. Alibaba, Baidu, and Bytedance slashed prices for Qwen-Long ($0.06/$0.06), Ernie-Speed and Ernie-Lite (free), and Doubau ($0.11/$0.11) respectively.\n",
      "- Makers of closed models outdid one another with lower and lower prices. In May, OpenAI introduced GPT-4o at $5.00/$15.00 per million tokens of input/output, half as much as GPT-4 Turbo. By August, GPT-4o cost $2.50/$10.00 and the newer GPT-4o mini cost $0.15/$0.60 (half as much for jobs with slower turnaround times).\n",
      "- Google ultimately cut the price of Gemini 1.5 Pro to $1.25/$5.00 per million input/output tokens (twice as much for prompts longer than 128,000 tokens) and slashed Gemini 1.5 Flash to $0.075/$0.30 per million input/output tokens (twice as much for prompts longer than 128,000 tokens). As of this writing, Gemini 2.0 Flash is free to use as an experimental preview, and API prices have not been announced.\n",
      "- In December, Amazon introduced the Nova family of LLMs. At launch, Nova Pro ($0.80/$3.20 per million tokens of input/output) cost much less than top models from OpenAI or Google, while Nova Lite ($0.06/$0.24) and Nova Micro ($0.035/$0.14 respectively) cost much less than GPT-4o mini. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)\n",
      "- Even as model providers cut their prices, startups including Cerebrus, Groq, and SambaNova designed specialized chips that enabled them to serve open weights models faster and more cheaply. For example, SambaNova offered Llama 3.1 405B for $5.00/$10.00 per million tokens of input/output, processing a blazing 132 tokens per second. DeepInfra offered the same model at a slower speed for as little as $2.70/$2.70.\n",
      "Yes, but: The trend toward more processing-intensive models is challenged but not dead. In September, OpenAI introduced token-hungry models with relatively hefty price tags: o1-preview ($15.00/$60.00 per million tokens input/output) and o1-mini ($3.00/$12.00). In December, o1 arrived with a more accurate pro mode that’s available only to subscribers who are willing to pay $200 per month.\n",
      "Behind the news: Prominent members of the AI community pushed against regulations that threatened to restrict open source models, which played an important role in bringing down prices. Opposition by developers helped to block California SB 1047, a proposed law that would have held developers of models above certain size limits liable for unintended harms caused by their models and required a “kill switch” that would enable developers to disable them — a problematic requirement for open weights models that anyone could modify and deploy. California Governor Gavin Newsom vetoed the bill in October.\n",
      "Where things stand: Falling prices are a sign of a healthy tech ecosystem. It’s likely that in-demand models will always fetch relatively high prices, but the market is increasingly priced in pennies, not dollars, per million tokens.\n",
      "\n",
      "## Generative Video Takes Off\n",
      "Video generation exploded in an abundance of powerful models.\n",
      "What happened: Companies big and small introduced new or updated text-to-video generators. Some added image-to-video and/or video-to-video capabilities. While most models focus on generating cinematic clips, some specialize in videos for social media.\n",
      "Driving the story: Even at the extraordinary pace of AI lately, video generators in the past year matured with remarkable speed. Virtually every major model produces convincing, highly detailed scenes, both realistic and fantastical, while ramping up image resolution, speed, output length, and users’ ability to control their outputs.\n",
      "- OpenAI Sora set a high bar early in the year. Introduced in February and shown privately to Hollywood creators, it built a formidable buzz despite being available to only selected users. Unauthorized users gained access in November, and OpenAI made the model available the following month. Built on a diffusion transformer , Sora generates consistent (if somewhat dreamlike) scenes of up to 1 minute long.\n",
      "- Runway Gen 3 Alpha and Gen 3 Alpha Turbo improved on their predecessors, generating higher-resolution videos (up to 1,280x768-pixel resolution) and introducing an API. Runway struck a deal with the film studio Lionsgate, which will use a custom version fine-tuned on its archive for visual effects and pre-visualizations.\n",
      "- Adobe took a different approach with its Firefly Video model. In addition to offering a web application, the company incorporated the model directly into its best-selling Adobe Premiere Pro video editing suite. The integration enables video artists to generate clips, extend or enhance existing ones, and add effects within the program.\n",
      "- Meta introduced Movie Gen , a suite of four systems. While its video output rivals that of competitors, it stands out especially for its ability to generate soundtracks. One system produces sound effects and music that match video. Another specializes in producing videos in which characters’ faces remain consistent, and another performs video-to-video alterations. Movie Gen will be available on Instagram in 2025.\n",
      "- Model builders in China tailored their models for producing social media. Kling AI emphasized making TikTok and Instagram Reels. PixVerse and Jimeng AI likewise introduced video generators designed for social media users. In October, TikTok’s parent ByteDance added two video generation models, PixelDance and Seaweed, that produce 10-second and 30-second clips respectively.\n",
      "Behind the news: Video generation is already reshaping the movie industry. In February, after seeing a preview of Sora, American filmmaker Tyler Perry halted a planned expansion of his production studio, arguing that within a few years, AI video could put traditional studios out of business. Members of the video graphics team at The Late Show with Stephen Colbert use Runway’s technology to add special effects to conventional digital video, cutting editing time from hours to minutes.\n",
      "Where things stand: Video generation came a long way in 2024, but there’s still plenty of room for improvement. Because most models only generate a small number of frames at a time, they can struggle to track physics and geometry and to generate consistent characters and scenery over time. The computational demands of maintaining consistency across frames means that generated clips are brief. And even short outputs take substantial time and resources to generate: Sora can take 10 to 20 minutes to render clips as short as 3 seconds. OpenAI and Runway released faster versions — Sora Turbo and Gen-3 Alpha Turbo — to address the challenge.\n",
      "\n",
      "## Smaller Is Beautiful\n",
      "For years, the best AI models got bigger and bigger. But in 2024, some popular large language models were small enough to run on a smartphone.\n",
      "What happened : Instead of putting all their resources into building big models, top AI companies promoted families of large language models that offer a choice of small, medium, and large. Model families such as Microsoft Phi-3 (in versions of roughly 3.8 billion, 7 billion, and 14 billion parameters), Google Gemma 2 (2 billion, 9 billion, and 27 billion), and Hugging Face SmolLM (135 million, 360 million, and 1.7 billion) specialize in small.\n",
      "Driving the story: Smaller models have become more capable thanks to techniques like knowledge distillation (in which a larger teacher model is used to train a smaller student model to match its output), parameter pruning (which removes less-influential parameters), quantization (which reduces neural network sizes by representing each parameter with fewer bits), and greater attention to curating training sets for data quality. Beyond performance, speed, and price, the ability to run on relatively low-powered hardware is a competitive advantage for a variety of uses.\n",
      "- Model builders have offered model families that include members of various sizes since at least 2019, when Google introduced the T5 family (five models between roughly 77 million parameters and 11 billion parameters). The success of OpenAI’s GPT series, which over time grew from 117 million parameters to a hypothesized 1.76 trillion parameters, demonstrated the power of bigger models. OpenAI researchers formulated scaling laws that appeared to guarantee that bigger models, training sets, and compute budgets would lead to predictable improvements in performance. This finding spurred rivals to build larger and larger models.\n",
      "- The tide started to turn in early 2023. Meta’s Llama 2 came in parameter counts of roughly 7 billion, 13 billion, and 70 billion with open weights.\n",
      "- In December 2023, Google launched the Gemini family, including Gemini Nano (1.8 billion parameters). In February, it released the small, open weights family Gemma 1 (2 billion and 7 billion parameters), followed by Gemma 2 (9 billion and 27 billion).\n",
      "- Microsoft introduced Phi-2 (2.7 billion parameters) in December 2023 and Phi-3 (3.8 billion, 7 billion, and 14 billion) in April.\n",
      "- In August, Nvidia released its Minitron models. It used a combination of distillation and pruning to shrink Llama 3.1 from 8 billion to 4 billion parameters and Mistral NeMo from 12 billion to 8 billion parameters, boosting speed and lowering computing costs while maintaining nearly the same level of accuracy.\n",
      "Behind the news: Distillation, pruning, quantization, and data curation are longstanding practices. But these techniques have not resulted in models quite this ratio of size and capability before, arguably because the larger models that are distilled, pruned, or quantized have never been so capable.\n",
      "- In 1989, Yann LeCun and colleagues at Bell Labs published “ Optimal Brain Damage ,” which showed that  deleting weights selectively could reduce a model’s size and, in some cases, improve its ability to generalize.\n",
      "- Quantization dates to 1990, when E. Fiesler and colleagues at the University of Alabama demonstrated various ways to represent the parameters of a neural network in “ A Weight Discretization Paradigm for Optical Neural Networks .” It made a resurgence 2010’s with the growth in popularity and sizes of neural networks, which spurred the refinements quantization-aware training and post-training quantization .\n",
      "- In 2006, Rich Caruana and colleagues at Cornell published “ Model Compression ,” showing how to train a single model to mimic the performance of multiple models. Geoffrey Hinton and colleagues at Google Brain followed in 2015 with “ Distilling the Knowledge in a Neural Network ,” which improved the work of Caruana et al. and introduced the term distillation to describe a more general way to compress models.\n",
      "- Most of the current crop of smaller models were trained on datasets that were carefully curated and cleaned. Higher-quality data makes it possible to get more performance out of fewer parameters. This is an example of data-centric AI , the practice of improving model performance by improving the quality of their training data.\n",
      "Where things stand: Smaller models dramatically widen the options for cost, speed, and deployment. As researchers find ways to shrink models without sacrificing performance, developers are gaining new ways to build profitable applications, deliver timely services, and distribute processing to the edges of the internet.\n",
      "\n",
      "## Alternatives to Acquisitions\n",
      "Big AI companies found creative ways to gain cutting-edge technology and talent without buying startups.\n",
      "What happened: In 2024, some tech giants entered into novel partnership arrangements with AI startups, hiring top executives and securing access to technology without acquiring the companies outright. These agreements enabled the giants to take on elite talent and proven technology quickly with less risk that regulators might hinder such actions. The startups lost their leadership teams and control over key technical developments. In return, they received cash (in some cases, at least), rewarded investors, and were able to step back from the expense of building cutting-edge models.\n",
      "Driving the story: Microsoft, Amazon, and Google used their deep pockets and cloud infrastructure to strike deals with Inflection AI, Adept AI and Covariant, and Character.ai respectively. (Disclosure: Andrew Ng is a member of Amazon’s board of directors.)\n",
      "- Microsoft blazed the trail in March. The tech giant invested $650 million in Inflection AI, licensed the startup’s models, integrated its conversational AI technologies, and hired much of its staff, including co-founders Mustafa Suleyman and Karén Simonyan. Microsoft named Suleyman CEO of a new AI division, putting him in charge of Microsoft’s own model building efforts and consumer-facing products like Bing and the Copilot product line. The remainder of Inflection focuses on customizing AI models for commercial clients.\n",
      "- In July, Amazon inked a similar agreement with Adept, a startup that built agents for tasks such as automating data entry and managing customer support tickets, under undisclosed terms. Amazon hired most of Adept AI’s staff, including CEO David Luan and other co-founders who were alumni from Google and OpenAI, and licensed Adept’s models, datasets, and other technology non-exclusively. Adept stopped developing in-house models to concentrate on building agents.\n",
      "- In October, Amazon further bolstered its logistics capabilities by forging an agreement with Covariant, a maker of AI-driven warehouse robots, also under undisclosed terms. Amazon hired most of the startup’s staff, including CEO/co-founder Peter Chen and chief scientist/co-founder Pieter Abbeel, and licensed its robotics models. In December, Amazon paired Abbeel and former Adept CEO Luan to run a new lab devoted to developing agents and artificial general intelligence. Covariant continues to serve customers in fulfillment centers and other industries.\n",
      "- In August, Google and conversational AI startup Character.ai cut a similar deal. Google hired Character.ai’s co-founders, Noam Shazeer and Daniel De Freitas, along with key team members, and inked a non-exclusive license to its technology. Shazeer joined Google’s Deep Learning research team, and other new hires set to work on Google’s chat services. Google gave Character.ai an undisclosed sum to buy out its investors and continue developing personalized AI products.\n",
      "Behind the news: Tech giants have long relied on traditional acquisitions to gain new talent and capabilities, often acquiring startups specifically for their skilled teams (known as an acquihire) and/or their products or underlying technology, which can be expensive and time-consuming to develop and test in the market. But traditional acquisitions increasingly face scrutiny from antitrust regulators who are concerned about big companies reducing competition by buying out smaller ones. For example, the United States Federal Trade Commission sought to block Amazon’s acquisition of iRobot, prompting the companies to abandon the transaction in January 2024.\n",
      "Where things stand: Giving startups a lump sum and/or licensing fees in return for top talent and technology looks like the new normal for tech giants that are challenged to keep pace with rapidly advancing research and markets. But even arms-length arrangements don’t immunize tech giants and startups against regulatory investigation. Microsoft’s investment in Inflection AI was briefly scrutinized in Europe and is still being evaluated by U.S. regulators. Even Microsoft’s more traditional investment in OpenAI and the interests of Amazon and Google in Anthropic faced regulatory hurdles. So far, however, regulators have yet to conclude that any of these agreements violates antitrust law.\n"
     ]
    }
   ],
   "source": [
    "article_text = get_featured_article()\n",
    "print(f\"\\n\\nArticle:\\n\", article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Article Chunks Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of docs: 15\n",
      "Chunk #1\n",
      "## Introduction\n",
      "Dear friends,\n",
      "Is AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.\n",
      "Consider this: GPT-4 was released March 2023. Since then, models have become much faster, cheaper, sometimes smaller, more multimodal, and better at reasoning, and many more open weight versions are available — so progress has been fantastic! (Claims that AI is “hitting a wall” seem extremely ill-informed.) But more significantly, many applications that  already were theoretically possible using the March 2023 version of GPT-4 — in areas such as customer service, question answering, and process automation — now have significant early momentum.\n",
      "I’m confident 2025 will see even faster and more exciting advances than 2024 in both AI technology and applications. Looking back, the one thing that could have stopped AI was bad, anti-competitive regulation that would have put onerous burdens on developers, particularly of open models. So long as we remain vigilant and hold off these anti-innovation forces, we’ll keep up or even further accelerate progress.\n",
      "I’m also seeing a widening gap between those at the cutting edge (which includes many readers of The Batch !) and those who have not yet tried out ChatGPT even once (yes, a lot of people are still in this group!). As technology changes around us, we all have to keep up to remain relevant and be able to make significant contributions. I’m committed to making sure DeepLearning.AI continues to help you learn the most useful and important AI technologies. If you’re making New Year’s resolutions, I hope you’ll include us in your learning plan!\n",
      "AI is the most important technological change happening in the world right now. I’m thrilled to be working in this exciting sector alongside you, and I’m grateful for your efforts to learn about and apply it to better the lives of yourself and others.\n",
      "Happy holidays!\n",
      "Andrew\n",
      "\n",
      "\n",
      "Chunk #2\n",
      "## A Blizzard of Progress\n",
      "What a year! AI made dramatic advances in 2024. Agentic systems improved their abilities to reason, use tools, and control desktop applications. Smaller models proliferated, many of them more capable and less expensive than their larger forbears. While some developments raised worries , far more sparked wonder and optimism. As in the waning days of earlier years , we invite you to pour a cup of hot cocoa and consider the high points of the last 12 months.\n",
      "\n",
      "\n",
      "Chunk #3\n",
      "## Agents Ascendant\n",
      "The AI community laid the foundation for systems that can act by prompting large language models iteratively, leading to much higher performance across a range of applications.\n",
      "What happened: AI gained a new buzzword — agentic — as researchers, tool vendors, and model builders equipped large language models (LLMs) to make choices and take actions to achieve goals. These developments set the stage for an upswell of agentic activity in the coming year and beyond.\n",
      "Driving the story: Several tools emerged to help developers build agentic workflows.\n",
      "- Microsoft primed the pump for agentic development tools in late 2023 with Autogen, an open source conversational framework that orchestrates collaboration among multiple agents. (Learn how to take advantage of it in our short course “ AI Agentic Design Patterns with Autogen .”) In late 2024, part of the Autogen team split off to build AG2 based on a fork of the code base.\n",
      "- In October 2023, CrewAI released its open source Python framework for building and managing multi-agent systems. Agents can be assigned roles and goals, gain access to tools like web search, and collaborate with each other. (DeepLearning.AI’s short courses “ Multi-Agent Systems with crewAI ” and “ Practical Multi AI-Agents and Advanced Use Cases with crewAI ” can give you a fast start.)\n",
      "- In January, LangChain, a provider of development tools, introduced LangGraph, which orchestrates agent behaviors using cyclical graphs. The framework enables LLM-driven agents to receive inputs, reason over them, decide on actions, use tools, evaluate the results, and repeat these steps to improve results. (Our short course “ AI Agents in LangGraph ” offers an introduction.)\n",
      "- In September, Meta introduced Llama Stack for building agentic applications based on Llama models. Llama Stack provides memory, conversational skills, orchestration services, and ethical guardrails.\n",
      "\n",
      "\n",
      "Chunk #4\n",
      "- Throughout the year, integrated development environments implemented agentic workflows to generate code. For instance, Devin and OpenHands accept natural-language instructions to generate prototype programs. Replit Agent, Vercel’s V0, and Bolt streamline projects by automatically writing code, fixing bugs, and managing dependencies.\n",
      "- Meanwhile, a number of LLM makers supported agentic workflows by implementing tool use and function calling. Anthropic added computer use , enabling Claude 3.5 Sonnet to control users’ computers directly.\n",
      "- Late in the year, OpenAI rolled out its o1 models and the processing-intensive o1 pro mode, which use agentic loops to work through prompts step by step. DeepSeek-R1 and Google Gemini 2.0 Flash Thinking Mode followed with similar agentic reasoning. In the final days of 2024, OpenAI announced o3 and o3-preview, which further extend o1’s agentic reasoning capabilities with impressive reported results.\n",
      "Behind the news: Techniques for prompting LLMs in more sophisticated ways began to take off in 2022. They coalesced in moves toward agentic AI early this year. Foundational examples of this body of work include:\n",
      "- Chain of Thought prompting, which asks LLMs to think step by step\n",
      "- Self-consistency , which prompts a model to generate several responses and pick the one that’s most consistent with the others\n",
      "- ReAc t, which interleaves reasoning and action steps to accomplish a goal\n",
      "- Self-Refine , which enables an agent to reflect on its own output\n",
      "- Reflexion , which enables a model to act, evaluate, reflect, and repeat.\n",
      "- Test-time compute , which increases the amount of processing power allotted to inference\n",
      "Where things stand: The agentic era is upon us! Regardless of how well scaling laws continue to drive improved performance of foundation models, agentic workflows are making AI systems increasingly helpful, efficient, and personalized.\n",
      "\n",
      "\n",
      "Chunk #5\n",
      "## Prices Tumble\n",
      "Fierce competition among model makers and cloud providers drove down the price of access to state-of-the-art models.\n",
      "What happened: AI providers waged a price war to attract paying customers. A leading indicator: From March 2023 to November 2024, OpenAI cut the per-token prices of cloud access to its models by nearly 90 percent even as performance improved, input context windows expanded, and the models became capable of processing images as well as text.\n",
      "Driving the story: Factors that pushed down prices include open source, more compute-efficient models, and excitement around agentic workflows that consume more tokens at inference. OpenAI’s GPT-4 Turbo set a baseline when it debuted in late 2023 at $10.00/$30.00 per million tokens of input/output. Top model makers slashed prices in turn: Google and OpenAI at the higher end of the market, companies in China at the lower end, and Amazon at both. Meanwhile, startups with specialized hardware offered open models at prices that dramatically undercut the giants.\n",
      "- Competitive models with open weights helped drive prices down by enabling cloud providers to offer high-performance models without bearing the cost of developing or licensing them. Meta released Llama 3 70B in April, and various cloud providers offered it at an average price of $0.78/$0.95 per million input/output tokens. Llama 3.1 405B followed in July 2024; Microsoft Azure priced it at almost half the price of GPT-4 Turbo ($5.33/$16.00).\n",
      "- Per-token prices for open weights models tumbled in China. In May, DeepSeek released DeepSeek V2 and soon dropped the price to $0.14/$0.28 per million tokens of input/output. Alibaba, Baidu, and Bytedance slashed prices for Qwen-Long ($0.06/$0.06), Ernie-Speed and Ernie-Lite (free), and Doubau ($0.11/$0.11) respectively.\n",
      "\n",
      "\n",
      "Chunk #6\n",
      "- Makers of closed models outdid one another with lower and lower prices. In May, OpenAI introduced GPT-4o at $5.00/$15.00 per million tokens of input/output, half as much as GPT-4 Turbo. By August, GPT-4o cost $2.50/$10.00 and the newer GPT-4o mini cost $0.15/$0.60 (half as much for jobs with slower turnaround times).\n",
      "- Google ultimately cut the price of Gemini 1.5 Pro to $1.25/$5.00 per million input/output tokens (twice as much for prompts longer than 128,000 tokens) and slashed Gemini 1.5 Flash to $0.075/$0.30 per million input/output tokens (twice as much for prompts longer than 128,000 tokens). As of this writing, Gemini 2.0 Flash is free to use as an experimental preview, and API prices have not been announced.\n",
      "- In December, Amazon introduced the Nova family of LLMs. At launch, Nova Pro ($0.80/$3.20 per million tokens of input/output) cost much less than top models from OpenAI or Google, while Nova Lite ($0.06/$0.24) and Nova Micro ($0.035/$0.14 respectively) cost much less than GPT-4o mini. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)\n",
      "- Even as model providers cut their prices, startups including Cerebrus, Groq, and SambaNova designed specialized chips that enabled them to serve open weights models faster and more cheaply. For example, SambaNova offered Llama 3.1 405B for $5.00/$10.00 per million tokens of input/output, processing a blazing 132 tokens per second. DeepInfra offered the same model at a slower speed for as little as $2.70/$2.70.\n",
      "Yes, but: The trend toward more processing-intensive models is challenged but not dead. In September, OpenAI introduced token-hungry models with relatively hefty price tags: o1-preview ($15.00/$60.00 per million tokens input/output) and o1-mini ($3.00/$12.00). In December, o1 arrived with a more accurate pro mode that’s available only to subscribers who are willing to pay $200 per month.\n",
      "\n",
      "\n",
      "Chunk #7\n",
      "Behind the news: Prominent members of the AI community pushed against regulations that threatened to restrict open source models, which played an important role in bringing down prices. Opposition by developers helped to block California SB 1047, a proposed law that would have held developers of models above certain size limits liable for unintended harms caused by their models and required a “kill switch” that would enable developers to disable them — a problematic requirement for open weights models that anyone could modify and deploy. California Governor Gavin Newsom vetoed the bill in October.\n",
      "Where things stand: Falling prices are a sign of a healthy tech ecosystem. It’s likely that in-demand models will always fetch relatively high prices, but the market is increasingly priced in pennies, not dollars, per million tokens.\n",
      "\n",
      "\n",
      "Chunk #8\n",
      "## Generative Video Takes Off\n",
      "Video generation exploded in an abundance of powerful models.\n",
      "What happened: Companies big and small introduced new or updated text-to-video generators. Some added image-to-video and/or video-to-video capabilities. While most models focus on generating cinematic clips, some specialize in videos for social media.\n",
      "Driving the story: Even at the extraordinary pace of AI lately, video generators in the past year matured with remarkable speed. Virtually every major model produces convincing, highly detailed scenes, both realistic and fantastical, while ramping up image resolution, speed, output length, and users’ ability to control their outputs.\n",
      "- OpenAI Sora set a high bar early in the year. Introduced in February and shown privately to Hollywood creators, it built a formidable buzz despite being available to only selected users. Unauthorized users gained access in November, and OpenAI made the model available the following month. Built on a diffusion transformer , Sora generates consistent (if somewhat dreamlike) scenes of up to 1 minute long.\n",
      "- Runway Gen 3 Alpha and Gen 3 Alpha Turbo improved on their predecessors, generating higher-resolution videos (up to 1,280x768-pixel resolution) and introducing an API. Runway struck a deal with the film studio Lionsgate, which will use a custom version fine-tuned on its archive for visual effects and pre-visualizations.\n",
      "- Adobe took a different approach with its Firefly Video model. In addition to offering a web application, the company incorporated the model directly into its best-selling Adobe Premiere Pro video editing suite. The integration enables video artists to generate clips, extend or enhance existing ones, and add effects within the program.\n",
      "\n",
      "\n",
      "Chunk #9\n",
      "- Meta introduced Movie Gen , a suite of four systems. While its video output rivals that of competitors, it stands out especially for its ability to generate soundtracks. One system produces sound effects and music that match video. Another specializes in producing videos in which characters’ faces remain consistent, and another performs video-to-video alterations. Movie Gen will be available on Instagram in 2025.\n",
      "- Model builders in China tailored their models for producing social media. Kling AI emphasized making TikTok and Instagram Reels. PixVerse and Jimeng AI likewise introduced video generators designed for social media users. In October, TikTok’s parent ByteDance added two video generation models, PixelDance and Seaweed, that produce 10-second and 30-second clips respectively.\n",
      "Behind the news: Video generation is already reshaping the movie industry. In February, after seeing a preview of Sora, American filmmaker Tyler Perry halted a planned expansion of his production studio, arguing that within a few years, AI video could put traditional studios out of business. Members of the video graphics team at The Late Show with Stephen Colbert use Runway’s technology to add special effects to conventional digital video, cutting editing time from hours to minutes.\n",
      "Where things stand: Video generation came a long way in 2024, but there’s still plenty of room for improvement. Because most models only generate a small number of frames at a time, they can struggle to track physics and geometry and to generate consistent characters and scenery over time. The computational demands of maintaining consistency across frames means that generated clips are brief. And even short outputs take substantial time and resources to generate: Sora can take 10 to 20 minutes to render clips as short as 3 seconds. OpenAI and Runway released faster versions — Sora Turbo and Gen-3 Alpha Turbo — to address the challenge.\n",
      "\n",
      "\n",
      "Chunk #10\n",
      "## Smaller Is Beautiful\n",
      "For years, the best AI models got bigger and bigger. But in 2024, some popular large language models were small enough to run on a smartphone.\n",
      "What happened : Instead of putting all their resources into building big models, top AI companies promoted families of large language models that offer a choice of small, medium, and large. Model families such as Microsoft Phi-3 (in versions of roughly 3.8 billion, 7 billion, and 14 billion parameters), Google Gemma 2 (2 billion, 9 billion, and 27 billion), and Hugging Face SmolLM (135 million, 360 million, and 1.7 billion) specialize in small.\n",
      "Driving the story: Smaller models have become more capable thanks to techniques like knowledge distillation (in which a larger teacher model is used to train a smaller student model to match its output), parameter pruning (which removes less-influential parameters), quantization (which reduces neural network sizes by representing each parameter with fewer bits), and greater attention to curating training sets for data quality. Beyond performance, speed, and price, the ability to run on relatively low-powered hardware is a competitive advantage for a variety of uses.\n",
      "- Model builders have offered model families that include members of various sizes since at least 2019, when Google introduced the T5 family (five models between roughly 77 million parameters and 11 billion parameters). The success of OpenAI’s GPT series, which over time grew from 117 million parameters to a hypothesized 1.76 trillion parameters, demonstrated the power of bigger models. OpenAI researchers formulated scaling laws that appeared to guarantee that bigger models, training sets, and compute budgets would lead to predictable improvements in performance. This finding spurred rivals to build larger and larger models.\n",
      "- The tide started to turn in early 2023. Meta’s Llama 2 came in parameter counts of roughly 7 billion, 13 billion, and 70 billion with open weights.\n",
      "\n",
      "\n",
      "Chunk #11\n",
      "- The tide started to turn in early 2023. Meta’s Llama 2 came in parameter counts of roughly 7 billion, 13 billion, and 70 billion with open weights.\n",
      "- In December 2023, Google launched the Gemini family, including Gemini Nano (1.8 billion parameters). In February, it released the small, open weights family Gemma 1 (2 billion and 7 billion parameters), followed by Gemma 2 (9 billion and 27 billion).\n",
      "- Microsoft introduced Phi-2 (2.7 billion parameters) in December 2023 and Phi-3 (3.8 billion, 7 billion, and 14 billion) in April.\n",
      "- In August, Nvidia released its Minitron models. It used a combination of distillation and pruning to shrink Llama 3.1 from 8 billion to 4 billion parameters and Mistral NeMo from 12 billion to 8 billion parameters, boosting speed and lowering computing costs while maintaining nearly the same level of accuracy.\n",
      "Behind the news: Distillation, pruning, quantization, and data curation are longstanding practices. But these techniques have not resulted in models quite this ratio of size and capability before, arguably because the larger models that are distilled, pruned, or quantized have never been so capable.\n",
      "- In 1989, Yann LeCun and colleagues at Bell Labs published “ Optimal Brain Damage ,” which showed that  deleting weights selectively could reduce a model’s size and, in some cases, improve its ability to generalize.\n",
      "- Quantization dates to 1990, when E. Fiesler and colleagues at the University of Alabama demonstrated various ways to represent the parameters of a neural network in “ A Weight Discretization Paradigm for Optical Neural Networks .” It made a resurgence 2010’s with the growth in popularity and sizes of neural networks, which spurred the refinements quantization-aware training and post-training quantization .\n",
      "\n",
      "\n",
      "Chunk #12\n",
      "- In 2006, Rich Caruana and colleagues at Cornell published “ Model Compression ,” showing how to train a single model to mimic the performance of multiple models. Geoffrey Hinton and colleagues at Google Brain followed in 2015 with “ Distilling the Knowledge in a Neural Network ,” which improved the work of Caruana et al. and introduced the term distillation to describe a more general way to compress models.\n",
      "- Most of the current crop of smaller models were trained on datasets that were carefully curated and cleaned. Higher-quality data makes it possible to get more performance out of fewer parameters. This is an example of data-centric AI , the practice of improving model performance by improving the quality of their training data.\n",
      "Where things stand: Smaller models dramatically widen the options for cost, speed, and deployment. As researchers find ways to shrink models without sacrificing performance, developers are gaining new ways to build profitable applications, deliver timely services, and distribute processing to the edges of the internet.\n",
      "\n",
      "\n",
      "Chunk #13\n",
      "## Alternatives to Acquisitions\n",
      "Big AI companies found creative ways to gain cutting-edge technology and talent without buying startups.\n",
      "What happened: In 2024, some tech giants entered into novel partnership arrangements with AI startups, hiring top executives and securing access to technology without acquiring the companies outright. These agreements enabled the giants to take on elite talent and proven technology quickly with less risk that regulators might hinder such actions. The startups lost their leadership teams and control over key technical developments. In return, they received cash (in some cases, at least), rewarded investors, and were able to step back from the expense of building cutting-edge models.\n",
      "Driving the story: Microsoft, Amazon, and Google used their deep pockets and cloud infrastructure to strike deals with Inflection AI, Adept AI and Covariant, and Character.ai respectively. (Disclosure: Andrew Ng is a member of Amazon’s board of directors.)\n",
      "- Microsoft blazed the trail in March. The tech giant invested $650 million in Inflection AI, licensed the startup’s models, integrated its conversational AI technologies, and hired much of its staff, including co-founders Mustafa Suleyman and Karén Simonyan. Microsoft named Suleyman CEO of a new AI division, putting him in charge of Microsoft’s own model building efforts and consumer-facing products like Bing and the Copilot product line. The remainder of Inflection focuses on customizing AI models for commercial clients.\n",
      "- In July, Amazon inked a similar agreement with Adept, a startup that built agents for tasks such as automating data entry and managing customer support tickets, under undisclosed terms. Amazon hired most of Adept AI’s staff, including CEO David Luan and other co-founders who were alumni from Google and OpenAI, and licensed Adept’s models, datasets, and other technology non-exclusively. Adept stopped developing in-house models to concentrate on building agents.\n",
      "\n",
      "\n",
      "Chunk #14\n",
      "- In October, Amazon further bolstered its logistics capabilities by forging an agreement with Covariant, a maker of AI-driven warehouse robots, also under undisclosed terms. Amazon hired most of the startup’s staff, including CEO/co-founder Peter Chen and chief scientist/co-founder Pieter Abbeel, and licensed its robotics models. In December, Amazon paired Abbeel and former Adept CEO Luan to run a new lab devoted to developing agents and artificial general intelligence. Covariant continues to serve customers in fulfillment centers and other industries.\n",
      "- In August, Google and conversational AI startup Character.ai cut a similar deal. Google hired Character.ai’s co-founders, Noam Shazeer and Daniel De Freitas, along with key team members, and inked a non-exclusive license to its technology. Shazeer joined Google’s Deep Learning research team, and other new hires set to work on Google’s chat services. Google gave Character.ai an undisclosed sum to buy out its investors and continue developing personalized AI products.\n",
      "Behind the news: Tech giants have long relied on traditional acquisitions to gain new talent and capabilities, often acquiring startups specifically for their skilled teams (known as an acquihire) and/or their products or underlying technology, which can be expensive and time-consuming to develop and test in the market. But traditional acquisitions increasingly face scrutiny from antitrust regulators who are concerned about big companies reducing competition by buying out smaller ones. For example, the United States Federal Trade Commission sought to block Amazon’s acquisition of iRobot, prompting the companies to abandon the transaction in January 2024.\n",
      "\n",
      "\n",
      "Chunk #15\n",
      "Where things stand: Giving startups a lump sum and/or licensing fees in return for top talent and technology looks like the new normal for tech giants that are challenged to keep pace with rapidly advancing research and markets. But even arms-length arrangements don’t immunize tech giants and startups against regulatory investigation. Microsoft’s investment in Inflection AI was briefly scrutinized in Europe and is still being evaluated by U.S. regulators. Even Microsoft’s more traditional investment in OpenAI and the interests of Amazon and Google in Anthropic faced regulatory hurdles. So far, however, regulators have yet to conclude that any of these agreements violates antitrust law.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_article_chunks(article_text):\n",
    "    markdown_splitter = MarkdownTextSplitter(chunk_size = 2000, chunk_overlap = 200)\n",
    "    docs = markdown_splitter.split_text(article_text)\n",
    "    return docs\n",
    "\n",
    "\n",
    "docs = get_article_chunks(article_text)\n",
    "print(f\"Length of docs: {len(docs)}\")\n",
    "for i, doc in enumerate(docs):\n",
    "        print(f\"Chunk #{i + 1}\\n{doc}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Metadata Function (Article Link, Chunk Heading, Chunk Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Heading': 'Introduction', 'source': 0}, {'Heading': 'A Blizzard of Progress', 'source': 1}, {'Heading': 'Agents Ascendant', 'source': 2}, {'Heading': '- Throughout the year,', 'source': 3}, {'Heading': 'Prices Tumble', 'source': 4}, {'Heading': '- Makers of closed', 'source': 5}, {'Heading': 'Behind the news: Prominent', 'source': 6}, {'Heading': 'Generative Video Takes Off', 'source': 7}, {'Heading': '- Meta introduced Movie', 'source': 8}, {'Heading': 'Smaller Is Beautiful', 'source': 9}, {'Heading': '- The tide started', 'source': 10}, {'Heading': '- In 2006, Rich', 'source': 11}, {'Heading': 'Alternatives to Acquisitions', 'source': 12}, {'Heading': '- In October, Amazon', 'source': 13}, {'Heading': 'Where things stand: Giving', 'source': 14}]\n",
      "['id0', 'id1', 'id2', 'id3', 'id4', 'id5', 'id6', 'id7', 'id8', 'id9', 'id10', 'id11', 'id12', 'id13', 'id14']\n"
     ]
    }
   ],
   "source": [
    "def create_metadata(docs):\n",
    "    headings = []\n",
    "    chunk_index = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    for index, doc in enumerate(docs):\n",
    "        if doc.startswith('##'):\n",
    "            pattern = re.compile(r'^##\\s+(.*)$', re.MULTILINE)\n",
    "            match = pattern.search(doc)\n",
    "            heading = match.group(1)\n",
    "            headings.append(match.group(1))\n",
    "            metadatas.append({\"Heading\": heading, \"source\": index})\n",
    "        else:\n",
    "            words = doc.split()\n",
    "            first_four = words[:4]\n",
    "            heading = ' '.join(first_four)\n",
    "            headings.append(heading)\n",
    "            metadatas.append({\"Heading\": heading, \"source\": index})\n",
    "\n",
    "        chunk_index.append(f\"Chunk #{index}\")\n",
    "    # metadatas[\"Headings\"] = headings\n",
    "    # metadatas[\"Indexes\"] = chunk_index\n",
    "        ids.append(f\"id{index}\")\n",
    "    return metadatas, ids\n",
    "\n",
    "metadatas, ids = create_metadata(docs)\n",
    "# print(f\"Headings: \\n{metadatas[\"Headings\"]}\\n\\nChunk Indexes: \\n{metadatas[\"Indexes\"]}\")\n",
    "print(metadatas)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChromaDB Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name = \"article_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(ids = ids, metadatas = metadatas, documents = docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id0', 'id1', 'id2', 'id3', 'id4', 'id5', 'id6', 'id7', 'id8', 'id9'],\n",
       " 'embeddings': array([[-0.05990074, -0.09561614,  0.0620347 , ..., -0.1074878 ,\n",
       "         -0.02350325,  0.04333426],\n",
       "        [-0.02935752, -0.05063661, -0.01405945, ..., -0.04106434,\n",
       "         -0.07007962,  0.01929996],\n",
       "        [-0.05704041, -0.08026227, -0.04355863, ...,  0.03351628,\n",
       "          0.00378328, -0.0132593 ],\n",
       "        ...,\n",
       "        [-0.04937019, -0.07073288, -0.0320917 , ..., -0.02720085,\n",
       "          0.01391544,  0.0292466 ],\n",
       "        [-0.08720752, -0.0737434 , -0.00401154, ..., -0.04853952,\n",
       "          0.06667031,  0.03110035],\n",
       "        [ 0.03579304, -0.05337286,  0.07313617, ..., -0.06324023,\n",
       "         -0.00179799,  0.05418792]], shape=(10, 384)),\n",
       " 'documents': ['## Introduction\\nDear friends,\\nIs AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.\\nConsider this: GPT-4 was released March 2023. Since then, models have become much faster, cheaper, sometimes smaller, more multimodal, and better at reasoning, and many more open weight versions are available — so progress has been fantastic! (Claims that AI is “hitting a wall” seem extremely ill-informed.) But more significantly, many applications that\\xa0 already were theoretically possible using the March 2023 version of GPT-4 — in areas such as customer service, question answering, and process automation — now have significant early momentum.\\nI’m confident 2025 will see even faster and more exciting advances than 2024 in both AI technology and applications. Looking back, the one thing that could have stopped AI was bad, anti-competitive regulation that would have put onerous burdens on developers, particularly of open models. So long as we remain vigilant and hold off these anti-innovation forces, we’ll keep up or even further accelerate progress.\\nI’m also seeing a widening gap between those at the cutting edge (which includes many readers of The Batch !) and those who have not yet tried out ChatGPT even once (yes, a lot of people are still in this group!). As technology changes around us, we all have to keep up to remain relevant and be able to make significant contributions. I’m committed to making sure DeepLearning.AI continues to help you learn the most useful and important AI technologies. If you’re making New Year’s resolutions, I hope you’ll include us in your learning plan!\\nAI is the most important technological change happening in the world right now. I’m thrilled to be working in this exciting sector alongside you, and I’m grateful for your efforts to learn about and apply it to better the lives of yourself and others.\\nHappy holidays!\\nAndrew',\n",
       "  '## A Blizzard of Progress\\nWhat a year! AI made dramatic advances in 2024. Agentic systems improved their abilities to reason, use tools, and control desktop applications. Smaller models proliferated, many of them more capable and less expensive than their larger forbears. While some developments raised worries , far more sparked wonder and optimism. As in the waning days of earlier years , we invite you to pour a cup of hot cocoa and consider the high points of the last 12 months.',\n",
       "  '## Agents Ascendant\\nThe AI community laid the foundation for systems that can act by prompting large language models iteratively, leading to much higher performance across a range of applications.\\nWhat happened: AI gained a new buzzword — agentic — as researchers, tool vendors, and model builders equipped large language models (LLMs) to make choices and take actions to achieve goals. These developments set the stage for an upswell of agentic activity in the coming year and beyond.\\nDriving the story: Several tools emerged to help developers build agentic workflows.\\n- Microsoft primed the pump for agentic development tools in late 2023 with Autogen, an open source conversational framework that orchestrates collaboration among multiple agents. (Learn how to take advantage of it in our short course “ AI Agentic Design Patterns with Autogen .”) In late 2024, part of the Autogen team split off to build AG2 based on a fork of the code base.\\n- In October 2023, CrewAI released its open source Python framework for building and managing multi-agent systems. Agents can be assigned roles and goals, gain access to tools like web search, and collaborate with each other. (DeepLearning.AI’s short courses “ Multi-Agent Systems with crewAI ” and “ Practical Multi AI-Agents and Advanced Use Cases with crewAI ” can give you a fast start.)\\n- In January, LangChain, a provider of development tools, introduced LangGraph, which orchestrates agent behaviors using cyclical graphs. The framework enables LLM-driven agents to receive inputs, reason over them, decide on actions, use tools, evaluate the results, and repeat these steps to improve results. (Our short course “ AI Agents in LangGraph ” offers an introduction.)\\n- In September, Meta introduced Llama Stack for building agentic applications based on Llama models. Llama Stack provides memory, conversational skills, orchestration services, and ethical guardrails.',\n",
       "  '- Throughout the year, integrated development environments implemented agentic workflows to generate code. For instance, Devin and OpenHands accept natural-language instructions to generate prototype programs. Replit Agent, Vercel’s V0, and Bolt streamline projects by automatically writing code, fixing bugs, and managing dependencies.\\n- Meanwhile, a number of LLM makers supported agentic workflows by implementing tool use and function calling. Anthropic added computer use , enabling Claude 3.5 Sonnet to control users’ computers directly.\\n- Late in the year, OpenAI rolled out its o1 models and the processing-intensive o1 pro mode, which use agentic loops to work through prompts step by step. DeepSeek-R1 and Google Gemini 2.0 Flash Thinking Mode followed with similar agentic reasoning. In the final days of 2024, OpenAI announced o3 and o3-preview, which further extend o1’s agentic reasoning capabilities with impressive reported results.\\nBehind the news: Techniques for prompting LLMs in more sophisticated ways began to take off in 2022. They coalesced in moves toward agentic AI early this year. Foundational examples of this body of work include:\\n- Chain of Thought prompting, which asks LLMs to think step by step\\n- Self-consistency , which prompts a model to generate several responses and pick the one that’s most consistent with the others\\n- ReAc t, which interleaves reasoning and action steps to accomplish a goal\\n- Self-Refine , which enables an agent to reflect on its own output\\n- Reflexion , which enables a model to act, evaluate, reflect, and repeat.\\n- Test-time compute , which increases the amount of processing power allotted to inference\\nWhere things stand: The agentic era is upon us! Regardless of how well scaling laws continue to drive improved performance of foundation models, agentic workflows are making AI systems increasingly helpful, efficient, and personalized.',\n",
       "  '## Prices Tumble\\nFierce competition among model makers and cloud providers drove down the price of access to state-of-the-art models.\\nWhat happened: AI providers waged a price war to attract paying customers. A leading indicator: From March 2023 to November 2024, OpenAI cut the per-token prices of cloud access to its models by nearly 90 percent even as performance improved, input context windows expanded, and the models became capable of processing images as well as text.\\nDriving the story: Factors that pushed down prices include open source, more compute-efficient models, and excitement around agentic workflows that consume more tokens at inference. OpenAI’s GPT-4 Turbo set a baseline when it debuted in late 2023 at $10.00/$30.00 per million tokens of input/output. Top model makers slashed prices in turn: Google and OpenAI at the higher end of the market, companies in China at the lower end, and Amazon at both. Meanwhile, startups with specialized hardware offered open models at prices that dramatically undercut the giants.\\n- Competitive models with open weights helped drive prices down by enabling cloud providers to offer high-performance models without bearing the cost of developing or licensing them. Meta released Llama 3 70B in April, and various cloud providers offered it at an average price of $0.78/$0.95 per million input/output tokens. Llama 3.1 405B followed in July 2024; Microsoft Azure priced it at almost half the price of GPT-4 Turbo ($5.33/$16.00).\\n- Per-token prices for open weights models tumbled in China. In May, DeepSeek released DeepSeek V2 and soon dropped the price to $0.14/$0.28 per million tokens of input/output. Alibaba, Baidu, and Bytedance slashed prices for Qwen-Long ($0.06/$0.06), Ernie-Speed and Ernie-Lite (free), and Doubau ($0.11/$0.11) respectively.',\n",
       "  '- Makers of closed models outdid one another with lower and lower prices. In May, OpenAI introduced GPT-4o at $5.00/$15.00 per million tokens of input/output, half as much as GPT-4 Turbo. By August, GPT-4o cost $2.50/$10.00 and the newer GPT-4o mini cost $0.15/$0.60 (half as much for jobs with slower turnaround times).\\n- Google ultimately cut the price of Gemini 1.5 Pro to $1.25/$5.00 per million input/output tokens (twice as much for prompts longer than 128,000 tokens) and slashed Gemini 1.5 Flash to $0.075/$0.30 per million input/output tokens (twice as much for prompts longer than 128,000 tokens). As of this writing, Gemini 2.0 Flash is free to use as an experimental preview, and API prices have not been announced.\\n- In December, Amazon introduced the Nova family of LLMs. At launch, Nova Pro ($0.80/$3.20 per million tokens of input/output) cost much less than top models from OpenAI or Google, while Nova Lite ($0.06/$0.24) and Nova Micro ($0.035/$0.14 respectively) cost much less than GPT-4o mini. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)\\n- Even as model providers cut their prices, startups including Cerebrus, Groq, and SambaNova designed specialized chips that enabled them to serve open weights models faster and more cheaply. For example, SambaNova offered Llama 3.1 405B for $5.00/$10.00 per million tokens of input/output, processing a blazing 132 tokens per second. DeepInfra offered the same model at a slower speed for as little as $2.70/$2.70.\\nYes, but: The trend toward more processing-intensive models is challenged but not dead. In September, OpenAI introduced token-hungry models with relatively hefty price tags: o1-preview ($15.00/$60.00 per million tokens input/output) and o1-mini ($3.00/$12.00). In December, o1 arrived with a more accurate pro mode that’s available only to subscribers who are willing to pay $200 per month.',\n",
       "  'Behind the news: Prominent members of the AI community pushed against regulations that threatened to restrict open source models, which played an important role in bringing down prices. Opposition by developers helped to block California SB 1047, a proposed law that would have held developers of models above certain size limits liable for unintended harms caused by their models and required a “kill switch” that would enable developers to disable them — a problematic requirement for open weights models that anyone could modify and deploy. California Governor Gavin Newsom vetoed the bill in October.\\nWhere things stand: Falling prices are a sign of a healthy tech ecosystem. It’s likely that in-demand models will always fetch relatively high prices, but the market is increasingly priced in pennies, not dollars, per million tokens.',\n",
       "  '## Generative Video Takes Off\\nVideo generation exploded in an abundance of powerful models.\\nWhat happened: Companies big and small introduced new or updated text-to-video generators. Some added image-to-video and/or video-to-video capabilities. While most models focus on generating cinematic clips, some specialize in videos for social media.\\nDriving the story: Even at the extraordinary pace of AI lately, video generators in the past year matured with remarkable speed. Virtually every major model produces convincing, highly detailed scenes, both realistic and fantastical, while ramping up image resolution, speed, output length, and users’ ability to control their outputs.\\n- OpenAI Sora set a high bar early in the year. Introduced in February and shown privately to Hollywood creators, it built a formidable buzz despite being available to only selected users. Unauthorized users gained access in November, and OpenAI made the model available the following month. Built on a diffusion transformer , Sora generates consistent (if somewhat dreamlike) scenes of up to 1 minute long.\\n- Runway Gen 3 Alpha and Gen 3 Alpha Turbo improved on their predecessors, generating higher-resolution videos (up to 1,280x768-pixel resolution) and introducing an API. Runway struck a deal with the film studio Lionsgate, which will use a custom version fine-tuned on its archive for visual effects and pre-visualizations.\\n- Adobe took a different approach with its Firefly Video model. In addition to offering a web application, the company incorporated the model directly into its best-selling Adobe Premiere Pro video editing suite. The integration enables video artists to generate clips, extend or enhance existing ones, and add effects within the program.',\n",
       "  '- Meta introduced Movie Gen , a suite of four systems. While its video output rivals that of competitors, it stands out especially for its ability to generate soundtracks. One system produces sound effects and music that match video. Another specializes in producing videos in which characters’ faces remain consistent, and another performs video-to-video alterations. Movie Gen will be available on Instagram in 2025.\\n- Model builders in China tailored their models for producing social media. Kling AI emphasized making TikTok and Instagram Reels. PixVerse and Jimeng AI likewise introduced video generators designed for social media users. In October, TikTok’s parent ByteDance added two video generation models, PixelDance and Seaweed, that produce 10-second and 30-second clips respectively.\\nBehind the news: Video generation is already reshaping the movie industry. In February, after seeing a preview of Sora, American filmmaker Tyler Perry halted a planned expansion of his production studio, arguing that within a few years, AI video could put traditional studios out of business. Members of the video graphics team at The Late Show with Stephen Colbert use Runway’s technology to add special effects to conventional digital video, cutting editing time from hours to minutes.\\nWhere things stand: Video generation came a long way in 2024, but there’s still plenty of room for improvement. Because most models only generate a small number of frames at a time, they can struggle to track physics and geometry and to generate consistent characters and scenery over time. The computational demands of maintaining consistency across frames means that generated clips are brief. And even short outputs take substantial time and resources to generate: Sora can take 10 to 20 minutes to render clips as short as 3 seconds. OpenAI and Runway released faster versions — Sora Turbo and Gen-3 Alpha Turbo — to address the challenge.',\n",
       "  '## Smaller Is Beautiful\\nFor years, the best AI models got bigger and bigger. But in 2024, some popular large language models were small enough to run on a smartphone.\\nWhat happened : Instead of putting all their resources into building big models, top AI companies promoted families of large language models that offer a choice of small, medium, and large. Model families such as Microsoft Phi-3 (in versions of roughly 3.8 billion, 7 billion, and 14 billion parameters), Google Gemma 2 (2 billion, 9 billion, and 27 billion), and Hugging Face SmolLM (135 million, 360 million, and 1.7 billion) specialize in small.\\nDriving the story: Smaller models have become more capable thanks to techniques like knowledge distillation (in which a larger teacher model is used to train a smaller student model to match its output), parameter pruning (which removes less-influential parameters), quantization (which reduces neural network sizes by representing each parameter with fewer bits), and greater attention to curating training sets for data quality. Beyond performance, speed, and price, the ability to run on relatively low-powered hardware is a competitive advantage for a variety of uses.\\n- Model builders have offered model families that include members of various sizes since at least 2019, when Google introduced the T5 family (five models between roughly 77 million parameters and 11 billion parameters). The success of OpenAI’s GPT series, which over time grew from 117 million parameters to a hypothesized 1.76 trillion parameters, demonstrated the power of bigger models. OpenAI researchers formulated scaling laws that appeared to guarantee that bigger models, training sets, and compute budgets would lead to predictable improvements in performance. This finding spurred rivals to build larger and larger models.\\n- The tide started to turn in early 2023. Meta’s Llama 2 came in parameter counts of roughly 7 billion, 13 billion, and 70 billion with open weights.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'Chunk Index': 0, 'Heading': 'Introduction'},\n",
       "  {'Chunk Index': 1, 'Heading': 'A Blizzard of Progress'},\n",
       "  {'Chunk Index': 2, 'Heading': 'Agents Ascendant'},\n",
       "  {'Chunk Index': 3, 'Heading': '- Throughout the year,'},\n",
       "  {'Chunk Index': 4, 'Heading': 'Prices Tumble'},\n",
       "  {'Chunk Index': 5, 'Heading': '- Makers of closed'},\n",
       "  {'Chunk Index': 6, 'Heading': 'Behind the news: Prominent'},\n",
       "  {'Chunk Index': 7, 'Heading': 'Generative Video Takes Off'},\n",
       "  {'Chunk Index': 8, 'Heading': '- Meta introduced Movie'},\n",
       "  {'Chunk Index': 9, 'Heading': 'Smaller Is Beautiful'}],\n",
       " 'included': [<IncludeEnum.embeddings: 'embeddings'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id2', 'id1', 'id0']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['## Agents Ascendant\\nThe AI community laid the foundation for systems that can act by prompting large language models iteratively, leading to much higher performance across a range of applications.\\nWhat happened: AI gained a new buzzword — agentic — as researchers, tool vendors, and model builders equipped large language models (LLMs) to make choices and take actions to achieve goals. These developments set the stage for an upswell of agentic activity in the coming year and beyond.\\nDriving the story: Several tools emerged to help developers build agentic workflows.\\n- Microsoft primed the pump for agentic development tools in late 2023 with Autogen, an open source conversational framework that orchestrates collaboration among multiple agents. (Learn how to take advantage of it in our short course “ AI Agentic Design Patterns with Autogen .”) In late 2024, part of the Autogen team split off to build AG2 based on a fork of the code base.\\n- In October 2023, CrewAI released its open source Python framework for building and managing multi-agent systems. Agents can be assigned roles and goals, gain access to tools like web search, and collaborate with each other. (DeepLearning.AI’s short courses “ Multi-Agent Systems with crewAI ” and “ Practical Multi AI-Agents and Advanced Use Cases with crewAI ” can give you a fast start.)\\n- In January, LangChain, a provider of development tools, introduced LangGraph, which orchestrates agent behaviors using cyclical graphs. The framework enables LLM-driven agents to receive inputs, reason over them, decide on actions, use tools, evaluate the results, and repeat these steps to improve results. (Our short course “ AI Agents in LangGraph ” offers an introduction.)\\n- In September, Meta introduced Llama Stack for building agentic applications based on Llama models. Llama Stack provides memory, conversational skills, orchestration services, and ethical guardrails.',\n",
       "   '## A Blizzard of Progress\\nWhat a year! AI made dramatic advances in 2024. Agentic systems improved their abilities to reason, use tools, and control desktop applications. Smaller models proliferated, many of them more capable and less expensive than their larger forbears. While some developments raised worries , far more sparked wonder and optimism. As in the waning days of earlier years , we invite you to pour a cup of hot cocoa and consider the high points of the last 12 months.',\n",
       "   '## Introduction\\nDear friends,\\nIs AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.\\nConsider this: GPT-4 was released March 2023. Since then, models have become much faster, cheaper, sometimes smaller, more multimodal, and better at reasoning, and many more open weight versions are available — so progress has been fantastic! (Claims that AI is “hitting a wall” seem extremely ill-informed.) But more significantly, many applications that\\xa0 already were theoretically possible using the March 2023 version of GPT-4 — in areas such as customer service, question answering, and process automation — now have significant early momentum.\\nI’m confident 2025 will see even faster and more exciting advances than 2024 in both AI technology and applications. Looking back, the one thing that could have stopped AI was bad, anti-competitive regulation that would have put onerous burdens on developers, particularly of open models. So long as we remain vigilant and hold off these anti-innovation forces, we’ll keep up or even further accelerate progress.\\nI’m also seeing a widening gap between those at the cutting edge (which includes many readers of The Batch !) and those who have not yet tried out ChatGPT even once (yes, a lot of people are still in this group!). As technology changes around us, we all have to keep up to remain relevant and be able to make significant contributions. I’m committed to making sure DeepLearning.AI continues to help you learn the most useful and important AI technologies. If you’re making New Year’s resolutions, I hope you’ll include us in your learning plan!\\nAI is the most important technological change happening in the world right now. I’m thrilled to be working in this exciting sector alongside you, and I’m grateful for your efforts to learn about and apply it to better the lives of yourself and others.\\nHappy holidays!\\nAndrew']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'Chunk Index': 2, 'Heading': 'Agents Ascendant'},\n",
       "   {'Chunk Index': 1, 'Heading': 'A Blizzard of Progress'},\n",
       "   {'Chunk Index': 0, 'Heading': 'Introduction'}]],\n",
       " 'distances': [[0.9427493214607239, 1.0356221199035645, 1.1276569366455078]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = collection.query(\n",
    "    query_texts=[\"What is the new buzzword in AI?\"],\n",
    "    n_results=3,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"},\n",
    "    # where_document={\"$contains\":\"search_string\"}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Agents Ascendant\n",
      "The AI community laid the foundation for systems that can act by prompting large language models iteratively, leading to much higher performance across a range of applications.\n",
      "What happened: AI gained a new buzzword — agentic — as researchers, tool vendors, and model builders equipped large language models (LLMs) to make choices and take actions to achieve goals. These developments set the stage for an upswell of agentic activity in the coming year and beyond.\n",
      "Driving the story: Several tools emerged to help developers build agentic workflows.\n",
      "- Microsoft primed the pump for agentic development tools in late 2023 with Autogen, an open source conversational framework that orchestrates collaboration among multiple agents. (Learn how to take advantage of it in our short course “ AI Agentic Design Patterns with Autogen .”) In late 2024, part of the Autogen team split off to build AG2 based on a fork of the code base.\n",
      "- In October 2023, CrewAI released its open source Python framework for building and managing multi-agent systems. Agents can be assigned roles and goals, gain access to tools like web search, and collaborate with each other. (DeepLearning.AI’s short courses “ Multi-Agent Systems with crewAI ” and “ Practical Multi AI-Agents and Advanced Use Cases with crewAI ” can give you a fast start.)\n",
      "- In January, LangChain, a provider of development tools, introduced LangGraph, which orchestrates agent behaviors using cyclical graphs. The framework enables LLM-driven agents to receive inputs, reason over them, decide on actions, use tools, evaluate the results, and repeat these steps to improve results. (Our short course “ AI Agents in LangGraph ” offers an introduction.)\n",
      "- In September, Meta introduced Llama Stack for building agentic applications based on Llama models. Llama Stack provides memory, conversational skills, orchestration services, and ethical guardrails.\n",
      "\n",
      "\n",
      "## A Blizzard of Progress\n",
      "What a year! AI made dramatic advances in 2024. Agentic systems improved their abilities to reason, use tools, and control desktop applications. Smaller models proliferated, many of them more capable and less expensive than their larger forbears. While some developments raised worries , far more sparked wonder and optimism. As in the waning days of earlier years , we invite you to pour a cup of hot cocoa and consider the high points of the last 12 months.\n",
      "\n",
      "\n",
      "## Introduction\n",
      "Dear friends,\n",
      "Is AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.\n",
      "Consider this: GPT-4 was released March 2023. Since then, models have become much faster, cheaper, sometimes smaller, more multimodal, and better at reasoning, and many more open weight versions are available — so progress has been fantastic! (Claims that AI is “hitting a wall” seem extremely ill-informed.) But more significantly, many applications that  already were theoretically possible using the March 2023 version of GPT-4 — in areas such as customer service, question answering, and process automation — now have significant early momentum.\n",
      "I’m confident 2025 will see even faster and more exciting advances than 2024 in both AI technology and applications. Looking back, the one thing that could have stopped AI was bad, anti-competitive regulation that would have put onerous burdens on developers, particularly of open models. So long as we remain vigilant and hold off these anti-innovation forces, we’ll keep up or even further accelerate progress.\n",
      "I’m also seeing a widening gap between those at the cutting edge (which includes many readers of The Batch !) and those who have not yet tried out ChatGPT even once (yes, a lot of people are still in this group!). As technology changes around us, we all have to keep up to remain relevant and be able to make significant contributions. I’m committed to making sure DeepLearning.AI continues to help you learn the most useful and important AI technologies. If you’re making New Year’s resolutions, I hope you’ll include us in your learning plan!\n",
      "AI is the most important technological change happening in the world right now. I’m thrilled to be working in this exciting sector alongside you, and I’m grateful for your efforts to learn about and apply it to better the lives of yourself and others.\n",
      "Happy holidays!\n",
      "Andrew\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in response['documents'][0]:\n",
    "    print(f\"{doc}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChromaDB Stuff using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-3-small\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"my_collection\",\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id0',\n",
       " 'id1',\n",
       " 'id2',\n",
       " 'id3',\n",
       " 'id4',\n",
       " 'id5',\n",
       " 'id6',\n",
       " 'id7',\n",
       " 'id8',\n",
       " 'id9',\n",
       " 'id10',\n",
       " 'id11',\n",
       " 'id12',\n",
       " 'id13',\n",
       " 'id14']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_texts(texts=docs, ids=ids, metadatas=metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id0', 'id1', 'id2', 'id3', 'id4'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['## Introduction\\nDear friends,\\nIs AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.\\nConsider this: GPT-4 was released March 2023. Since then, models have become much faster, cheaper, sometimes smaller, more multimodal, and better at reasoning, and many more open weight versions are available — so progress has been fantastic! (Claims that AI is “hitting a wall” seem extremely ill-informed.) But more significantly, many applications that\\xa0 already were theoretically possible using the March 2023 version of GPT-4 — in areas such as customer service, question answering, and process automation — now have significant early momentum.\\nI’m confident 2025 will see even faster and more exciting advances than 2024 in both AI technology and applications. Looking back, the one thing that could have stopped AI was bad, anti-competitive regulation that would have put onerous burdens on developers, particularly of open models. So long as we remain vigilant and hold off these anti-innovation forces, we’ll keep up or even further accelerate progress.\\nI’m also seeing a widening gap between those at the cutting edge (which includes many readers of The Batch !) and those who have not yet tried out ChatGPT even once (yes, a lot of people are still in this group!). As technology changes around us, we all have to keep up to remain relevant and be able to make significant contributions. I’m committed to making sure DeepLearning.AI continues to help you learn the most useful and important AI technologies. If you’re making New Year’s resolutions, I hope you’ll include us in your learning plan!\\nAI is the most important technological change happening in the world right now. I’m thrilled to be working in this exciting sector alongside you, and I’m grateful for your efforts to learn about and apply it to better the lives of yourself and others.\\nHappy holidays!\\nAndrew',\n",
       "  '## A Blizzard of Progress\\nWhat a year! AI made dramatic advances in 2024. Agentic systems improved their abilities to reason, use tools, and control desktop applications. Smaller models proliferated, many of them more capable and less expensive than their larger forbears. While some developments raised worries , far more sparked wonder and optimism. As in the waning days of earlier years , we invite you to pour a cup of hot cocoa and consider the high points of the last 12 months.',\n",
       "  '## Agents Ascendant\\nThe AI community laid the foundation for systems that can act by prompting large language models iteratively, leading to much higher performance across a range of applications.\\nWhat happened: AI gained a new buzzword — agentic — as researchers, tool vendors, and model builders equipped large language models (LLMs) to make choices and take actions to achieve goals. These developments set the stage for an upswell of agentic activity in the coming year and beyond.\\nDriving the story: Several tools emerged to help developers build agentic workflows.\\n- Microsoft primed the pump for agentic development tools in late 2023 with Autogen, an open source conversational framework that orchestrates collaboration among multiple agents. (Learn how to take advantage of it in our short course “ AI Agentic Design Patterns with Autogen .”) In late 2024, part of the Autogen team split off to build AG2 based on a fork of the code base.\\n- In October 2023, CrewAI released its open source Python framework for building and managing multi-agent systems. Agents can be assigned roles and goals, gain access to tools like web search, and collaborate with each other. (DeepLearning.AI’s short courses “ Multi-Agent Systems with crewAI ” and “ Practical Multi AI-Agents and Advanced Use Cases with crewAI ” can give you a fast start.)\\n- In January, LangChain, a provider of development tools, introduced LangGraph, which orchestrates agent behaviors using cyclical graphs. The framework enables LLM-driven agents to receive inputs, reason over them, decide on actions, use tools, evaluate the results, and repeat these steps to improve results. (Our short course “ AI Agents in LangGraph ” offers an introduction.)\\n- In September, Meta introduced Llama Stack for building agentic applications based on Llama models. Llama Stack provides memory, conversational skills, orchestration services, and ethical guardrails.',\n",
       "  '- Throughout the year, integrated development environments implemented agentic workflows to generate code. For instance, Devin and OpenHands accept natural-language instructions to generate prototype programs. Replit Agent, Vercel’s V0, and Bolt streamline projects by automatically writing code, fixing bugs, and managing dependencies.\\n- Meanwhile, a number of LLM makers supported agentic workflows by implementing tool use and function calling. Anthropic added computer use , enabling Claude 3.5 Sonnet to control users’ computers directly.\\n- Late in the year, OpenAI rolled out its o1 models and the processing-intensive o1 pro mode, which use agentic loops to work through prompts step by step. DeepSeek-R1 and Google Gemini 2.0 Flash Thinking Mode followed with similar agentic reasoning. In the final days of 2024, OpenAI announced o3 and o3-preview, which further extend o1’s agentic reasoning capabilities with impressive reported results.\\nBehind the news: Techniques for prompting LLMs in more sophisticated ways began to take off in 2022. They coalesced in moves toward agentic AI early this year. Foundational examples of this body of work include:\\n- Chain of Thought prompting, which asks LLMs to think step by step\\n- Self-consistency , which prompts a model to generate several responses and pick the one that’s most consistent with the others\\n- ReAc t, which interleaves reasoning and action steps to accomplish a goal\\n- Self-Refine , which enables an agent to reflect on its own output\\n- Reflexion , which enables a model to act, evaluate, reflect, and repeat.\\n- Test-time compute , which increases the amount of processing power allotted to inference\\nWhere things stand: The agentic era is upon us! Regardless of how well scaling laws continue to drive improved performance of foundation models, agentic workflows are making AI systems increasingly helpful, efficient, and personalized.',\n",
       "  '## Prices Tumble\\nFierce competition among model makers and cloud providers drove down the price of access to state-of-the-art models.\\nWhat happened: AI providers waged a price war to attract paying customers. A leading indicator: From March 2023 to November 2024, OpenAI cut the per-token prices of cloud access to its models by nearly 90 percent even as performance improved, input context windows expanded, and the models became capable of processing images as well as text.\\nDriving the story: Factors that pushed down prices include open source, more compute-efficient models, and excitement around agentic workflows that consume more tokens at inference. OpenAI’s GPT-4 Turbo set a baseline when it debuted in late 2023 at $10.00/$30.00 per million tokens of input/output. Top model makers slashed prices in turn: Google and OpenAI at the higher end of the market, companies in China at the lower end, and Amazon at both. Meanwhile, startups with specialized hardware offered open models at prices that dramatically undercut the giants.\\n- Competitive models with open weights helped drive prices down by enabling cloud providers to offer high-performance models without bearing the cost of developing or licensing them. Meta released Llama 3 70B in April, and various cloud providers offered it at an average price of $0.78/$0.95 per million input/output tokens. Llama 3.1 405B followed in July 2024; Microsoft Azure priced it at almost half the price of GPT-4 Turbo ($5.33/$16.00).\\n- Per-token prices for open weights models tumbled in China. In May, DeepSeek released DeepSeek V2 and soon dropped the price to $0.14/$0.28 per million tokens of input/output. Alibaba, Baidu, and Bytedance slashed prices for Qwen-Long ($0.06/$0.06), Ernie-Speed and Ernie-Lite (free), and Doubau ($0.11/$0.11) respectively.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'Chunk Index': 0, 'Heading': 'Introduction', 'source': 0},\n",
       "  {'Chunk Index': 1, 'Heading': 'A Blizzard of Progress', 'source': 1},\n",
       "  {'Chunk Index': 2, 'Heading': 'Agents Ascendant', 'source': 2},\n",
       "  {'Chunk Index': 3, 'Heading': '- Throughout the year,', 'source': 3},\n",
       "  {'Chunk Index': 4, 'Heading': 'Prices Tumble', 'source': 4}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get(ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* ## Agents Ascendant\n",
      "The AI community laid the foundation for systems that can act by prompting large language models iteratively, leading to much higher performance across a range of applications.\n",
      "What happened: AI gained a new buzzword — agentic — as researchers, tool vendors, and model builders equipped large language models (LLMs) to make choices and take actions to achieve goals. These developments set the stage for an upswell of agentic activity in the coming year and beyond.\n",
      "Driving the story: Several tools emerged to help developers build agentic workflows.\n",
      "- Microsoft primed the pump for agentic development tools in late 2023 with Autogen, an open source conversational framework that orchestrates collaboration among multiple agents. (Learn how to take advantage of it in our short course “ AI Agentic Design Patterns with Autogen .”) In late 2024, part of the Autogen team split off to build AG2 based on a fork of the code base.\n",
      "- In October 2023, CrewAI released its open source Python framework for building and managing multi-agent systems. Agents can be assigned roles and goals, gain access to tools like web search, and collaborate with each other. (DeepLearning.AI’s short courses “ Multi-Agent Systems with crewAI ” and “ Practical Multi AI-Agents and Advanced Use Cases with crewAI ” can give you a fast start.)\n",
      "- In January, LangChain, a provider of development tools, introduced LangGraph, which orchestrates agent behaviors using cyclical graphs. The framework enables LLM-driven agents to receive inputs, reason over them, decide on actions, use tools, evaluate the results, and repeat these steps to improve results. (Our short course “ AI Agents in LangGraph ” offers an introduction.)\n",
      "- In September, Meta introduced Llama Stack for building agentic applications based on Llama models. Llama Stack provides memory, conversational skills, orchestration services, and ethical guardrails.\n",
      "* - Throughout the year, integrated development environments implemented agentic workflows to generate code. For instance, Devin and OpenHands accept natural-language instructions to generate prototype programs. Replit Agent, Vercel’s V0, and Bolt streamline projects by automatically writing code, fixing bugs, and managing dependencies.\n",
      "- Meanwhile, a number of LLM makers supported agentic workflows by implementing tool use and function calling. Anthropic added computer use , enabling Claude 3.5 Sonnet to control users’ computers directly.\n",
      "- Late in the year, OpenAI rolled out its o1 models and the processing-intensive o1 pro mode, which use agentic loops to work through prompts step by step. DeepSeek-R1 and Google Gemini 2.0 Flash Thinking Mode followed with similar agentic reasoning. In the final days of 2024, OpenAI announced o3 and o3-preview, which further extend o1’s agentic reasoning capabilities with impressive reported results.\n",
      "Behind the news: Techniques for prompting LLMs in more sophisticated ways began to take off in 2022. They coalesced in moves toward agentic AI early this year. Foundational examples of this body of work include:\n",
      "- Chain of Thought prompting, which asks LLMs to think step by step\n",
      "- Self-consistency , which prompts a model to generate several responses and pick the one that’s most consistent with the others\n",
      "- ReAc t, which interleaves reasoning and action steps to accomplish a goal\n",
      "- Self-Refine , which enables an agent to reflect on its own output\n",
      "- Reflexion , which enables a model to act, evaluate, reflect, and repeat.\n",
      "- Test-time compute , which increases the amount of processing power allotted to inference\n",
      "Where things stand: The agentic era is upon us! Regardless of how well scaling laws continue to drive improved performance of foundation models, agentic workflows are making AI systems increasingly helpful, efficient, and personalized.\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"What is the new buzzword in AI?\",\n",
    "    k = 2\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Agents Ascendant\n",
      "The AI community laid the foundation for systems that can act by prompting large language models iteratively, leading to much higher performance across a range of applications.\n",
      "What happened: AI gained a new buzzword — agentic — as researchers, tool vendors, and model builders equipped large language models (LLMs) to make choices and take actions to achieve goals. These developments set the stage for an upswell of agentic activity in the coming year and beyond.\n",
      "Driving the story: Several tools emerged to help developers build agentic workflows.\n",
      "- Microsoft primed the pump for agentic development tools in late 2023 with Autogen, an open source conversational framework that orchestrates collaboration among multiple agents. (Learn how to take advantage of it in our short course “ AI Agentic Design Patterns with Autogen .”) In late 2024, part of the Autogen team split off to build AG2 based on a fork of the code base.\n",
      "- In October 2023, CrewAI released its open source Python framework for building and managing multi-agent systems. Agents can be assigned roles and goals, gain access to tools like web search, and collaborate with each other. (DeepLearning.AI’s short courses “ Multi-Agent Systems with crewAI ” and “ Practical Multi AI-Agents and Advanced Use Cases with crewAI ” can give you a fast start.)\n",
      "- In January, LangChain, a provider of development tools, introduced LangGraph, which orchestrates agent behaviors using cyclical graphs. The framework enables LLM-driven agents to receive inputs, reason over them, decide on actions, use tools, evaluate the results, and repeat these steps to improve results. (Our short course “ AI Agents in LangGraph ” offers an introduction.)\n",
      "- In September, Meta introduced Llama Stack for building agentic applications based on Llama models. Llama Stack provides memory, conversational skills, orchestration services, and ethical guardrails.\n",
      "0.555881\n",
      "\n",
      "\n",
      "- Throughout the year, integrated development environments implemented agentic workflows to generate code. For instance, Devin and OpenHands accept natural-language instructions to generate prototype programs. Replit Agent, Vercel’s V0, and Bolt streamline projects by automatically writing code, fixing bugs, and managing dependencies.\n",
      "- Meanwhile, a number of LLM makers supported agentic workflows by implementing tool use and function calling. Anthropic added computer use , enabling Claude 3.5 Sonnet to control users’ computers directly.\n",
      "- Late in the year, OpenAI rolled out its o1 models and the processing-intensive o1 pro mode, which use agentic loops to work through prompts step by step. DeepSeek-R1 and Google Gemini 2.0 Flash Thinking Mode followed with similar agentic reasoning. In the final days of 2024, OpenAI announced o3 and o3-preview, which further extend o1’s agentic reasoning capabilities with impressive reported results.\n",
      "Behind the news: Techniques for prompting LLMs in more sophisticated ways began to take off in 2022. They coalesced in moves toward agentic AI early this year. Foundational examples of this body of work include:\n",
      "- Chain of Thought prompting, which asks LLMs to think step by step\n",
      "- Self-consistency , which prompts a model to generate several responses and pick the one that’s most consistent with the others\n",
      "- ReAc t, which interleaves reasoning and action steps to accomplish a goal\n",
      "- Self-Refine , which enables an agent to reflect on its own output\n",
      "- Reflexion , which enables a model to act, evaluate, reflect, and repeat.\n",
      "- Test-time compute , which increases the amount of processing power allotted to inference\n",
      "Where things stand: The agentic era is upon us! Regardless of how well scaling laws continue to drive improved performance of foundation models, agentic workflows are making AI systems increasingly helpful, efficient, and personalized.\n",
      "0.597668\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"What tools were introduced to create agentic AI applications?\",\n",
    "    k = 2\n",
    ")\n",
    "\n",
    "for res, score in results:\n",
    "    print(f\"{res.page_content}\\n{score:3f}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_llm(llm = llm, retriever=vector_store.as_retriever())\n",
    "\n",
    "query = \"Summarize the article\"\n",
    "\n",
    "response = chain.invoke({\"question\": query}, return_only_outputs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article discusses significant advancements in AI throughout 2024, highlighting improvements in agentic systems that enhance reasoning and tool usage. Smaller, more capable AI models have emerged, and applications in customer service and process automation are gaining momentum. The author expresses optimism for further advancements in 2025, despite concerns about regulatory challenges. Key developments include new frameworks for multi-agent collaboration from Microsoft and CrewAI, and partnerships between major tech companies and AI startups to access cutting-edge technology and talent. Overall, the article emphasizes the rapid evolution of AI and encourages ongoing learning in this field.\\n\\n'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses significant advancements in AI throughout 2024, highlighting improvements in agentic systems that enhance reasoning and tool usage. Smaller, more capable AI models have emerged, and applications in customer service and process automation are gaining momentum. The author expresses optimism for further advancements in 2025, despite concerns about regulatory challenges. Key developments include new frameworks for multi-agent collaboration from Microsoft and CrewAI, and partnerships between major tech companies and AI startups to access cutting-edge technology and talent. Overall, the article emphasizes the rapid evolution of AI and encourages ongoing learning in this field.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'].format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The article discusses significant advancements in AI throughout 2024, highlighting improvements in agentic systems that enhance reasoning and tool usage. Smaller, more capable AI models have emerged, and applications in customer service and process automation are gaining momentum. The author expresses optimism for further advancements in 2025, despite concerns about regulatory challenges. Key developments include new frameworks for multi-agent collaboration from Microsoft and CrewAI, and partnerships between major tech companies and AI startups to access cutting-edge technology and talent. Overall, the article emphasizes the rapid evolution of AI and encourages ongoing learning in this field.\\n\\n',\n",
       " 'sources': '1, 0, 2, 12'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Generic Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Articles' Links Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><title>The Batch | DeepLearning.AI | AI News &amp; Insights</title><meta name=\"description\" content=\"Weekly AI news for engineers, executives, and enthusiasts.\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><link rel=\"canonical\" href=\"https://www.deeplearning.ai/the-batch/\"/><meta property=\"og:type\" content=\"website\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><meta property=\"og:title\" content=\"The Batch | DeepLearning.AI | AI News &amp; Insights\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><meta property=\"og:description\" content=\"Weekly AI news for engineers, executives, and enthusiasts.\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><meta property=\"og:site_name\" content=\"The Batch | DeepLearning.AI | AI News &amp; Insights\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><meta property=\"og:url\" content=\"https://www.deeplearning.ai/the-batch/\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><meta property=\"twitter:title\" content=\"The Batch | DeepLearning.AI | AI News &amp; Insights\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><meta property=\"twitter:description\" content=\"Weekly AI news for engineers, executives, and enthusiasts.\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><meta property=\"twitter:url\" content=\"https://www.deeplearning.ai/the-batch/\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><meta property=\"twitter:card\" content=\"summary_large_image\" data-sentry-element=\"meta\" data-sentry-source-file=\"seo.tsx\"/><meta property=\"twitter:creator\" content=\"@DeepLearningAI\"/><meta property=\"twitter:site\" content=\"https://twitter.com/DeepLearningAI/\"/><meta name=\"twitter:image\" content=\"https://www.deeplearning.ai/site-meta.png\"/><meta property=\"og:image\" content=\"https://www.deeplearning.ai/site-meta.png\"/><meta property=\"og:image:width\" content=\"2048\"/><meta property=\"og:image:height\" content=\"1024\"/><script type=\"application/ld+json\">{\"@context\":\"https://schema.org/\",\"@type\":\"WebSite\",\"image\":{\"@type\":\"ImageObject\",\"url\":\"https://www.deeplearning.ai/site-meta.png\",\"width\":2048,\"height\":1024},\"publisher\":{\"@type\":\"Organization\",\"name\":\"The Batch | DeepLearning.AI | AI News & Insights\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png\",\"width\":60,\"height\":60}},\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://www.deeplearning.ai\"},\"description\":\"Weekly AI news for engineers, executives, and enthusiasts.\"}</script><meta name=\"next-head-count\" content=\"21\"/><link href=\"/static/favicons/favicon.ico\" rel=\"shortcut icon\"/><link rel=\"stylesheet\" data-href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap\"/><link rel=\"stylesheet\" data-href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap\"/><link rel=\"preload\" href=\"/_next/static/css/7adbf46a6d669572.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/7adbf46a6d669572.css\" data-n-g=\"\"/><link rel=\"preload\" href=\"/_next/static/css/50b31a8e13f731be.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/50b31a8e13f731be.css\" data-n-p=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-7690c02358b700f2.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-966363d4ce7dc58a.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-4fbf91706d1267b7.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-05c3c0770e43c5a8.js\" defer=\"\"></script><script src=\"/_next/static/chunks/3a17f596-c0003e14321dd27f.js\" defer=\"\"></script><script src=\"/_next/static/chunks/36d2f571-b2b09c00a6769bbb.js\" defer=\"\"></script><script src=\"/_next/static/chunks/5c0b189e-4e740639a6808d9d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/5567-32270572c718c9a9.js\" defer=\"\"></script><script src=\"/_next/static/chunks/1045-fdb96a45188e8986.js\" defer=\"\"></script><script src=\"/_next/static/chunks/8569-edef3745251b6564.js\" defer=\"\"></script><script src=\"/_next/static/chunks/3864-6c41b52ab8ea6f77.js\" defer=\"\"></script><script src=\"/_next/static/chunks/4965-3715a8bec87b206d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/4875-684db166cb2088a7.js\" defer=\"\"></script><script src=\"/_next/static/chunks/1891-f23debe9df5d2a34.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/the-batch-05ac6254200bd6f5.js\" defer=\"\"></script><script src=\"/_next/static/F_BMQAVRJZAkZ3uV3_heV/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/F_BMQAVRJZAkZ3uV3_heV/_ssgManifest.js\" defer=\"\"></script><link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\"/><link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap\"/></head><body><noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ\" height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript><div id=\"__next\"><div data-sentry-component=\"Layout\" data-sentry-source-file=\"Layout.tsx\"><aside id=\"top-announcement\" class=\"text-neutral-900 \" style=\"color:#0c0c0c;background-color:#05256C;background-image:linear-gradient(318deg, rgba(249,186,26,1) 0%, rgba(247,223,87,1) 100%)\" data-sentry-component=\"AnnouncementBanner\" data-sentry-source-file=\"AnnouncementBanner.tsx\"><div class=\"container--boxed py-3 flex items-center justify-between \"><div class=\"flex items-center\"><p class=\"text-sm lg:text-base\">✨ New course! Enroll in<!-- --> <a href=\"https://bit.ly/3ZXjdrf\" class=\"underline\" target=\"_blank\">Reasoning with o1</a></p></div><div class=\"flex items-center\"><button class=\"bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><circle cx=\"12\" cy=\"12\" r=\"10\"></circle><line x1=\"15\" y1=\"9\" x2=\"9\" y2=\"15\"></line><line x1=\"9\" y1=\"9\" x2=\"15\" y2=\"15\"></line></svg></button></div></div></aside><header class=\"static h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200\" data-sentry-component=\"Header\" data-sentry-source-file=\"index.tsx\"><div class=\"container--boxed flex justify-between items-center\"><div class=\"max-w-[210px] lg:max-w-[210px]\"><a href=\"/\"><div class=\"flex items-center text-brand\"><svg viewBox=\"0 0 272 34\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" width=\"272\" height=\"34\" aria-label=\"DeepLearning.AI\" data-sentry-element=\"svg\" data-sentry-component=\"DLAILogo\" data-sentry-source-file=\"DLAILogo.tsx\"><g fill=\"currentColor\" data-sentry-element=\"g\" data-sentry-source-file=\"DLAILogo.tsx\"><path d=\"M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M268.681 5.961H272v20.152h-3.319V5.961z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path></g></svg></div></a></div><div class=\"flex items-center\"><div class=\"hidden lg:flex items-center\"><nav aria-label=\"Primary\" data-sentry-component=\"Nav\" data-sentry-source-file=\"Nav.tsx\"><ul class=\"flex items-center p-0 m-0 list-none\"><li class=\"NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a class=\"inline-block py-4 lg:px-2 xl:px-4\" href=\"/courses/\"><div class=\"NavItem_navItemLink__Aq6E5\"><span>Explore Courses</span></div></a></li><li class=\"NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a class=\"inline-block py-4 lg:px-2 xl:px-4\" href=\"/the-batch/\"><div class=\"NavItem_navItemLink__Aq6E5\"><span>AI Newsletter</span><span class=\"text-xl ml-1 -mr-1 text-slate-500\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"6 9 12 15 18 9\"></polyline></svg></span></div></a><ul class=\"NavItem_subMenu__qK1m4\"><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/the-batch/\"><div>The Batch</div></a></li><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/the-batch/tag/letters/\"><div>Andrew&#x27;s Letter</div></a></li><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/the-batch/tag/data-points/\"><div>Data Points</div></a></li><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/the-batch/tag/research/\"><div>ML Research</div></a></li><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/blog/\"><div>Blog</div></a></li></ul></li><li class=\"NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a class=\"inline-block py-4 lg:px-2 xl:px-4\" href=\"/community/\"><div class=\"NavItem_navItemLink__Aq6E5\"><span>Community</span><span class=\"text-xl ml-1 -mr-1 text-slate-500\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"6 9 12 15 18 9\"></polyline></svg></span></div></a><ul class=\"NavItem_subMenu__qK1m4\"><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"https://community.deeplearning.ai/\"><div>Forum</div></a></li><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/events/\"><div>Events</div></a></li><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/ambassador/\"><div>Ambassadors</div></a></li><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/blog/category/ambassador-spotlight/\"><div>Ambassador Spotlight</div></a></li></ul></li><li class=\"NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a class=\"inline-block py-4 lg:px-2 xl:px-4\" href=\"/resources/\"><div class=\"NavItem_navItemLink__Aq6E5\"><span>Resources</span></div></a></li><li class=\"NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a class=\"inline-block py-4 lg:px-2 xl:px-4\" href=\"/about/\"><div class=\"NavItem_navItemLink__Aq6E5\"><span>Company</span><span class=\"text-xl ml-1 -mr-1 text-slate-500\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"6 9 12 15 18 9\"></polyline></svg></span></div></a><ul class=\"NavItem_subMenu__qK1m4\"><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/about/\"><div>About</div></a></li><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/careers/\"><div>Careers</div></a></li><li class=\"NavItem_subMenuItem__2oKDr\"><a class=\"NavItem_subMenuItemLink__35KOd\" href=\"/contact/\"><div>Contact</div></a></li></ul></li></ul></nav><a class=\"btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10\" data-sentry-element=\"Link\" data-sentry-source-file=\"index.tsx\" href=\"https://bit.ly/3RB9T8a\">Start Learning</a></div><div data-sentry-element=\"Menu\" data-sentry-component=\"MobileMenu\" data-sentry-source-file=\"MobileMenu.tsx\" data-headlessui-state=\"\"><button class=\"lg:hidden\" data-sentry-element=\"MenuButton\" data-sentry-source-file=\"MobileMenu.tsx\" id=\"headlessui-menu-button-:R1qa6:\" type=\"button\" aria-haspopup=\"menu\" aria-expanded=\"false\" data-headlessui-state=\"\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"text-4xl text-slate-600\" data-sentry-element=\"FiMenu\" data-sentry-source-file=\"MobileMenu.tsx\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><line x1=\"3\" y1=\"12\" x2=\"21\" y2=\"12\"></line><line x1=\"3\" y1=\"6\" x2=\"21\" y2=\"6\"></line><line x1=\"3\" y1=\"18\" x2=\"21\" y2=\"18\"></line></svg></button></div></div></div></header><main><div id=\"content\"><section class=\"pt-16 pb-24 bg-white\" data-sentry-component=\"TheBatchHero\" data-sentry-source-file=\"TheBatchHero.tsx\"><div class=\"container--boxed\"><div class=\"flex flex-col items-center text-center max-w-boxed-xs mx-auto\"><div class=\"max-w-[300px] lg:max-w-[400px]\"><span style=\"box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%\"><span style=\"box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%\"><img style=\"display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0\" alt=\"\" aria-hidden=\"true\" src=\"data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27500%27%20height=%2765%27/%3e\"/></span><img alt=\"The Batch\" data-sentry-element=\"Image\" data-sentry-source-file=\"TheBatchHero.tsx\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"intrinsic\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/><noscript><img alt=\"The Batch\" data-sentry-element=\"Image\" data-sentry-source-file=\"TheBatchHero.tsx\" loading=\"lazy\" decoding=\"async\" data-nimg=\"intrinsic\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\" srcSet=\"/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fthe-batch-logo.0b7c10a2.png&amp;w=640&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fthe-batch-logo.0b7c10a2.png&amp;w=1080&amp;q=75 2x\" src=\"/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fthe-batch-logo.0b7c10a2.png&amp;w=1080&amp;q=75\"/></noscript></span></div><h1 class=\"text-4xl lg:text-5xl text-slate-400 font-normal mt-4 tracking-tight\">What Matters in AI Right Now</h1><div class=\"mt-11 w-full\"><form class=\"flex-col w-full\" data-sentry-component=\"SubscribeForm\" data-sentry-source-file=\"SubscribeForm.tsx\"><div class=\"w-full flex flex-col  items-center md:flex-row\"><input class=\"forms_input__6_Vmc  md:mr-4\" type=\"email\" placeholder=\"Email\" id=\"hero_subscribe_email\" required=\"\" value=\"\"/><button type=\"submit\" class=\"buttons_primary__wk22n  mt-4 btn--tracking md:mt-0\">Subscribe</button></div><div class=\"transform transition-all delay-200 duration-300  max-h-0 opacity-0 overflow-hidden\"><div class=\"flex mt-8 xs:mt-4 \"><div class=\"relative w-1/2 mr-2\"><label for=\"hero_subscribe_first_name\" class=\"forms_label__BDuBc forms_labelHidden__vroD6\">First Name</label><input id=\"hero_subscribe_first_name\" type=\"text\" class=\"forms_input__6_Vmc shadow-sm\" placeholder=\"e.g. John\" required=\"\" value=\"\"/></div><div class=\"relative w-1/2 ml-2\"><label for=\"hero_subscribe_last_name\" class=\"forms_label__BDuBc forms_labelHidden__vroD6\">Last Name</label><input id=\"hero_subscribe_last_name\" type=\"text\" class=\"forms_input__6_Vmc shadow-sm\" placeholder=\"e.g. Smith\" required=\"\" value=\"\"/></div></div><div class=\"mt-8 xs:mt-4 \"><div class=\"relative \"><label for=\"hero_subscribe_country\" class=\"forms_label__BDuBc forms_labelHidden__vroD6\">Where do you live?</label><input type=\"hidden\" name=\"hero_subscribe_country\" id=\"hero_subscribe_country\"/><style data-emotion=\"css b62m3t-container\">.css-b62m3t-container{position:relative;box-sizing:border-box;}</style><div class=\"react-select_reactSelect__op_fT css-b62m3t-container\"><style data-emotion=\"css 7pg0cj-a11yText\">.css-7pg0cj-a11yText{z-index:9999;border:0;clip:rect(1px, 1px, 1px, 1px);height:1px;width:1px;position:absolute;overflow:hidden;padding:0;white-space:nowrap;}</style><span id=\"react-select-jnkh67t5rtfy-live-region\" class=\"css-7pg0cj-a11yText\"></span><span aria-live=\"polite\" aria-atomic=\"false\" aria-relevant=\"additions text\" role=\"log\" class=\"css-7pg0cj-a11yText\"></span><style data-emotion=\"css 13cymwt-control\">.css-13cymwt-control{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:default;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;min-height:38px;outline:0!important;position:relative;-webkit-transition:all 100ms;transition:all 100ms;background-color:hsl(0, 0%, 100%);border-color:hsl(0, 0%, 80%);border-radius:4px;border-style:solid;border-width:1px;box-sizing:border-box;}.css-13cymwt-control:hover{border-color:hsl(0, 0%, 70%);}</style><div class=\" css-13cymwt-control\"><style data-emotion=\"css hlgwow\">.css-hlgwow{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:grid;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-overflow-scrolling:touch;position:relative;overflow:hidden;padding:2px 8px;box-sizing:border-box;}</style><div class=\" css-hlgwow\"><style data-emotion=\"css 1jqq78o-placeholder\">.css-1jqq78o-placeholder{grid-area:1/1/2/3;color:hsl(0, 0%, 50%);margin-left:2px;margin-right:2px;box-sizing:border-box;}</style><div class=\" css-1jqq78o-placeholder\" id=\"react-select-jnkh67t5rtfy-placeholder\">Select a country</div><style data-emotion=\"css 19bb58m\">.css-19bb58m{visibility:visible;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:inline-grid;grid-area:1/1/2/3;grid-template-columns:0 min-content;margin:2px;padding-bottom:2px;padding-top:2px;color:hsl(0, 0%, 20%);box-sizing:border-box;}.css-19bb58m:after{content:attr(data-value) \" \";visibility:hidden;white-space:pre;grid-area:1/2;font:inherit;min-width:2px;border:0;margin:0;outline:0;padding:0;}</style><div class=\" css-19bb58m\" data-value=\"\"><input class=\"\" style=\"label:input;color:inherit;background:0;opacity:1;width:100%;grid-area:1 / 2;font:inherit;min-width:2px;border:0;margin:0;outline:0;padding:0\" autoCapitalize=\"none\" autoComplete=\"off\" autoCorrect=\"off\" id=\"react-select-jnkh67t5rtfy-input\" spellcheck=\"false\" tabindex=\"0\" type=\"text\" aria-autocomplete=\"list\" aria-expanded=\"false\" aria-haspopup=\"true\" role=\"combobox\" aria-activedescendant=\"\" aria-describedby=\"react-select-jnkh67t5rtfy-placeholder\" value=\"\"/></div></div><style data-emotion=\"css 1wy0on6\">.css-1wy0on6{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-self:stretch;-ms-flex-item-align:stretch;align-self:stretch;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;}</style><div class=\" css-1wy0on6\"><style data-emotion=\"css 1u9des2-indicatorSeparator\">.css-1u9des2-indicatorSeparator{-webkit-align-self:stretch;-ms-flex-item-align:stretch;align-self:stretch;width:1px;background-color:hsl(0, 0%, 80%);margin-bottom:8px;margin-top:8px;box-sizing:border-box;}</style><span class=\" css-1u9des2-indicatorSeparator\"></span><style data-emotion=\"css 1xc3v61-indicatorContainer\">.css-1xc3v61-indicatorContainer{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-transition:color 150ms;transition:color 150ms;color:hsl(0, 0%, 80%);padding:8px;box-sizing:border-box;}.css-1xc3v61-indicatorContainer:hover{color:hsl(0, 0%, 60%);}</style><div class=\" css-1xc3v61-indicatorContainer\" aria-hidden=\"true\"><style data-emotion=\"css 8mmkcg\">.css-8mmkcg{display:inline-block;fill:currentColor;line-height:1;stroke:currentColor;stroke-width:0;}</style><svg height=\"20\" width=\"20\" viewBox=\"0 0 20 20\" aria-hidden=\"true\" focusable=\"false\" class=\"css-8mmkcg\"><path d=\"M4.516 7.548c0.436-0.446 1.043-0.481 1.576 0l3.908 3.747 3.908-3.747c0.533-0.481 1.141-0.446 1.574 0 0.436 0.445 0.408 1.197 0 1.615-0.406 0.418-4.695 4.502-4.695 4.502-0.217 0.223-0.502 0.335-0.787 0.335s-0.57-0.112-0.789-0.335c0 0-4.287-4.084-4.695-4.502s-0.436-1.17 0-1.615z\"></path></svg></div></div></div></div></div></div><div class=\"mt-8 xs:mt-4 \"><div class=\"relative \"><label for=\"job_function\" class=\"forms_label__BDuBc forms_labelHidden__vroD6\">What is your job title?</label><style data-emotion=\"css b62m3t-container\">.css-b62m3t-container{position:relative;box-sizing:border-box;}</style><div class=\"react-select_reactSelect__op_fT css-b62m3t-container\"><style data-emotion=\"css 7pg0cj-a11yText\">.css-7pg0cj-a11yText{z-index:9999;border:0;clip:rect(1px, 1px, 1px, 1px);height:1px;width:1px;position:absolute;overflow:hidden;padding:0;white-space:nowrap;}</style><span id=\"react-select-4-live-region\" class=\"css-7pg0cj-a11yText\"></span><span aria-live=\"polite\" aria-atomic=\"false\" aria-relevant=\"additions text\" role=\"log\" class=\"css-7pg0cj-a11yText\"></span><style data-emotion=\"css 13cymwt-control\">.css-13cymwt-control{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:default;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;min-height:38px;outline:0!important;position:relative;-webkit-transition:all 100ms;transition:all 100ms;background-color:hsl(0, 0%, 100%);border-color:hsl(0, 0%, 80%);border-radius:4px;border-style:solid;border-width:1px;box-sizing:border-box;}.css-13cymwt-control:hover{border-color:hsl(0, 0%, 70%);}</style><div class=\" css-13cymwt-control\"><style data-emotion=\"css hlgwow\">.css-hlgwow{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:grid;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-overflow-scrolling:touch;position:relative;overflow:hidden;padding:2px 8px;box-sizing:border-box;}</style><div class=\" css-hlgwow\"><style data-emotion=\"css 1jqq78o-placeholder\">.css-1jqq78o-placeholder{grid-area:1/1/2/3;color:hsl(0, 0%, 50%);margin-left:2px;margin-right:2px;box-sizing:border-box;}</style><div class=\" css-1jqq78o-placeholder\" id=\"react-select-4-placeholder\">Please select</div><style data-emotion=\"css 19bb58m\">.css-19bb58m{visibility:visible;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:inline-grid;grid-area:1/1/2/3;grid-template-columns:0 min-content;margin:2px;padding-bottom:2px;padding-top:2px;color:hsl(0, 0%, 20%);box-sizing:border-box;}.css-19bb58m:after{content:attr(data-value) \" \";visibility:hidden;white-space:pre;grid-area:1/2;font:inherit;min-width:2px;border:0;margin:0;outline:0;padding:0;}</style><div class=\" css-19bb58m\" data-value=\"\"><input class=\"\" style=\"label:input;color:inherit;background:0;opacity:1;width:100%;grid-area:1 / 2;font:inherit;min-width:2px;border:0;margin:0;outline:0;padding:0\" autoCapitalize=\"none\" autoComplete=\"off\" autoCorrect=\"off\" id=\"react-select-4-input\" spellcheck=\"false\" tabindex=\"0\" type=\"text\" aria-autocomplete=\"list\" aria-expanded=\"false\" aria-haspopup=\"true\" role=\"combobox\" aria-activedescendant=\"\" aria-describedby=\"react-select-4-placeholder\" value=\"\"/></div></div><style data-emotion=\"css 1wy0on6\">.css-1wy0on6{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-self:stretch;-ms-flex-item-align:stretch;align-self:stretch;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;}</style><div class=\" css-1wy0on6\"><style data-emotion=\"css 1u9des2-indicatorSeparator\">.css-1u9des2-indicatorSeparator{-webkit-align-self:stretch;-ms-flex-item-align:stretch;align-self:stretch;width:1px;background-color:hsl(0, 0%, 80%);margin-bottom:8px;margin-top:8px;box-sizing:border-box;}</style><span class=\" css-1u9des2-indicatorSeparator\"></span><style data-emotion=\"css 1xc3v61-indicatorContainer\">.css-1xc3v61-indicatorContainer{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-transition:color 150ms;transition:color 150ms;color:hsl(0, 0%, 80%);padding:8px;box-sizing:border-box;}.css-1xc3v61-indicatorContainer:hover{color:hsl(0, 0%, 60%);}</style><div class=\" css-1xc3v61-indicatorContainer\" aria-hidden=\"true\"><style data-emotion=\"css 8mmkcg\">.css-8mmkcg{display:inline-block;fill:currentColor;line-height:1;stroke:currentColor;stroke-width:0;}</style><svg height=\"20\" width=\"20\" viewBox=\"0 0 20 20\" aria-hidden=\"true\" focusable=\"false\" class=\"css-8mmkcg\"><path d=\"M4.516 7.548c0.436-0.446 1.043-0.481 1.576 0l3.908 3.747 3.908-3.747c0.533-0.481 1.141-0.446 1.574 0 0.436 0.445 0.408 1.197 0 1.615-0.406 0.418-4.695 4.502-4.695 4.502-0.217 0.223-0.502 0.335-0.787 0.335s-0.57-0.112-0.789-0.335c0 0-4.287-4.084-4.695-4.502s-0.436-1.17 0-1.615z\"></path></svg></div></div></div></div></div></div><div class=\"mt-8 xs:mt-4 \"><div class=\"relative text-left\"><label id=\"keep_me_updated_on_the_latest_news_events_and_courses-label\"><input id=\"keep_me_updated_on_the_latest_news_events_and_courses_input\" type=\"checkbox\" name=\"keep_me_updated_on_the_latest_news_events_and_courses\" aria-checked=\"true\" aria-invalid=\"false\" aria-required=\"false\" aria-labelledby=\"keep_me_updated_on_the_latest_news_events_and_courses-label\" aria-describedby=\"keep_me_updated_on_the_latest_news_events_and_courses-description\" class=\"mr-2\" checked=\"\" value=\"true\"/><span class=\"\">Keep me updated on the latest news, events, and courses</span></label></div></div><div class=\"mt-8 mb-8 text-center xs:mt-4\"><button type=\"submit\" class=\"btn--tracking buttons_primary__wk22n\">Subscribe</button></div></div></form><div class=\"h-0 overflow-hidden opacity-0\"><div><div id=\"reactHubspotForm32\" style=\"display:none\"></div><div class=\"flex items-center justify-center\"><svg class=\"animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" data-sentry-element=\"svg\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"Spinner.tsx\"><circle class=\"opacity-25\" cx=\"12\" cy=\"12\" r=\"10\" stroke=\"currentColor\" stroke-width=\"4\" data-sentry-element=\"circle\" data-sentry-source-file=\"Spinner.tsx\"></circle><path class=\"opacity-75\" fill=\"currentColor\" d=\"M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z\" data-sentry-element=\"path\" data-sentry-source-file=\"Spinner.tsx\"></path></svg></div></div></div><div class=\"text-sm mt-3 text-gray-400\">🗞️   Stay updated with weekly AI News and Insights delivered to your inbox</div></div></div></div></section><nav aria-label=\"Secondary\" class=\"h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block\" data-sentry-component=\"SecondaryNav\" data-sentry-source-file=\"index.tsx\"><div class=\"container--boxed h-full w-full flex items-center justify-between \"><div class=\"relative flex h-full\"><button class=\"h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden\"><span class=\"flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 18 9 12 15 6\"></polyline></svg></span></button><ul id=\"nav-secondary\" class=\"list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i\"><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-brand border-b-brand\">Weekly Issues</div></a></li><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/tag/letters/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500\">Andrew&#x27;s Letters</div></a></li><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/tag/data-points/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500\">Data Points</div></a></li><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/tag/research/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500\">ML Research</div></a></li><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/tag/business/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500\">Business</div></a></li><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/tag/science/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500\">Science</div></a></li><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/tag/culture/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500\">Culture</div></a></li><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/tag/hardware/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500\">Hardware</div></a></li><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/tag/ai-careers/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500\">AI Careers</div></a></li></ul><button class=\"h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex\"><span class=\"flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"9 18 15 12 9 6\"></polyline></svg></span></button></div><div class=\"flex items-center h-full\"><ul class=\"list-none p-0 m-0 h-full flex items-center mr-5\"><li class=\"mr-6 last:mr-0 h-full\" data-sentry-component=\"NavItem\" data-sentry-source-file=\"NavItem.tsx\"><a data-sentry-element=\"Link\" data-sentry-source-file=\"NavItem.tsx\" href=\"/the-batch/about/\"><div class=\"h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500\">About</div></a></li></ul><a href=\"/search/\"><div title=\"Search\" class=\"transition-colors text-slate-400 hover:text-slate-500\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"text-2xl\" aria-hidden=\"true\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><circle cx=\"11\" cy=\"11\" r=\"8\"></circle><line x1=\"21\" y1=\"21\" x2=\"16.65\" y2=\"16.65\"></line></svg></div></a></div></div></nav><section class=\"py-12 bg-slate-100\"><div class=\"relative container--boxed\"><div data-sentry-component=\"GridView\" data-sentry-source-file=\"GridView.tsx\"><div class=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-11\"><div class=\"col-span-1 lg:col-span-2\"><article class=\"lg:min-h-[500px] bg-white relative rounded-lg shadow-md hover:shadow-sm transition-shadow h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCardLarge.tsx\"><div class=\"aspect-w-16 aspect-h-9 lg:aspect-auto lg:w-full lg:h-full rounded-t-lg lg:rounded-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Deer training class with sleigh diagrams on a chalkboard.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" class=\"rounded-t-lg lg:rounded-lg\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Deer training class with sleigh diagrams on a chalkboard.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" class=\"rounded-t-lg lg:rounded-lg\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--39--1.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--39--1.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--39--1.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--39--1.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--39--1.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--39--1.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--39--1.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--39--1.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--39--1.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 lg:p-7 flex flex-col items-start relative lg:absolute bottom-0 left-0 bg-white lg:bg-white/80 w-full lg:w-10/12 rounded-b-lg lg:rounded-br-none lg:rounded-tr-md lg:rounded-bl-lg overflow-hidden backdrop-blur-sm\"><a href=\"/the-batch/tag/dec-25-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-white text-slate-500\">Dec 25, 2024</div></a><h2 class=\"text-xl lg:text-3xl font-semibold tracking-tight leading-tight text-slate-800 font-primary\">Top AI Stories of 2024! Agents Rise, Prices Fall, Models Shrink, Video Takes Off, Acquisitions Morph</h2><div class=\"text-sm lg:text-[15px]  leading-normal text-slate-500 line-clamp-3 lg:line-clamp-none mt-3 lg:hidden\">The Batch AI News and Insights: Is AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.</div><div class=\"grow\"></div><div class=\"lg:flex items-center text-brand-teal mt-4 hidden\"><span class=\"font-medium\">Read more</span><span><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" aria-hidden=\"true\" class=\"w-5 h-5 ml-2\" data-sentry-element=\"ArrowNarrowRightIcon\" data-sentry-source-file=\"PostCardLarge.tsx\"><path fill-rule=\"evenodd\" d=\"M12.293 5.293a1 1 0 011.414 0l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414-1.414L14.586 11H3a1 1 0 110-2h11.586l-2.293-2.293a1 1 0 010-1.414z\" clip-rule=\"evenodd\"></path></svg></span></div></div><a href=\"/the-batch/issue-281/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a></article></div><div class=\"col-span-1 hidden lg:block\"><div class=\"flex items-center justify-between\"><span class=\"text-4xl text-slate-400  font-semibold\">Popular Articles</span></div><div class=\"mt-4 grid grid-cols-1 gap-5\"><article class=\"bg-white relative rounded-lg shadow-md hover:shadow-sm transition-shadow grid grid-cols-3 min-h-[135px]\" data-sentry-component=\"PostCardSmall\" data-sentry-source-file=\"PostCardSmall.tsx\"><div class=\"col-span-1 overflow-hidden rounded-l-lg aspect-w-16 aspect-h-9 bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Llama 3.1 is State-of-the-Art and Open, Web Data Goes Dark, OpenAI Takes on Google and Bing, Synthetic Data Improves\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Llama 3.1 is State-of-the-Art and Open, Web Data Goes Dark, OpenAI Takes on Google and Bing, Synthetic Data Improves\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed---2024-07-31T173743.998-1.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed---2024-07-31T173743.998-1.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed---2024-07-31T173743.998-1.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed---2024-07-31T173743.998-1.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed---2024-07-31T173743.998-1.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed---2024-07-31T173743.998-1.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed---2024-07-31T173743.998-1.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed---2024-07-31T173743.998-1.png&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed---2024-07-31T173743.998-1.png&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"py-3 px-4 col-span-2 flex flex-col h-full justify-between\"><h2 class=\"text-base font-semibold leading-tight tracking-tight text-slate-800 font-primary line-clamp-4\">Llama 3.1 is State-of-the-Art and Open, Web Data Goes Dark, OpenAI Takes on Google and Bing, Synthetic Data Improves</h2><a href=\"/the-batch/issue-260/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"flex items-center justify-between mt-3\"><time dateTime=\"2024-07-31T15:48:54.000-07:00\" class=\"text-xs text-slate-400\">Jul 31, 2024</time><span class=\"text-xs text-slate-400 block mt-[2px]\">14<!-- --> min read</span></footer></div></article><article class=\"bg-white relative rounded-lg shadow-md hover:shadow-sm transition-shadow grid grid-cols-3 min-h-[135px]\" data-sentry-component=\"PostCardSmall\" data-sentry-source-file=\"PostCardSmall.tsx\"><div class=\"col-span-1 overflow-hidden rounded-l-lg aspect-w-16 aspect-h-9 bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"OpenAI Shrinks GPT-4o, Meta Withholds Models From Europe, Investors Hoard GPUs, Synthetic Talking Heads Get Expressive\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"OpenAI Shrinks GPT-4o, Meta Withholds Models From Europe, Investors Hoard GPUs, Synthetic Talking Heads Get Expressive\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--75-.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--75-.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--75-.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--75-.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--75-.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--75-.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--75-.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--75-.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--75-.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"py-3 px-4 col-span-2 flex flex-col h-full justify-between\"><h2 class=\"text-base font-semibold leading-tight tracking-tight text-slate-800 font-primary line-clamp-4\">OpenAI Shrinks GPT-4o, Meta Withholds Models From Europe, Investors Hoard GPUs, Synthetic Talking Heads Get Expressive</h2><a href=\"/the-batch/issue-259/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"flex items-center justify-between mt-3\"><time dateTime=\"2024-07-24T12:51:25.000-07:00\" class=\"text-xs text-slate-400\">Jul 24, 2024</time><span class=\"text-xs text-slate-400 block mt-[2px]\">13<!-- --> min read</span></footer></div></article><article class=\"bg-white relative rounded-lg shadow-md hover:shadow-sm transition-shadow grid grid-cols-3 min-h-[135px]\" data-sentry-component=\"PostCardSmall\" data-sentry-source-file=\"PostCardSmall.tsx\"><div class=\"col-span-1 overflow-hidden rounded-l-lg aspect-w-16 aspect-h-9 bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F03%2Funnamed--55--2.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F03%2Funnamed--55--2.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F03%2Funnamed--55--2.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F03%2Funnamed--55--2.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F03%2Funnamed--55--2.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F03%2Funnamed--55--2.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F03%2Funnamed--55--2.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F03%2Funnamed--55--2.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F03%2Funnamed--55--2.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"py-3 px-4 col-span-2 flex flex-col h-full justify-between\"><h2 class=\"text-base font-semibold leading-tight tracking-tight text-slate-800 font-primary line-clamp-4\">Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance</h2><a href=\"/the-batch/how-agents-can-improve-llm-performance/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"flex items-center justify-between mt-3\"><time dateTime=\"2024-03-20T14:45:48.000-07:00\" class=\"text-xs text-slate-400\">Mar 20, 2024</time><span class=\"text-xs text-slate-400 block mt-[2px]\">2<!-- --> min read</span></footer></div></article></div></div><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Graph showing cross-validation accuracy vs. number of features for raw and whitened inputs.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Graph showing cross-validation accuracy vs. number of features for raw and whitened inputs.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--32--1.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--32--1.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--32--1.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--32--1.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--32--1.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--32--1.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--32--1.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--32--1.png&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--32--1.png&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/dec-18-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Dec 18, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, Gemini 2.0 Flash Accelerates Multimodal Modeling, LLMs Propose Research Ideas</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards.</div><a href=\"/the-batch/issue-280/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Cartoon showing people stuck in wet concrete, with a person saying ‘You asked for a concrete idea!’\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Cartoon showing people stuck in wet concrete, with a person saying ‘You asked for a concrete idea!’\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--38--1.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--38--1.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--38--1.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--38--1.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--38--1.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--38--1.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--38--1.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--38--1.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--38--1.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/dec-11-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Dec 11, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications.</div><a href=\"/the-batch/issue-279/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"AI ecosystem layers: applications, orchestration, foundational models, cloud, and semiconductors.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"AI ecosystem layers: applications, orchestration, foundational models, cloud, and semiconductors.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--25--1.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--25--1.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--25--1.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--25--1.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--25--1.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--25--1.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--25--1.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--25--1.png&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F12%2Funnamed--25--1.png&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/dec-04-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Dec 04, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">AI Agents Spend Real Money, Breaking Jailbreaks, Mistral Goes Big and Multimodal, AI’s Growing E-Waste Problem</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: AI Agents Spend Real Money, Breaking Jailbreaks, Mistral Goes Big and Multimodal, AI’s Growing E-Waste Problem.</div><a href=\"/the-batch/issue-278/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Cornucopia overflowing with fruits and vegetables.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Cornucopia overflowing with fruits and vegetables.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--35--1.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--35--1.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--35--1.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--35--1.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--35--1.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--35--1.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--35--1.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--35--1.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--35--1.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/nov-27-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Nov 27, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">DeepSeek Takes On OpenAI, Robots Fold Laundry, Amazon and Anthropic Expand Partnership, More Efficient Object Detection</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: DeepSeek Takes On OpenAI, Robots Fold Laundry, Amazon and Anthropic Expand Partnership, More Efficient Object Detection. </div><a href=\"/the-batch/issue-277/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Two people reading in bed, one with a book on library functions and a head labeled with AI layers.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Two people reading in bed, one with a book on library functions and a head labeled with AI layers.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2FCaptura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2FCaptura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2FCaptura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2FCaptura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2FCaptura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2FCaptura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2FCaptura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2FCaptura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2FCaptura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/nov-20-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Nov 20, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, Transformer Training Streamlined</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: A small number of people are posting text online that’s intended for direct consumption not by humans, but by LLMs (large language models).</div><a href=\"/the-batch/issue-276/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Man with tools says, “I optimized for tool use!” Woman at computer replies, “Should’ve optimized for computer use!”\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Man with tools says, “I optimized for tool use!” Woman at computer replies, “Should’ve optimized for computer use!”\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--33--1.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--33--1.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--33--1.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--33--1.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--33--1.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--33--1.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--33--1.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--33--1.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--33--1.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/nov-13-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Nov 13, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions.</div><a href=\"/the-batch/issue-275/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Robot using a megaphone to amplify its message, with smaller robots spreading out from the megaphone.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Robot using a megaphone to amplify its message, with smaller robots spreading out from the megaphone.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--32--1.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--32--1.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--32--1.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--32--1.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--32--1.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--32--1.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--32--1.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--32--1.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F11%2Funnamed--32--1.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/nov-06-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Nov 06, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">AI Controls Desktops, Agents Train Algorithms, Does Anyone Comply With the EU’s AI Act?, Robots on the Loading Dock</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: Trump and the Republican party chalked up huge wins this week. Did manipulation of social media by generative AI play any role in this election?</div><a href=\"/the-batch/issue-274/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Man pulls lever to electrify a robot maid holding cleaning tools, cartoon-style.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Man pulls lever to electrify a robot maid holding cleaning tools, cartoon-style.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--27--1.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--27--1.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--27--1.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--27--1.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--27--1.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--27--1.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--27--1.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--27--1.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--27--1.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/oct-30-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 30, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Trick or treat! AI Devours Energy, Innovation Can’t Win, Models Collapse, Benchmark Tests Are Meaningless, No Work for Coders</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: Welcome to our special Halloween issue of The Batch, in which we probe fears, anomalies, and shadows of AI.</div><a href=\"/the-batch/issue-273/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Two cheetahs in a savannah, with one saying ‘Move fast and be responsible!’ in a speech bubble.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Two cheetahs in a savannah, with one saying ‘Move fast and be responsible!’ in a speech bubble.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--23--1.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--23--1.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--23--1.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--23--1.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--23--1.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--23--1.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--23--1.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--23--1.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--23--1.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/oct-23-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 23, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">AI Giants Go Nuclear, A Tech Bromance Turns Turbulent, Mistral Sharpens the Edge, Cheaper Video Generation</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: Startups live or die by their ability to execute at speed.</div><a href=\"/the-batch/issue-272/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Graph showing global warming with and without aerosol injection.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Graph showing global warming with and without aerosol injection.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FDisen-o-sin-ti-tulo.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FDisen-o-sin-ti-tulo.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FDisen-o-sin-ti-tulo.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FDisen-o-sin-ti-tulo.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FDisen-o-sin-ti-tulo.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FDisen-o-sin-ti-tulo.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FDisen-o-sin-ti-tulo.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FDisen-o-sin-ti-tulo.png&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FDisen-o-sin-ti-tulo.png&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/oct-16-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 16, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Bogus Apps, AI Boomtown, Better Embeddings, 2024 Highlights</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: It’s high time to take geoengineering more seriously as a potential tool to mitigate climate change.</div><a href=\"/the-batch/issue-271/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"How Meta’s Movie Gen Does It, AI’s Criminal Underground, Court Says LAION is Legal, OpenAI’s New Voice API\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"How Meta’s Movie Gen Does It, AI’s Criminal Underground, Court Says LAION is Legal, OpenAI’s New Voice API\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FHINTON-PARTY.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FHINTON-PARTY.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FHINTON-PARTY.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FHINTON-PARTY.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FHINTON-PARTY.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FHINTON-PARTY.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FHINTON-PARTY.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FHINTON-PARTY.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2FHINTON-PARTY.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/oct-09-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 09, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">How Meta’s Movie Gen Does It, AI’s Criminal Underground, Court Says LAION is Legal, OpenAI’s New Voice API</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!</div><a href=\"/the-batch/issue-270/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"California Senate Bill 1047 with a large veto stamp on top of the document.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"California Senate Bill 1047 with a large veto stamp on top of the document.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--18-.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--18-.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--18-.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--18-.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--18-.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--18-.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--18-.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--18-.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F10%2Funnamed--18-.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/oct-02-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 02, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Llama Goes Multimodal, Pros Embrace Generative Video, Military AI Guidelines, LLMs That Read Spreadsheets</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: We won! California’s anti-innovation bill SB 1047 was vetoed by Governor Newsom over the weekend.</div><a href=\"/the-batch/issue-269/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Hollywood Embraces Video Gen, New Restrictions on Deepfakes, More Open Source Models, Robot Server\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Hollywood Embraces Video Gen, New Restrictions on Deepfakes, More Open Source Models, Robot Server\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--13-.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--13-.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--13-.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--13-.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--13-.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--13-.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--13-.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--13-.png&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--13-.png&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/sep-25-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Sep 25, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Hollywood Embraces Video Gen, New Restrictions on Deepfakes, More Open Source Models, Robot Server</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: Last week I spoke at Coursera Connect, the company’s annual conference in Las Vegas, where a major topic was AI and education.</div><a href=\"/the-batch/issue-268/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Diagram of the data engineering cycle from generation to ingestion and transformation to analytics and machine learning.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Diagram of the data engineering cycle from generation to ingestion and transformation to analytics and machine learning.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2FUntitled-design.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2FUntitled-design.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2FUntitled-design.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2FUntitled-design.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2FUntitled-design.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2FUntitled-design.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2FUntitled-design.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2FUntitled-design.png&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2FUntitled-design.png&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/sep-18-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Sep 18, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Models Built for Reasoning, High Gear for Llama 3.1, Brains for Warehouse Robots, Stopping LLMs From Plagiarizing</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: Years ago, when I was working at a large tech company, I was responsible for the data warehouse.</div><a href=\"/the-batch/issue-267/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article><article class=\"bg-white relative rounded-lg shadow-sm hover:shadow-md transition-shadow flex flex-col h-full\" data-sentry-component=\"PostCard\" data-sentry-source-file=\"PostCard.tsx\"><div class=\"aspect-w-16 aspect-h-9 rounded-t-lg overflow-hidden bg-slate-200\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Comic where a robot is hiding in a closet during a game of hide-and-seek.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Comic where a robot is hiding in a closet during a game of hide-and-seek.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--10-.jpg&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--10-.jpg&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--10-.jpg&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--10-.jpg&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--10-.jpg&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--10-.jpg&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--10-.jpg&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--10-.jpg&amp;w=3840&amp;q=75 3840w\" src=\"/_next/image/?url=https%3A%2F%2Fdl-staging-website.ghost.io%2Fcontent%2Fimages%2F2024%2F09%2Funnamed--10-.jpg&amp;w=3840&amp;q=75\"/></noscript></span></div><div class=\"p-6 flex flex-col items-start h-full\"><a href=\"/the-batch/tag/sep-11-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Sep 11, 2024</div></a><h2 class=\"text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2\">Nations Sign Binding AI Treaty, Waymo Reveals Safety Record, 2D to 3D Goes Mainstream, Balancing Web Data Distributions</h2><div class=\"text-sm lg:text-[15px] leading-normal text-slate-500 line-clamp-3 mt-3 \">The Batch AI News and Insights: Over the weekend, my two kids colluded in a hilariously bad attempt to mislead me to look in the wrong place during a game of hide-and-seek.</div><a href=\"/the-batch/issue-266/\"><div class=\"absolute top-0 left-0 w-full h-full \"></div></a><footer class=\"mt-3\"></footer></div></article></div><div class=\"mt-12\"><nav aria-label=\"Pagination\" class=\"w-full\" data-sentry-component=\"Pagination\" data-sentry-source-file=\"Pagination.tsx\"><div class=\"grid grid-cols-3 items-center\"><div class=\"justify-self-start\"></div><div class=\"text-sm md:text-base text-slate-500 justify-self-center\">Page <!-- -->1<!-- --> of <!-- -->20</div><div class=\"justify-self-end\"><a href=\"/the-batch/page/2/\"><div class=\"buttons_secondary__8o9u6 buttons_small__C_CFb text-center\">Older Posts<svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"text-xl ml-1 hidden md:block\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><line x1=\"5\" y1=\"12\" x2=\"19\" y2=\"12\"></line><polyline points=\"12 5 19 12 12 19\"></polyline></svg></div></a></div></div></nav></div></div><div class=\"absolute top-0 -right-[30px] hidden lg:block\"><div class=\"flex flex-col items-center relative z-10 gap-1 w-[36px]\" data-sentry-component=\"FeedLayoutToggle\" data-sentry-source-file=\"FeedLayoutToggle.tsx\"><button class=\"w-[36px] h-[36px] rounded-full text-xl text-slate-400 transition-colors p-0 flex items-center justify-center bg-slate-200 hover:bg-slate-200 text-slate-500\" title=\"Grid View\" data-sentry-element=\"Button\" data-sentry-source-file=\"FeedLayoutToggle.tsx\" data-sentry-component=\"Button\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" data-sentry-element=\"FiGrid\" data-sentry-source-file=\"FeedLayoutToggle.tsx\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><rect x=\"3\" y=\"3\" width=\"7\" height=\"7\"></rect><rect x=\"14\" y=\"3\" width=\"7\" height=\"7\"></rect><rect x=\"14\" y=\"14\" width=\"7\" height=\"7\"></rect><rect x=\"3\" y=\"14\" width=\"7\" height=\"7\"></rect></svg></button><button class=\"w-[36px] h-[36px] rounded-full text-xl text-slate-400 transition-colors p-0 flex items-center justify-center bg-transparent hover:bg-slate-200 hover:text-slate-500\" title=\"List View\" data-sentry-element=\"Button\" data-sentry-source-file=\"FeedLayoutToggle.tsx\" data-sentry-component=\"Button\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" data-sentry-element=\"FiList\" data-sentry-source-file=\"FeedLayoutToggle.tsx\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><line x1=\"8\" y1=\"6\" x2=\"21\" y2=\"6\"></line><line x1=\"8\" y1=\"12\" x2=\"21\" y2=\"12\"></line><line x1=\"8\" y1=\"18\" x2=\"21\" y2=\"18\"></line><line x1=\"3\" y1=\"6\" x2=\"3.01\" y2=\"6\"></line><line x1=\"3\" y1=\"12\" x2=\"3.01\" y2=\"12\"></line><line x1=\"3\" y1=\"18\" x2=\"3.01\" y2=\"18\"></line></svg></button></div></div></div></section><div class=\"pt-8 pb-10 bg-slate-100\"><section id=\"subscribe\" data-sentry-component=\"CtaNewsletter\" data-sentry-source-file=\"CtaNewsletter.tsx\"><div class=\"container--boxed relative\"><div class=\"text-center\"><h2 class=\"text--l2 text-slate-900\">Subscribe to The Batch</h2><p class=\"text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto\">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class=\"flex flex-col items-center mt-9\"><div><div id=\"reactHubspotForm33\" style=\"display:none\"></div><div class=\"flex items-center justify-center\"><svg class=\"animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" data-sentry-element=\"svg\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"Spinner.tsx\"><circle class=\"opacity-25\" cx=\"12\" cy=\"12\" r=\"10\" stroke=\"currentColor\" stroke-width=\"4\" data-sentry-element=\"circle\" data-sentry-source-file=\"Spinner.tsx\"></circle><path class=\"opacity-75\" fill=\"currentColor\" d=\"M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z\" data-sentry-element=\"path\" data-sentry-source-file=\"Spinner.tsx\"></path></svg></div></div></div></div></section></div></div></main><footer class=\"py-16 bg-brand-teal-900\" data-sentry-component=\"Footer\" data-sentry-source-file=\"index.tsx\"><div class=\"flex flex-col items-center justify-center text-center container--boxed\"><div class=\"max-w-[220px] flex items-center justify-center text-white\"><svg viewBox=\"0 0 272 34\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" width=\"272\" height=\"34\" aria-label=\"DeepLearning.AI\" data-sentry-element=\"svg\" data-sentry-component=\"DLAILogo\" data-sentry-source-file=\"DLAILogo.tsx\"><g fill=\"currentColor\" data-sentry-element=\"g\" data-sentry-source-file=\"DLAILogo.tsx\"><path d=\"M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path d=\"M268.681 5.961H272v20.152h-3.319V5.961z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z\" data-sentry-element=\"path\" data-sentry-source-file=\"DLAILogo.tsx\"></path></g></svg></div><nav class=\"mt-6 md:mt-10\"><ul class=\"flex flex-wrap justify-center space-x-8 gap-x-8\"><li class=\"mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto\"><a href=\"/courses/\"><div class=\"text-xl text-brand hover:underline whitespace-nowrap \">Courses</div></a></li><li class=\"mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto\"><a href=\"/the-batch/\"><div class=\"text-xl text-brand hover:underline whitespace-nowrap \">The Batch</div></a></li><li class=\"mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto\"><a href=\"/community/\"><div class=\"text-xl text-brand hover:underline whitespace-nowrap \">Community</div></a></li><li class=\"mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto\"><a href=\"/careers/\"><div class=\"text-xl text-brand hover:underline whitespace-nowrap \">Careers</div></a></li><li class=\"mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto\"><a href=\"/about/\"><div class=\"text-xl text-brand hover:underline whitespace-nowrap \">About</div></a></li></ul></nav><div class=\"flex mt-12\"><a rel=\"noopener noreferrer\" target=\"_blank\" class=\"mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white\" href=\"https://www.facebook.com/1027125564106325\" data-sentry-element=\"SocialLink\" data-sentry-source-file=\"index.tsx\" data-sentry-component=\"SocialLink\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 16 16\" data-sentry-element=\"BsFacebook\" data-sentry-source-file=\"index.tsx\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951\"></path></svg></a><a rel=\"noopener noreferrer\" target=\"_blank\" class=\"mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white\" href=\"https://www.instagram.com/deeplearningai\" data-sentry-element=\"SocialLink\" data-sentry-source-file=\"index.tsx\" data-sentry-component=\"SocialLink\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 16 16\" data-sentry-element=\"BsInstagram\" data-sentry-source-file=\"index.tsx\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334\"></path></svg></a><a rel=\"noopener noreferrer\" target=\"_blank\" class=\"mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white\" href=\"https://twitter.com/deeplearningai\" data-sentry-element=\"SocialLink\" data-sentry-source-file=\"index.tsx\" data-sentry-component=\"SocialLink\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 16 16\" data-sentry-element=\"BsTwitter\" data-sentry-source-file=\"index.tsx\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15\"></path></svg></a><a rel=\"noopener noreferrer\" target=\"_blank\" class=\"mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white\" href=\"https://www.linkedin.com/company/18246783\" data-sentry-element=\"SocialLink\" data-sentry-source-file=\"index.tsx\" data-sentry-component=\"SocialLink\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 16 16\" data-sentry-element=\"BsLinkedin\" data-sentry-source-file=\"index.tsx\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z\"></path></svg></a><a rel=\"noopener noreferrer\" target=\"_blank\" class=\"mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white\" href=\"https://www.youtube.com/c/Deeplearningai\" data-sentry-element=\"SocialLink\" data-sentry-source-file=\"index.tsx\" data-sentry-component=\"SocialLink\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 16 16\" data-sentry-element=\"BsYoutube\" data-sentry-source-file=\"index.tsx\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z\"></path></svg></a></div></div></footer></div></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"posts\":[{\"title\":\"Top AI Stories of 2024! Agents Rise, Prices Fall, Models Shrink, Video Takes Off, Acquisitions Morph\",\"slug\":\"issue-281\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--39--1.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: Is AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.\",\"published_at\":\"2024-12-25T11:17:00.000-08:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"62ffbead663060004d6945e8\",\"name\":\"Year in Review\",\"slug\":\"year-in-review\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"676c5a9e4b838200017dcdfa\",\"name\":\"Dec 25, 2024\",\"slug\":\"dec-25-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"676c5a9e4b838200017dcdfb\",\"name\":\"issue-281\",\"slug\":\"issue-281\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: Is AI progressing rapidly? Yes! But while the progress of underlying AI technology has indeed sped up over the past 2 years, the fastest acceleration is in applications.\",\"feature_image_alt\":\"Deer training class with sleigh diagrams on a chalkboard.\",\"eyebrow\":{\"id\":\"676c5a9e4b838200017dcdfa\",\"name\":\"Dec 25, 2024\",\"slug\":\"dec-25-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, Gemini 2.0 Flash Accelerates Multimodal Modeling, LLMs Propose Research Ideas\",\"slug\":\"issue-280\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32--1.png\",\"custom_excerpt\":\"The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards.\",\"published_at\":\"2024-12-18T12:00:00.000-08:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"67632aa24b838200017dcc85\",\"name\":\"Dec 18, 2024\",\"slug\":\"dec-18-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"67632aa24b838200017dcc86\",\"name\":\"issue-280\",\"slug\":\"issue-280\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards.\",\"feature_image_alt\":\"Graph showing cross-validation accuracy vs. number of features for raw and whitened inputs.\",\"eyebrow\":{\"id\":\"67632aa24b838200017dcc85\",\"name\":\"Dec 18, 2024\",\"slug\":\"dec-18-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs\",\"slug\":\"issue-279\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38--1.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications.\",\"published_at\":\"2024-12-11T12:50:00.000-08:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"6759fb8358d8b10001af9bb7\",\"name\":\"Dec 11, 2024\",\"slug\":\"dec-11-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"6759fb8358d8b10001af9bb8\",\"name\":\"issue-279\",\"slug\":\"issue-279\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications.\",\"feature_image_alt\":\"Cartoon showing people stuck in wet concrete, with a person saying ‘You asked for a concrete idea!’\",\"eyebrow\":{\"id\":\"6759fb8358d8b10001af9bb7\",\"name\":\"Dec 11, 2024\",\"slug\":\"dec-11-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"AI Agents Spend Real Money, Breaking Jailbreaks, Mistral Goes Big and Multimodal, AI’s Growing E-Waste Problem\",\"slug\":\"issue-278\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--25--1.png\",\"custom_excerpt\":\"The Batch AI News and Insights: AI Agents Spend Real Money, Breaking Jailbreaks, Mistral Goes Big and Multimodal, AI’s Growing E-Waste Problem.\",\"published_at\":\"2024-12-04T12:44:00.000-08:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"6750c0d7ccfc3a0001d8d5e8\",\"name\":\"Dec 04, 2024\",\"slug\":\"dec-04-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"6750bf78ccfc3a0001d8d5c0\",\"name\":\"issue-278\",\"slug\":\"issue-278\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: AI Agents Spend Real Money, Breaking Jailbreaks, Mistral Goes Big and Multimodal, AI’s Growing E-Waste Problem.\",\"feature_image_alt\":\"AI ecosystem layers: applications, orchestration, foundational models, cloud, and semiconductors.\",\"eyebrow\":{\"id\":\"6750c0d7ccfc3a0001d8d5e8\",\"name\":\"Dec 04, 2024\",\"slug\":\"dec-04-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"DeepSeek Takes On OpenAI, Robots Fold Laundry, Amazon and Anthropic Expand Partnership, More Efficient Object Detection\",\"slug\":\"issue-277\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--35--1.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: DeepSeek Takes On OpenAI, Robots Fold Laundry, Amazon and Anthropic Expand Partnership, More Efficient Object Detection. \",\"published_at\":\"2024-11-27T11:42:00.000-08:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"674776ddfdb1390001aebb1c\",\"name\":\"issue-277\",\"slug\":\"issue-277\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"674776ddfdb1390001aebb1d\",\"name\":\"Nov 27, 2024\",\"slug\":\"nov-27-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: DeepSeek Takes On OpenAI, Robots Fold Laundry, Amazon and Anthropic Expand Partnership, More Efficient Object Detection. \",\"feature_image_alt\":\"Cornucopia overflowing with fruits and vegetables.\",\"eyebrow\":{\"id\":\"674776ddfdb1390001aebb1d\",\"name\":\"Nov 27, 2024\",\"slug\":\"nov-27-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, Transformer Training Streamlined\",\"slug\":\"issue-276\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png\",\"custom_excerpt\":\"The Batch AI News and Insights: A small number of people are posting text online that’s intended for direct consumption not by humans, but by LLMs (large language models).\",\"published_at\":\"2024-11-20T12:46:00.000-08:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"673e4ad16dcabe0001af5c64\",\"name\":\"issue-276\",\"slug\":\"issue-276\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"673e4ad16dcabe0001af5c65\",\"name\":\"Nov 20, 2024\",\"slug\":\"nov-20-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: A small number of people are posting text online that’s intended for direct consumption not by humans, but by LLMs (large language models).\",\"feature_image_alt\":\"Two people reading in bed, one with a book on library functions and a head labeled with AI layers.\",\"eyebrow\":{\"id\":\"673e4ad16dcabe0001af5c65\",\"name\":\"Nov 20, 2024\",\"slug\":\"nov-20-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot\",\"slug\":\"issue-275\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33--1.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions.\",\"published_at\":\"2024-11-13T11:54:00.000-08:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"673504713ea32c00011e2243\",\"name\":\"Nov 13, 2024\",\"slug\":\"nov-13-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"673504713ea32c00011e2244\",\"name\":\"issue-275\",\"slug\":\"issue-275\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions.\",\"feature_image_alt\":\"Man with tools says, “I optimized for tool use!” Woman at computer replies, “Should’ve optimized for computer use!”\",\"eyebrow\":{\"id\":\"673504713ea32c00011e2243\",\"name\":\"Nov 13, 2024\",\"slug\":\"nov-13-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"AI Controls Desktops, Agents Train Algorithms, Does Anyone Comply With the EU’s AI Act?, Robots on the Loading Dock\",\"slug\":\"issue-274\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--32--1.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: Trump and the Republican party chalked up huge wins this week. Did manipulation of social media by generative AI play any role in this election?\",\"published_at\":\"2024-11-06T12:20:00.000-08:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"672bd056aa57490001fc3190\",\"name\":\"issue-274\",\"slug\":\"issue-274\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"672bd056aa57490001fc3191\",\"name\":\"Nov 06, 2024\",\"slug\":\"nov-06-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: Trump and the Republican party chalked up huge wins this week. Did manipulation of social media by generative AI play any role in this election?\",\"feature_image_alt\":\"Robot using a megaphone to amplify its message, with smaller robots spreading out from the megaphone.\",\"eyebrow\":{\"id\":\"672bd056aa57490001fc3191\",\"name\":\"Nov 06, 2024\",\"slug\":\"nov-06-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Trick or treat! AI Devours Energy, Innovation Can’t Win, Models Collapse, Benchmark Tests Are Meaningless, No Work for Coders\",\"slug\":\"issue-273\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--27--1.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: Welcome to our special Halloween issue of The Batch, in which we probe fears, anomalies, and shadows of AI.\",\"published_at\":\"2024-10-30T07:23:00.000-07:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"672393552a932f000109c5a0\",\"name\":\"issue-273\",\"slug\":\"issue-273\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"672393552a932f000109c5a1\",\"name\":\"Oct 30, 2024\",\"slug\":\"oct-30-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: Welcome to our special Halloween issue of The Batch, in which we probe fears, anomalies, and shadows of AI.\",\"feature_image_alt\":\"Man pulls lever to electrify a robot maid holding cleaning tools, cartoon-style.\",\"eyebrow\":{\"id\":\"672393552a932f000109c5a1\",\"name\":\"Oct 30, 2024\",\"slug\":\"oct-30-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"AI Giants Go Nuclear, A Tech Bromance Turns Turbulent, Mistral Sharpens the Edge, Cheaper Video Generation\",\"slug\":\"issue-272\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--23--1.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: Startups live or die by their ability to execute at speed.\",\"published_at\":\"2024-10-23T16:13:00.000-07:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"671983d6323caf00013ef305\",\"name\":\"issue-272\",\"slug\":\"issue-272\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"671983d6323caf00013ef306\",\"name\":\"Oct 23, 2024\",\"slug\":\"oct-23-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: Startups live or die by their ability to execute at speed.\",\"feature_image_alt\":\"Two cheetahs in a savannah, with one saying ‘Move fast and be responsible!’ in a speech bubble.\",\"eyebrow\":{\"id\":\"671983d6323caf00013ef306\",\"name\":\"Oct 23, 2024\",\"slug\":\"oct-23-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Bogus Apps, AI Boomtown, Better Embeddings, 2024 Highlights\",\"slug\":\"issue-271\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/10/Disen-o-sin-ti-tulo.png\",\"custom_excerpt\":\"The Batch AI News and Insights: It’s high time to take geoengineering more seriously as a potential tool to mitigate climate change.\",\"published_at\":\"2024-10-16T15:09:00.000-07:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"67103a1913d19b000156997a\",\"name\":\"issue 271\",\"slug\":\"issue-271\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"67103a1913d19b000156997b\",\"name\":\"Oct 16, 2024\",\"slug\":\"oct-16-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: It’s high time to take geoengineering more seriously as a potential tool to mitigate climate change.\",\"feature_image_alt\":\"Graph showing global warming with and without aerosol injection.\",\"eyebrow\":{\"id\":\"67103a1913d19b000156997b\",\"name\":\"Oct 16, 2024\",\"slug\":\"oct-16-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"How Meta’s Movie Gen Does It, AI’s Criminal Underground, Court Says LAION is Legal, OpenAI’s New Voice API\",\"slug\":\"issue-270\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!\",\"published_at\":\"2024-10-09T14:59:00.000-07:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"6706fd5f504fea00012eb1ac\",\"name\":\"issue 270\",\"slug\":\"issue-270\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"6706fd5f504fea00012eb1ad\",\"name\":\"Oct 09, 2024\",\"slug\":\"oct-09-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!\",\"feature_image_alt\":null,\"eyebrow\":{\"id\":\"6706fd5f504fea00012eb1ad\",\"name\":\"Oct 09, 2024\",\"slug\":\"oct-09-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Llama Goes Multimodal, Pros Embrace Generative Video, Military AI Guidelines, LLMs That Read Spreadsheets\",\"slug\":\"issue-269\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--18-.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: We won! California’s anti-innovation bill SB 1047 was vetoed by Governor Newsom over the weekend.\",\"published_at\":\"2024-10-02T15:40:00.000-07:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"66fdcc44653e12000123aad0\",\"name\":\"Issue-269\",\"slug\":\"issue-269\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"66fdcc44653e12000123aad1\",\"name\":\"Oct 02, 2024\",\"slug\":\"oct-02-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: We won! California’s anti-innovation bill SB 1047 was vetoed by Governor Newsom over the weekend.\",\"feature_image_alt\":\"California Senate Bill 1047 with a large veto stamp on top of the document.\",\"eyebrow\":{\"id\":\"66fdcc44653e12000123aad1\",\"name\":\"Oct 02, 2024\",\"slug\":\"oct-02-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Hollywood Embraces Video Gen, New Restrictions on Deepfakes, More Open Source Models, Robot Server\",\"slug\":\"issue-268\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--13-.png\",\"custom_excerpt\":\"The Batch AI News and Insights: Last week I spoke at Coursera Connect, the company’s annual conference in Las Vegas, where a major topic was AI and education.\",\"published_at\":\"2024-09-25T13:04:00.000-07:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"66f46d478bb1e50001b2cb57\",\"name\":\"issue-268\",\"slug\":\"issue-268\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"66f46d478bb1e50001b2cb58\",\"name\":\"Sep 25, 2024\",\"slug\":\"sep-25-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: Last week I spoke at Coursera Connect, the company’s annual conference in Las Vegas, where a major topic was AI and education.\",\"feature_image_alt\":null,\"eyebrow\":{\"id\":\"66f46d478bb1e50001b2cb58\",\"name\":\"Sep 25, 2024\",\"slug\":\"sep-25-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Models Built for Reasoning, High Gear for Llama 3.1, Brains for Warehouse Robots, Stopping LLMs From Plagiarizing\",\"slug\":\"issue-267\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/09/Untitled-design.png\",\"custom_excerpt\":\"The Batch AI News and Insights: Years ago, when I was working at a large tech company, I was responsible for the data warehouse.\",\"published_at\":\"2024-09-18T16:00:00.000-07:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"66eb5c2199961b0001f50df4\",\"name\":\"issue 267\",\"slug\":\"issue-267\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"66eb5c2199961b0001f50df5\",\"name\":\"Sep 18, 2024\",\"slug\":\"sep-18-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: Years ago, when I was working at a large tech company, I was responsible for the data warehouse.\",\"feature_image_alt\":\"Diagram of the data engineering cycle from generation to ingestion and transformation to analytics and machine learning.\",\"eyebrow\":{\"id\":\"66eb5c2199961b0001f50df5\",\"name\":\"Sep 18, 2024\",\"slug\":\"sep-18-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}},{\"title\":\"Nations Sign Binding AI Treaty, Waymo Reveals Safety Record, 2D to 3D Goes Mainstream, Balancing Web Data Distributions\",\"slug\":\"issue-266\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--10-.jpg\",\"custom_excerpt\":\"The Batch AI News and Insights: Over the weekend, my two kids colluded in a hilariously bad attempt to mislead me to look in the wrong place during a game of hide-and-seek.\",\"published_at\":\"2024-09-11T15:11:00.000-07:00\",\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"66e2164691be85000169b162\",\"name\":\"issue-266\",\"slug\":\"issue-266\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null},{\"id\":\"66e2164691be85000169b163\",\"name\":\"Sep 11, 2024\",\"slug\":\"sep-11-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}],\"excerpt\":\"The Batch AI News and Insights: Over the weekend, my two kids colluded in a hilariously bad attempt to mislead me to look in the wrong place during a game of hide-and-seek.\",\"feature_image_alt\":\"Comic where a robot is hiding in a closet during a game of hide-and-seek.\",\"eyebrow\":{\"id\":\"66e2164691be85000169b163\",\"name\":\"Sep 11, 2024\",\"slug\":\"sep-11-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null}}],\"featuredPosts\":[{\"id\":\"66aabc656032ae000139f174\",\"uuid\":\"cfb61caf-e039-47a2-9c61-3c3769c39b73\",\"title\":\"Llama 3.1 is State-of-the-Art and Open, Web Data Goes Dark, OpenAI Takes on Google and Bing, Synthetic Data Improves\",\"slug\":\"issue-260\",\"html\":\"\\u003cp\\u003eDear friends,\\u003c/p\\u003e\\u003cp\\u003eLast week, I\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/concrete-ideas-make-strong-ai-startups/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003ewrote\\u003c/a\\u003e\\u0026nbsp;about why working on a concrete startup or project idea — meaning a specific product envisioned in enough detail that we can build it for a specific target user — lets you go faster. In this letter, I’d like to share some best practices for identifying promising ideas.\\u003c/p\\u003e\\u003cp\\u003eAI Fund, which I lead, works with many corporate partners to identify ideas, often involving applications of AI to the company’s domain. Because AI is applicable to numerous sectors such as retail, energy, logistics and finance, I’ve found working with domain experts who know these areas well immensely helpful for identifying what applications are worth building in these areas.\\u003c/p\\u003e\\u003cp\\u003eOur brainstorming process starts with recommending that a large number of key contributors at our partner corporation (at least 10 but sometimes well over 100) gain a non-technical, business-level understanding of AI and what it can and can’t do. Taking DeepLearning.AI’s “\\u003ca href=\\\"https://www.deeplearning.ai/courses/generative-ai-for-everyone/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eGenerative AI for Everyone\\u003c/a\\u003e” course is a popular option, after which a company is well positioned to assign a small team to coordinate a brainstorming process, followed by a prioritization exercise to pick what to work on. The brainstorming process can be supported by a\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/which-ai-applications-should-you-build/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003etask-based analysis of jobs\\u003c/a\\u003e\\u0026nbsp;in which we decompose employees’ jobs into tasks to identify which ones might be automated or augmented using AI.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eHere are some best practices for these activities:\\u003cbr\\u003e\\u003cbr\\u003e\\u003cstrong\\u003eTrust the domain expert’s gut.\\u0026nbsp;\\u003c/strong\\u003eA domain expert who has worked for years in a particular sector will have well honed instincts that let them make leaps that would take a non-expert weeks of research.\\u003c/p\\u003e\\u003cp\\u003eLet’s say we’re working with a financial services expert and have developed a vague idea (“build a chatbot for financial advice”). To turn this into a concrete idea, we might need to answer questions such as what areas of finance to target (should we focus on budgeting, investing, or insurance?) and what types of user to serve (fresh graduates, mortgage applicants, new parents, or retirees?) Even a domain expert who has spent years giving financial advice might not know the best answer, but a choice made via their gut gives a quick way to get to one plausible concrete idea. Of course, if market-research data can be obtained quickly to support this decision, we should take advantage of it. But to avoid slowing down too much, we’ve found that experts’ gut reactions work well and are a quick way to make decisions.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eSo, if I’m handed a non-concrete idea, I often ask a domain expert to use their gut — and nothing else — to quickly make decisions as needed to make the idea concrete. The resulting idea is only a starting point to be tweaked over time. If, in the discussion, the domain expert picks one option but seems very hesitant to disregard a different option, then we can also keep the second option as a back-up that we can quickly pivot to if the initial one no longer looks promising.\\u0026nbsp;\\u003c/p\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T173743.998.png\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1200\\\" height=\\\"677\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/unnamed---2024-07-31T173743.998.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/unnamed---2024-07-31T173743.998.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T173743.998.png 1200w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/figure\\u003e\\u003cp\\u003e\\u003cstrong\\u003eGenerate many ideas.\\u0026nbsp;\\u003c/strong\\u003eI usually suggest coming up with at least 10 ideas; some will come up with over 100, which is even better. The usual brainstorming advice to go for volume rather than quality applies here. Having many ideas is particularly important when it comes to prioritization. If only one idea is seriously considered — sometimes this happens if a senior executive has an idea they really like and puts this forward as the “main” idea to be worked on — there’s a lot of pressure to make this idea work. Even if further investigation discovers problems with it — for example, market demand turns out to be weak or the technology is very expensive to build — the team will want to keep trying to make it work so we don’t end up with nothing.\\u003c/p\\u003e\\u003cp\\u003eIn contrast, when a company has many ideas to choose from, if one starts to look less interesting, it’s easy to shift attention to a different one. When many ideas are considered, it’s easier to compare them to pick the superior ones. As explained in the book\\u0026nbsp;\\u003ca href=\\\"https://www.amazon.com/Ideaflow-Only-Business-Metric-Matters-ebook/dp/B09R6M3292/ref=sr_1_1?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003e\\u003cem\\u003eIdeaflow\\u003c/em\\u003e\\u003c/a\\u003e, teams that generate more ideas for evaluation and prioritization end up with better solutions.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eBecause of this, I’ve found it helpful to run a broad brainstorming process that involves many employees. Specifically, large companies have many people who collectively have a lot of wisdom regarding the business. Having a small core team coordinate the gathering of ideas from a large number of people lets us tap into this collective fountain of invention. Many times I’ve seen a broad effort (involving, say, ~100 people who are knowledgeable about the domain and have a basic understanding of AI) end up with better ideas than a narrow one (involving, say, a handful of top executives).\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eMake the evaluation criteria explicit.\\u003c/strong\\u003e\\u0026nbsp;When evaluating and prioritizing, clear criteria for scoring and ranking ideas helps the team to judge ideas more consistently. Business value and technical feasibility are almost always included. Additionally, many companies will prioritize projects that can be a quick win (to build momentum for their overall AI efforts) or support certain strategic priorities such as growth in a particular part of the business. Making such criteria explicit can help during the idea-generation phase, and it’s critical when you evaluate and prioritize.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eIn large companies, it can take a few weeks to go through a process to gather and prioritize ideas, but this pays off well in identifying valuable, concrete ideas to pursue. AI isn’t useful unless we find appropriate ways to apply it, and I hope these best practices will help you to generate great AI application ideas to work on.\\u003c/p\\u003e\\u003cp\\u003eKeep learning!\\u003c/p\\u003e\\u003cp\\u003eAndrew\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003c/p\\u003e\\u003ch2 id=\\\"a-message-from-deeplearningai\\\"\\u003eA MESSAGE FROM\\u0026nbsp;DEEPLEARNING.AI\\u003c/h2\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003ca href=\\\"https://www.deeplearning.ai/short-courses/embedding-models-from-architecture-to-implementation?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-30T090813.026.png\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1680\\\" height=\\\"945\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-30T090813.026.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-30T090813.026.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-30T090813.026.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-30T090813.026.png 1680w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/a\\u003e\\u003c/figure\\u003e\\u003cp\\u003eJoin our new short course and gain an in-depth understanding of embedding models! Learn to train and use Word2Vec and BERT in semantic search systems, and build a dual-encoder model with a contrastive loss to enhance question-answer accuracy.\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/short-courses/embedding-models-from-architecture-to-implementation?ref=dl-staging-website.ghost.io\\\" rel=\\\"noreferrer\\\"\\u003eSign up today\\u003c/a\\u003e\\u003c/p\\u003e\\u003ch1 id=\\\"news\\\"\\u003eNews\\u003c/h1\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174003.755.png\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1200\\\" height=\\\"675\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/unnamed---2024-07-31T174003.755.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/unnamed---2024-07-31T174003.755.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174003.755.png 1200w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/figure\\u003e\\u003ch1 id=\\\"the-state-of-the-art-is-open\\\"\\u003eThe State of the Art Is Open\\u003c/h1\\u003e\\u003cp\\u003eMeta raised the bar for large language models with open weights and published details about how it built one that outperforms GPT-4o and Claude 3.5 Sonnet by some measures.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhat's new:\\u003c/strong\\u003e\\u0026nbsp;\\u003ca href=\\\"https://ai.meta.com/research/publications/the-llama-3-herd-of-models/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eLlama 3.1 405B\\u003c/a\\u003e\\u0026nbsp;delivers state-of-the-art performance on a handful of public benchmarks and has a context window of 128,000 input tokens while allowing a range of commercial uses. In addition to the 405-billion parameter model, Meta released new versions of the earlier Llama 3 70B (70 billion parameters) and 8B (8 billion parameters). Model weights are available\\u0026nbsp;\\u003ca href=\\\"https://llama.meta.com/llama-downloads/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003ehere\\u003c/a\\u003e.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eKey insight:\\u003c/strong\\u003e\\u0026nbsp;Fine-tuning on generated data can improve a model’s performance, but incorrect or lower-quality examples degrade it. The Llama team undertook an extensive effort to fix or remove bad examples using a variety of tools including the model itself, auxiliary models, and off-the-shelf tools.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eHow it works:\\u003c/strong\\u003e\\u0026nbsp;Llama 3.1 models are transformers that have been pretrained to predict the next token in a sequence. Meta provided more information about the development of Llama 3.1 405B than the smaller versions. Its pretraining dataset comprised 16.4 trillion tokens of text, “much” of it scraped from the web. The pretrained model was fine-tuned to perform seven tasks, including coding and reasoning, via supervised learning and\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/human-feedback-without-reinforcement-learning/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003edirect preference optimization\\u003c/a\\u003e\\u0026nbsp;(DPO). Most of the fine-tuning data was generated by the model itself and curated using a variety of methods including agentic workflows. For instance,\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eTo generate good code to learn from, the team: (1) Generated programming problems from random code snippets. (2) Generated a solution to each problem, prompting the model to follow good programming practices and explain its thought process in comments. (3) Ran the generated code through a parser and linter to check for issues like syntax errors, style issues, and uninitialized variables. (4) Generated unit tests. (5) Tested the code on the unit tests. (6) If there were any issues, regenerated the code, giving the model the original question, code, and feedback. (7) If the code passed all tests, added it to the dataset. (8) Fine-tuned the model. (9) Repeated this process several times.\\u003c/li\\u003e\\u003cli\\u003eTo generate fine-tuning data that represented good lines of reasoning, the team: (1) Generated math questions and answers from math problems. (2) Manually identified the types of problems the model struggled with. (3) Asked humans to write questions for those problems. (4) Generated step-by-step answers for those problems. (5)\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2403.04706?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eRemoved\\u003c/a\\u003e\\u0026nbsp;examples that end with the wrong answer. (6) Asked the model to determine whether the reasoning was correct. (7) Removed examples that the model identified as having incorrect reasoning. (8)\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2305.20050?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eTrained\\u003c/a\\u003e\\u0026nbsp;separate models to determine if the reasoning was correct. (9) Used those models to filter out incorrect examples.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eResults:\\u003c/strong\\u003e\\u0026nbsp;The authors compared Llama 3.1 405B to Claude 3.5 Sonnet, GPT-4, GPT-4o, and Nemotron 4 340B on 16 public benchmarks. It either outperformed or tied the other models on seven of the 16 (although two, GSM8K and MMLU zero-shot chain-of-thought, are not directly comparable due to differences in prompting methods). For instance, Llama 3.1 405B set a new state of the art in IFEval (general knowledge), ARC Challenge (reasoning), and Nexus (tool use). The smaller versions outperformed other models in the same general size classes as well. Llama 3.1 70B set new states of the art in all benchmarks for general knowledge, coding, math, and reasoning. Llama 3.1 8B dominated general, coding, and math benchmarks.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eLicense:\\u0026nbsp;\\u003c/strong\\u003eLlama 3.1 models are licensed under a\\u0026nbsp;\\u003ca href=\\\"https://llamaimodel.com/commercial-use/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003ecustom license\\u003c/a\\u003e\\u0026nbsp;that allows both commercial use (by companies with up to 700 million monthly active users in the month prior to Llama 3.1’s release) and training other models on generated data. This enables many companies to use it as they like while potentially requiring Meta’s largest competitors to negotiate a commercial license.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eThe French connection:\\u003c/strong\\u003e\\u0026nbsp;Separately, Mistral announced its next-generation LLM\\u0026nbsp;\\u003ca href=\\\"https://mistral.ai/news/mistral-large-2407/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eMistral Large 2\\u003c/a\\u003e, which\\u0026nbsp;\\u003ca href=\\\"https://mistral.ai/licenses/MRL-0.1.md?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eallows\\u003c/a\\u003e\\u0026nbsp;noncommercial use but requires a special license for commercial use. The 123 billion-parameter model boasts performance similar to that of Llama 3.1 405B on a number of benchmarks despite being less than one-third the size.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhy it matters:\\u003c/strong\\u003e\\u0026nbsp;The Llama 3.1 family continues Meta’s contributions in open models and extends them to some commercial uses. The upgraded 8B and 70B models perform better than their predecessors, while the 405B version rivals top proprietary models and enables researchers to generate high-quality synthetic data for training further models. The team provides extensive detail about how they generated fine-tuning data. For each task, they describe the pipeline used to create the data along with various notes about what worked and what didn’t work for them — helpful information for researchers who aim to build next-generation LLMs.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWe're thinking:\\u003c/strong\\u003e\\u0026nbsp;\\u0026nbsp;\\u003ca href=\\\"https://datacentricai.org/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eData-centric AI\\u003c/a\\u003e, the discipline of systematically engineering data to build a successful AI system, is critical for machine learning. The Llama 3.1 paper makes clear that systematically engineering the training data was also a key to training what is, as far as we know, the first open weights model to achieve better performance than the best proprietary models on multiple benchmarks. The potential of open weights is looking better every day!\\u003c/p\\u003e\\u003chr\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174116.563.gif\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"600\\\" height=\\\"338\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174116.563.gif 600w\\\"\\u003e\\u003c/figure\\u003e\\u003ch1 id=\\\"search-gets-conversational\\\"\\u003eSearch Gets Conversational\\u003c/h1\\u003e\\u003cp\\u003eOpenAI is testing an AI-powered search engine in a bid to compete head-to-head with both Google and its close partner Microsoft Bing.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhat’s new:\\u003c/strong\\u003e\\u0026nbsp;OpenAI\\u0026nbsp;\\u003ca href=\\\"https://openai.com/index/searchgpt-prototype/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003ereleased\\u003c/a\\u003e\\u0026nbsp;SearchGPT, an integrated search engine and large language model that aims to be friendly to both users and publishers. Access is limited initially to selected trial users. OpenAI offers a wait list but no timeline for expanding access.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eHow it works:\\u003c/strong\\u003e\\u0026nbsp;SearchGPT sorts results collected by web crawler, like Google and its competitors. It differs in providing direct answers to queries and offering a conversational user interface for follow-up questions. OpenAI has not disclosed the underlying model.\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eGiven a question or search string like “best tomatoes to grow in Minnesota,” SearchGPT returns an answer such as a list of tomato varieties. Typically it adds a source for the information (\\u003cem\\u003eThe Garden Magazine\\u003c/em\\u003e) and a link to the published site(s). Other relevant links appear in a sidebar.\\u003c/li\\u003e\\u003cli\\u003eAfter receiving the initial response, users can refine the search by asking further questions like, “which of these can I plant now?” SearchGPT will generate new results based on context.\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eThe system draws on information from publishers from which OpenAI\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/openai-licenses-financial-times-archive-in-fifth-deal-with-major-news-publishers/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003elicensed\\u003c/a\\u003e\\u0026nbsp;copyrighted materials including\\u0026nbsp;\\u003cem\\u003eAssociated Press\\u003c/em\\u003e,\\u0026nbsp;\\u003cem\\u003eThe Atlantic\\u003c/em\\u003e,\\u0026nbsp;\\u003cem\\u003eFinancial Times\\u003c/em\\u003e, and\\u0026nbsp;\\u003cem\\u003eNews Corp\\u003c/em\\u003e. OpenAI also has struck licensing deals with online forums including\\u0026nbsp;\\u003ca href=\\\"https://openai.com/index/openai-and-reddit-partnership/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eReddit\\u003c/a\\u003e\\u0026nbsp;and\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/data-points-issue-249/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eStack Overflow\\u003c/a\\u003e. Whether these partners are favored in search results is not clear.\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eThe service also draws on web pages indexed by its crawler. Web publishers can opt out of being crawled for indexing, gathering training data, or both.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eBehind the news:\\u003c/strong\\u003e\\u0026nbsp;OpenAI’s move is part of a larger race to supercharge web search with AI.\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eGoogle and Microsoft\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/google-and-microsoft-both-announce-ai-powered-search/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eadded\\u003c/a\\u003e\\u0026nbsp;AI-generated results and summaries to their search engines last year, and Google\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/google-io-developers-conference-reveals-new-ai-models-features-and-upgrades/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eexpanded\\u003c/a\\u003e\\u0026nbsp;its AI Overview program earlier this year. Search GPT amps up OpenAI’s competition with Google, which uses its own Gemini models, but also with its partner Microsoft, whose AI-driven Bing Search and Copilot products rely on OpenAI.\\u003c/li\\u003e\\u003cli\\u003eThe startups You.com and Perplexity offer AI-driven search services. Publishers have\\u0026nbsp;\\u003ca href=\\\"https://www.wired.com/story/perplexity-is-a-bullshit-machine/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003ecriticized\\u003c/a\\u003e\\u0026nbsp;Perplexity for breaching paywalls, ignoring publishers’ efforts to opt out, and publishing AI-generated summaries of articles produced by other companies on its own websites.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhy it matters:\\u0026nbsp;\\u003c/strong\\u003eSearch stands to be disrupted by advances in AI, and agents that browse multiple articles to synthesize a result are becoming more capable. OpenAI’s approach looks like a step forward (and smart business insofar as it leads users into deeper relationship with its models), and its strategy of licensing content from trusted sources could prove to be an advantage.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWe’re thinking:\\u003c/strong\\u003e\\u0026nbsp;In less than two years, OpenAI has revolutionized expectations of one of the web’s bedrock applications, search. Its progress shows how AI can make applications smarter, more efficient, and more responsive.\\u003c/p\\u003e\\u003chr\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174238.698.gif\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1200\\\" height=\\\"676\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/unnamed---2024-07-31T174238.698.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/unnamed---2024-07-31T174238.698.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174238.698.gif 1200w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/figure\\u003e\\u003ch1 id=\\\"web-data-increasingly-off-limits\\\"\\u003eWeb Data Increasingly Off Limits\\u003c/h1\\u003e\\u003cp\\u003eOnline publishers are moving to stop AI developers from training models on their content.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhat’s new:\\u0026nbsp;\\u003c/strong\\u003eResearchers at MIT\\u0026nbsp;\\u003ca href=\\\"https://www.dataprovenance.org/consent-in-crisis-paper?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eanalyzed\\u003c/a\\u003e\\u0026nbsp;websites whose contents appear in widely used training datasets. Between 2023 and 2024, many of these websites changed their terms of service to ban web crawlers, restricted the pages they permit web crawlers to access, or both.\\u003cbr\\u003e\\u003cbr\\u003e\\u003cstrong\\u003eHow it works:\\u003c/strong\\u003e\\u0026nbsp;MIT’s Data Provenance Initiative examined 14,000 websites whose contents are included in three large datasets, each of which contains data from between 16 and 45 million websites:\\u0026nbsp;\\u003ca href=\\\"https://huggingface.co/datasets/legacy-datasets/c4?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eC4\\u003c/a\\u003e\\u0026nbsp;(1.4 trillion text tokens from Common Crawl),\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2306.01116?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eRefinedWeb\\u003c/a\\u003e\\u0026nbsp;(3 trillion to 6 trillion text tokens plus image links), and\\u0026nbsp;\\u003ca href=\\\"https://allenai.github.io/dolma/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eDolma\\u003c/a\\u003e\\u0026nbsp;(3 trillion text tokens).\\u0026nbsp;\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eThe authors segmented each dataset into a head (2,000 websites that contributed the most tokens to each dataset) and a tail. Uniting the three heads yielded approximately 4,000 high-contribution sites (since content from some of these sites appears in more than one dataset). To represent the tail, they randomly sampled 10,000 other websites that appear in at least one dataset.\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eThey examined each website’s terms of service and\\u0026nbsp;\\u003ca href=\\\"https://www.cloudflare.com/learning/bots/what-is-robots-txt/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003erobots.txt\\u003c/a\\u003e, a text file that tells web crawlers which pages they can access, for restrictions on using the website’s content. (Robots.txt is an honor system; no mechanism exists to enforce it.)\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eResults:\\u0026nbsp;\\u003c/strong\\u003eIn the past year, websites responsible for half of all tokens (text scraped and encoded for use as training data) in the study changed their terms of service to forbid either crawlers in general or use of their content to train AI systems. Robots.txt files showed the same shift.\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eIn April 2023, robots.txt files restricted less than 3 percent of tokens in the head and 1 percent of all tokens in the study. One year later, they restricted around 28 percent of tokens in the head and 5 percent of all tokens.\\u003c/li\\u003e\\u003cli\\u003eSome types of websites are growing more restrictive than others. In April 2023, news websites in the head used robots.txt to restrict 3 percent of their tokens. In April 2024, that number rose to 45 percent.\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eWebsites are restricting some crawlers significantly more than others. Websites that represent more than 25 percent of tokens included in C4’s head restricted OpenAI’s crawler, but less than 5 percent of them restricted Cohere’s and Meta’s. By contrast, 1 percent restricted Google’s search crawler.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eBehind the news:\\u0026nbsp;\\u003c/strong\\u003eData that once was freely available is becoming harder to obtain on multiple fronts. Software developers, authors, newspapers, and music labels have\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/judge-dismisses-key-arguments-in-ai-copyright-lawsuit-against-github-microsoft-and-openai/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003efiled\\u003c/a\\u003e\\u0026nbsp;lawsuits that allege that AI developers trained systems on their data in violation of the law.\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/openai-licenses-financial-times-archive-in-fifth-deal-with-major-news-publishers/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eOpenAI\\u003c/a\\u003e\\u0026nbsp;and others recently agreed to pay licensing fees to publishers for access to their material. Last year, Reddit and Stack Overflow started\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/reddit-and-stack-overflow-ask-ai-devs-to-pay-for-data/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003echarging\\u003c/a\\u003e\\u0026nbsp;AI developers for use of their APIs.\\u003cbr\\u003e\\u003cbr\\u003e\\u003cstrong\\u003eYes, but:\\u003c/strong\\u003e\\u0026nbsp;The instructions in robots.txt files are not considered mandatory, and web crawlers can disregard them. Moreover, most websites have little ability to enforce their terms of use, which opens loopholes. For instance, if a site disallows one company’s crawler, the company may hire an intermediary to scrape the site.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhy it matters:\\u0026nbsp;\\u003c/strong\\u003eAI systems rely on ample, high-quality training data to attain high performance. Restrictions on training data give developers less scope to build valuable models. In addition to affecting commercial AI developers, they may also limit research in academia and the nonprofit sector.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWe’re thinking:\\u0026nbsp;\\u003c/strong\\u003eWe would prefer that AI developers be allowed to train on data that’s available on the open web. We hope that future court decisions and legislation will affirm this.\\u003c/p\\u003e\\u003chr\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174326.474.png\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1200\\\" height=\\\"676\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/unnamed---2024-07-31T174326.474.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/unnamed---2024-07-31T174326.474.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174326.474.png 1200w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/figure\\u003e\\u003ch1 id=\\\"synthetic-data-factory\\\"\\u003eSynthetic Data Factory\\u003c/h1\\u003e\\u003cp\\u003eResearchers increasingly fine-tune models on synthetic data, but generated datasets may not be sufficiently diverse. New work used agentic workflows to produce diverse synthetic datasets.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhat’s new:\\u003c/strong\\u003e\\u0026nbsp;Arindam Mitra, Luciano Del Corro, Guoqing Zheng, and colleagues at Microsoft introduced\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2407.03502?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eAgentInstruct\\u003c/a\\u003e, a framework for producing synthetic data for fine-tuning large language models (LLMs).\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eKey insight:\\u003c/strong\\u003e\\u0026nbsp;To generate synthetic data for fine-tuning, researchers typically prompt an LLM to generate responses (and possibly further prompts) using a\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2304.03277?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eselection of existing prompts\\u003c/a\\u003e. While training on the resulting dataset can improve model performance, the synthetic data’s distribution may not match that of real-world data, yielding inconsistent performance. A more methodical approach can generate data closer to the real-world distribution: First generate prompts from each example in a large, diverse dataset, then generate responses.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eHow it works:\\u003c/strong\\u003e\\u0026nbsp;The authors generated a synthetic text dataset based on\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2401.14624?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003ethree\\u003c/a\\u003e\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2402.07625?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eunlabeled\\u003c/a\\u003e\\u0026nbsp;\\u003ca href=\\\"https://huggingface.co/datasets/codeparrot/github-code-clean?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003edatasets\\u003c/a\\u003e\\u0026nbsp;(including code) scraped from the web. They generated new examples for 17 tasks, including natural language tasks like reading comprehension and word puzzles as well as coding, tool use, and estimating measurements.\\u0026nbsp;\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eUsing an unspecified LLM, they generated prompts (text plus an instruction) using three agentic workflows they called content transformation (which created variations on the text that offer wider latitude for generating instructions), instruction generation, and instruction refinement (which made the instructions more complicated or unsolvable).\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eFor each task, they manually defined a team of agents to perform each workflow. For example, for the reading comprehension task, content transformation agents transformed raw text into a poem, satire, or other stylistic or formal variation. Instruction generation agents generated questions to ask about the transformed text based on an author-defined list of 43 types of questions. Instruction refinement agents received each (text, question) pair and produced more pairs by either (i) modifying the passage to make the question unanswerable, (ii) modifying the passage so the correct answer became the opposite of the original answer, or (iii) modifying the questions to be more complicated or unanswerable.\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eThe authors combined the resulting 22 million (text, instruction) prompts with prompts used to train Orca-1, Orca-2, and Orca-Math, for a total of 25.8 million prompts. Then they generated responses and fine-tuned\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2310.06825?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR\\\" rel=\\\"noopener\\\"\\u003eMistral-7B\\u003c/a\\u003e\\u0026nbsp;on the resulting dataset. They called the resulting model Orca-3.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eResults:\\u003c/strong\\u003e\\u0026nbsp;The authors compared Orca 3’s performance against that of competitors on 14 benchmarks. Orca 3 outperformed Mistral-7B (fine-tuned on prompts from previous versions of Orca) and Mistral-7B-Instruct (fine-tuned to respond to instructions) on 13 benchmarks. In some cases, it did so by large margins; for instance 40 percent on AGIEVAL, 54 percent on GSM8K, and 19 percent on MMLU. Orca 3 fell short of GPT-4 on 12 benchmarks.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhy it matters:\\u003c/strong\\u003e\\u0026nbsp;The authors defined agentic workflows that turn text into diverse data for fine-tuning models. Their framework offers a pattern for AI engineers who want to build synthetic datasets for other tasks.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWe’re thinking:\\u003c/strong\\u003e\\u0026nbsp;We’re excited to see agentic workflows find applications that a wide variety of AI developers might put to use!\\u003c/p\\u003e\\u003chr\\u003e\\u003ch2 id=\\\"a-message-from-rapidfire-ai\\\"\\u003eA MESSAGE FROM\\u0026nbsp;RAPIDFIRE AI\\u003c/h2\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003ca href=\\\"https://forms.gle/o9yqbp2HGriwnZWk6?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/DL.AI-Ad--6-.png\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1680\\\" height=\\\"945\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/DL.AI-Ad--6-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/DL.AI-Ad--6-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/07/DL.AI-Ad--6-.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/07/DL.AI-Ad--6-.png 1680w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/a\\u003e\\u003c/figure\\u003e\\u003cp\\u003eTell us about your deep learning use cases and issues that need to be addressed and get a chance to win a $200 Amazon gift card! Take 10 minutes to fill out this\\u003cstrong\\u003e\\u0026nbsp;\\u003c/strong\\u003e\\u003ca href=\\\"https://forms.gle/o9yqbp2HGriwnZWk6?ref=dl-staging-website.ghost.io\\\" rel=\\\"noreferrer\\\"\\u003equick survey\\u003c/a\\u003e\\u0026nbsp;now\\u003c/p\\u003e\",\"comment_id\":\"66aabc656032ae000139f174\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T173743.998-1.png\",\"featured\":true,\"visibility\":\"public\",\"created_at\":\"2024-07-31T15:36:21.000-07:00\",\"updated_at\":\"2024-08-12T07:41:42.000-07:00\",\"published_at\":\"2024-07-31T15:48:54.000-07:00\",\"custom_excerpt\":\"The Batch AI News and Insights: Last week, I wrote about why working on a concrete startup or project idea — meaning a specific product envisioned in enough detail that we can build it for a specific target user — lets you go faster. \",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":null,\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/the-batch/\"},{\"id\":\"66ba1f23718eb4000198dd5f\",\"name\":\"issue-260\",\"slug\":\"issue-260\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/issue-260/\"},{\"id\":\"66da10ad98bf2a0001c4990c\",\"name\":\"Jul 31, 2024\",\"slug\":\"jul-31-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/jul-31-2024/\"}],\"primary_tag\":{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/the-batch/\"},\"url\":\"https://dl-staging-website.ghost.io/issue-260/\",\"excerpt\":\"The Batch AI News and Insights: Last week, I wrote about why working on a concrete startup or project idea — meaning a specific product envisioned in enough detail that we can build it for a specific target user — lets you go faster. \",\"reading_time\":14,\"access\":true,\"comments\":false,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":\"Llama 3.1 is State-of-the-Art and Open, Web Data Goes Dark, and more\",\"meta_description\":\"The Batch AI News and Insights: Last week, I wrote about why working on a concrete startup or project idea — meaning a specific product envisioned...\",\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"66a1587fee9afc0001640ade\",\"uuid\":\"4c3e1fea-d0bc-4bfc-94fd-c8866c85827c\",\"title\":\"OpenAI Shrinks GPT-4o, Meta Withholds Models From Europe, Investors Hoard GPUs, Synthetic Talking Heads Get Expressive\",\"slug\":\"issue-259\",\"html\":\"\\u003cp\\u003eDear friends,\\u003c/p\\u003e\\u003cp\\u003eAI’s usefulness in a wide variety of applications creates many opportunities for entrepreneurship. In this letter, I’d like to share what might be a counter-intuitive best practice that I’ve learned from leading \\u003ca href=\\\"http://aifund.ai/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eAI Fund\\u003c/u\\u003e\\u003c/a\\u003e, a venture studio that has built dozens of startups with extraordinary entrepreneurs. When it comes to building AI applications, we strongly prefer to work on a \\u003cem\\u003econcrete idea\\u003c/em\\u003e, meaning a specific product envisioned in enough detail that we can build it for a specific target user.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eSome design philosophies say you shouldn’t envision a specific product from the start. Instead, they recommend starting with a problem to be solved and then carefully studying the market before you devise a concrete solution. There’s a reason for this: The more concrete or precise your product specification, the more likely it is to be off-target. However, I find that having something specific to execute toward lets you go much faster and discover and fix problems more rapidly along the way. If the idea turns out to be flawed, rapid execution will let you discover the flaws sooner, and this knowledge and experience will help you switch to a different concrete idea.\\u003c/p\\u003e\\u003cp\\u003eOne test of concreteness is whether you’ve specified the idea in enough detail that a product/engineering team could build an initial prototype. For example, “AI for livestock farming” is not concrete; it’s vague. If you were to ask an engineer to build this, they would have a hard time knowing what to build.\\u0026nbsp; Similarly, “AI for livestock tracking in farming” is still vague. There are so many approaches to this that most reasonable engineers wouldn’t know what to build. But “Apply face recognition to cows so as to recognize individual cows and monitor their movement on a farm” is specific enough that a good engineer could quickly choose from the available options (for example, what algorithm to try first, what camera resolution to use, and so on) to let us relatively efficiently assess:\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003e\\u003cstrong\\u003eTechnical feasibility:\\u003c/strong\\u003e For example, do face recognition algorithms developed for human faces work for cows? (It turns out that they do!)\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003e\\u003cstrong\\u003eBusiness feasibility:\\u003c/strong\\u003e Does the idea add enough value to be worth building? (Talking to farmers might quickly reveal that solutions like RFID are easier and cheaper.)\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003eArticulating a concrete idea — which is more likely than a vague idea to be wrong — takes more courage. The more specific an idea, the more likely it is to be a bit off, especially in the details. The general area of AI for livestock farming seems promising, and surely there will be good ways to apply AI for livestock. In contrast, specifying a concrete idea, which is much easier to invalidate, is scary.\\u003c/p\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--75--1.jpg\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1200\\\" height=\\\"676\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/unnamed--75--1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/unnamed--75--1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--75--1.jpg 1200w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/figure\\u003e\\u003cp\\u003eThe benefit is that the clarity of a specific product vision lets a team execute much faster. One strong predictor of how likely a startup is to succeed is the speed with which it can get stuff done. This is why founders with clarity of vision tend to be desired; clarity helps drive a team in a specific direction. Of course, the vision has to be a good one, and there’s always a risk of efficiently building something that no one wants to buy! But a startup is unlikely to succeed if it meanders for too long without forming a clear, concrete vision.\\u003c/p\\u003e\\u003cp\\u003eBuilding toward something concrete — if you can do so in a responsible way that doesn’t harm others — lets you get critical feedback more efficiently and, if necessary, switch directions sooner. (See my \\u003ca href=\\\"https://www.deeplearning.ai/the-batch/how-to-build-ai-products-and-businesses-two-strategies?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eletter\\u003c/u\\u003e\\u003c/a\\u003e on when it’s better to go with a “Ready, Fire, Aim” approach to projects.) One factor that favors this approach is the low cost of experimenting and iterating. This is increasingly the case for many AI applications, but perhaps less so for deep-tech AI projects.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eI realize that this advice runs counter to common practice in \\u003ca href=\\\"https://wind4change.com/design-thinking-d-school-stanford-ideo-approach-methodology/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003edesign thinking\\u003c/u\\u003e\\u003c/a\\u003e, which warns against leaping to a solution too quickly, and instead advocates spending time understanding end-users, deeply understanding their problems, and brainstorming a wide range of solutions. If you’re starting without any ideas, then such an extended process can be a good way to develop good ideas. Further, keeping ideas open-ended can be good for curiosity-driven research, where investing to pursue deep tech with only a vague direction in mind can pay huge dividends over the long term.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eIf you are thinking about starting a new AI project, consider whether you can come up with a concrete vision to execute toward. Even if the initial vision turns out not to be quite right, rapid iteration will let you discover this sooner, and the learnings will let you switch to a different concrete idea.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eThrough working with many large corporations, AI Fund has developed best practices for identifying concrete ideas relevant to a business. I’ll share more on this in a later letter.\\u003c/p\\u003e\\u003cp\\u003eKeep learning!\\u003c/p\\u003e\\u003cp\\u003eAndrew\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003c/p\\u003e\\u003ch2 id=\\\"a-message-from-deeplearningai\\\"\\u003eA MESSAGE FROM\\u0026nbsp;DEEPLEARNING.AI\\u003c/h2\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003ca href=\\\"https://www.deeplearning.ai/short-courses/intro-to-federated-learning?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-23T084952.204.png\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1680\\\" height=\\\"945\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-23T084952.204.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-23T084952.204.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-23T084952.204.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-23T084952.204.png 1680w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/a\\u003e\\u003c/figure\\u003e\\u003cp\\u003eLearn how to build secure, privacy-focused federated learning systems using the Flower framework in a new two-part short course. Start with the basics in “Intro to Federated Learning,” and explore advanced techniques in “Federated Fine-tuning of LLMs with Private Data.”\\u0026nbsp;\\u003ca href=\\\"https://www.deeplearning.ai/short-courses/intro-to-federated-learning?ref=dl-staging-website.ghost.io\\\" rel=\\\"noreferrer\\\"\\u003eEnroll for free\\u003c/a\\u003e\\u003c/p\\u003e\\u003cp\\u003e\\u003c/p\\u003e\\u003ch1 id=\\\"news\\\"\\u003eNews\\u003c/h1\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-24T144159.287.gif\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1200\\\" height=\\\"676\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/unnamed---2024-07-24T144159.287.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/unnamed---2024-07-24T144159.287.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-24T144159.287.gif 1200w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/figure\\u003e\\u003ch1 id=\\\"mini-but-mighty\\\"\\u003eMini but Mighty\\u003c/h1\\u003e\\u003cp\\u003eA slimmed-down version of Open AI’s multimodal flagship packs a low-price punch.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhat’s new:\\u003c/strong\\u003e OpenAI \\u003ca href=\\\"https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003ereleased\\u003c/u\\u003e\\u003c/a\\u003e GPT-4o mini, a smaller text-image-video-audio generative model that, according to the company, generally outperforms models from Google and Anthropic models of similar size at a lower price for API access. It newly underpins the free version of ChatGPT.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eHow it works:\\u003c/strong\\u003e GPT-4o mini currently accepts text and image inputs and outputs text. Image output as well as video and audio input/output are coming soon. OpenAI did not provide information about its architecture or training but \\u003ca href=\\\"https://techcrunch.com/2024/07/18/openai-unveils-gpt-4o-mini-a-small-ai-model-powering-chatgpt/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003etold\\u003c/u\\u003e\\u003c/a\\u003e \\u003cem\\u003eTechCrunch\\u003c/em\\u003e it’s roughly the size of Claude 3 Haiku, Gemini 1.5 Flash, and the 8-billion-parameter version of Llama 3. It has a context window of 128,000 tokens and can output up to around 16,400 tokens.\\u0026nbsp;\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eAPI access to GPT-4o mini, which \\u003ca href=\\\"https://openai.com/api/pricing/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003ecosts\\u003c/u\\u003e\\u003c/a\\u003e $0.15/$0.60 per 1 million input/output tokens. That’s significantly less than the more capable GPT-4o ($5/$15 per 1 million input/output tokens with the same context window). It’s also more cost-effective and significantly better performing than GPT-3.5 Turbo ($0.50/$1.50 per 1 million input/output tokens with a 16,000-token context window).\\u003c/li\\u003e\\u003cli\\u003eOn the \\u003ca href=\\\"https://paperswithcode.com/dataset/mmlu?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eMMLU\\u003c/u\\u003e\\u003c/a\\u003e language understanding benchmark, GPT-4o mini beats Gemini 1.5 Flash at a lower cost, according to tests by \\u003ca href=\\\"https://artificialanalysis.ai/models/gpt-4o-mini?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eArtificial Analysis\\u003c/u\\u003e\\u003c/a\\u003e. It’s just behind Llama 3 70B and \\u003ca href=\\\"https://arxiv.org/abs/2404.12387?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eReka Core\\u003c/u\\u003e\\u003c/a\\u003e but costs around half as much as the former and 1/20th as much as the latter.\\u003c/li\\u003e\\u003cli\\u003eGPT-4o mini (which generates 108 tokens per second) is slower than Llama 3 8B (166 tokens per second), Gemini 1.5 Flash (148 tokens per second), and Claude 3 Haiku (127 tokens per second) according to Artificial Analysis. However, GPT-4o mini speeds past GPT-4o, which produces 63 tokens per second.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eBehind the news:\\u003c/strong\\u003e GPT-4o mini part of a July wave of smaller large language models.\\u0026nbsp;\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eMistral and Nvidia jointly \\u003ca href=\\\"https://mistral.ai/news/mistral-nemo/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003ereleased\\u003c/u\\u003e\\u003c/a\\u003e Mistral NeMo (12 billion parameters). Its context window is 128,000 tokens, equal to GPT-4o mini and larger than most models of its size. It’s available under the Apache 2.0 open source license.\\u003c/li\\u003e\\u003cli\\u003eHugging Face \\u003ca href=\\\"https://huggingface.co/blog/smollm?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003edebuted\\u003c/u\\u003e\\u003c/a\\u003e SmolLM, a family of three even smaller models — 135 million, 362 million, and 1.71 billion parameters — designed to run on mobile devices. The base and instruction-tuned versions including weights are freely available for download with no restrictions on commercial use. SmolLM is licensed under Apache 2.0.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhy it matters:\\u003c/strong\\u003e Powerful multimodal models are becoming ever more widely available at lower prices, creating opportunities for developers and researchers alike. GPT-4o mini sets a new standard for others to beat. Its price may be especially appealing to developers who aim to build agentic workflows that require models to process large numbers of tokens on their way to producing output.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWe’re thinking:\\u003c/strong\\u003e Not long ago, pushing the edge of large language models meant making them larger, with higher computing costs to drive rising parameter counts. But building bigger models has made it easier to develop smaller models that are more cost-effective and nearly as capable. It’s a virtuous circle: Costs fall and productivity rises to everyone’s benefit.\\u003c/p\\u003e\\u003chr\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--76-.jpg\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1200\\\" height=\\\"676\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/unnamed--76-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/unnamed--76-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--76-.jpg 1200w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/figure\\u003e\\u003ch1 id=\\\"meta-withholds-models-from-europe\\\"\\u003eM\\u003cstrong\\u003eeta Withholds Models From Europe\\u003c/strong\\u003e\\u003c/h1\\u003e\\u003cp\\u003eEuropean users won’t have access to Meta’s multimodal models.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhat’s new:\\u003c/strong\\u003e Meta said it would \\u003ca href=\\\"https://www.axios.com/2024/07/17/meta-future-multimodal-ai-models-eu?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003ewithhold\\u003c/u\\u003e\\u003c/a\\u003e future multimodal models from the European Union (EU) to avoid being charged, banned, or fined for running afoul of the region’s privacy laws, according to Axios. (The newly released \\u003ca href=\\\"https://ai.meta.com/blog/meta-llama-3-1/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eLlama 3.1\\u003c/u\\u003e\\u003c/a\\u003e family, which processes text only, will be available to EU users.) \\u003cbr\\u003e\\u003cbr\\u003e\\u003cstrong\\u003eHow it works:\\u003c/strong\\u003e EU data regulators have said that Meta may be violating EU privacy laws by training models on data from Facebook, Instagram, and its other properties. Meta’s move in Europe follows its \\u003ca href=\\\"https://www.reuters.com/technology/artificial-intelligence/meta-decides-suspend-its-generative-ai-tools-brazil-2024-07-17/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003ewithdrawal\\u003c/u\\u003e\\u003c/a\\u003e of generative models from Brazil, after that country’s national data-protection authority \\u003ca href=\\\"https://www.reuters.com/technology/artificial-intelligence/brazil-authority-suspends-metas-ai-privacy-policy-seeks-adjustment-2024-07-02/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003estruck down\\u003c/u\\u003e\\u003c/a\\u003e the part of Meta’s privacy policy that allowed it to use personal data from users of Meta products to train AI models.\\u0026nbsp;\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eEU companies will not be able to build applications on future multimodal models from Meta. Companies outside the EU that build products based on these models will not be able to deliver them to EU customers. Text-only versions including Llama 3.1, as well as applications built on them, will continue to be available in the EU.\\u003c/li\\u003e\\u003cli\\u003eIn a blog post in May, Meta \\u003ca href=\\\"https://about.fb.com/news/h/bringing-generative-ai-experiences-to-people-in-europe/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eannounced\\u003c/u\\u003e\\u003c/a\\u003e that it would train models on text and images that are publicly visible on Meta-owned services; for example, public Facebook posts and public Instagram photos and their captions. The data-protection authorities of 11 EU member states (including Ireland, where Meta’s European headquarters is located), objected to Meta’s collection of this data from EU users. Meta responded by \\u003ca href=\\\"https://about.fb.com/news/2024/06/building-ai-technology-for-europeans-in-a-transparent-and-responsible-way/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003edelaying\\u003c/u\\u003e\\u003c/a\\u003e its collection of user data in the EU.\\u003c/li\\u003e\\u003cli\\u003eThe UK has a nearly \\u003ca href=\\\"https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/06/statement-in-response-to-metas-plans-to-train-generative-ai-with-user-data/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eidentical\\u003c/u\\u003e\\u003c/a\\u003e data-protection law, but Meta does not plan to restrict its models there. That’s because UK regulators have been clearer than their EU counterparts about the law’s requirements, a Meta representative told Axios.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eApple and OpenAI in Europe:\\u003c/strong\\u003e Meta is not the only global AI company that’s wary of EU technology regulations.\\u0026nbsp;\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eIn June, Apple \\u003ca href=\\\"https://www.cnbc.com/2024/06/21/apple-ai-europe-dma-macos.html?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eannounced\\u003c/u\\u003e\\u003c/a\\u003e it would withhold \\u003ca href=\\\"https://www.deeplearning.ai/the-batch/apple-unveils-ai-features-in-new-ios-and-macos-update-during-wwdc/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003egenerative AI features\\u003c/u\\u003e\\u003c/a\\u003e from iOS devices in the EU. Apple said the EU’s \\u003ca href=\\\"https://digital-markets-act.ec.europa.eu/index_en?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eDigital Markets Act\\u003c/u\\u003e\\u003c/a\\u003e, which requires that basic applications like web browsers, search engines, and messaging be able to work together regardless of the operating systems they run on, prevented it from deploying the features to EU customers without compromising user privacy.\\u003c/li\\u003e\\u003cli\\u003eEarly in the year, OpenAI \\u003ca href=\\\"https://www.bbc.com/news/technology-68128396?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003edrew\\u003c/u\\u003e\\u003c/a\\u003e attention from Italian regulators, who briefly \\u003ca href=\\\"https://www.deeplearning.ai/the-batch/italy-blocked-chatgpt-for-alleged-privacy-violations/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003ebanned\\u003c/u\\u003e\\u003c/a\\u003e ChatGPT in 2023 for violating EU law. As of May, a multinational task force was \\u003ca href=\\\"https://www.edpb.europa.eu/system/files/2024-05/edpb_20240523_report_chatgpt_taskforce_en.pdf?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003einvestigating\\u003c/u\\u003e\\u003c/a\\u003e the matter.\\u0026nbsp;\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhy it matters:\\u003c/strong\\u003e Different regions are taking different paths toward regulating AI. The EU is more restrictive than others, creating barriers to AI companies that develop new technology and products. Meta and Apple are taking proactive steps to reduce their risks even if it means foregoing portions of the European market.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWe’re thinking:\\u003c/strong\\u003e We hope regulators everywhere will think hard about how to strike a balance between protecting innovation and other interests. In this instance, the EU’s regulations have prompted Meta to make a decision that likely likely set back European AI while delivering little benefit to citizens.\\u003c/p\\u003e\\u003chr\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--77-.jpg\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1200\\\" height=\\\"676\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/unnamed--77-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/unnamed--77-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--77-.jpg 1200w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/figure\\u003e\\u003ch1 id=\\\"ai-investors-hoard-gpu-power\\\"\\u003e\\u003cstrong\\u003eAI Investors Hoard GPU Power\\u003c/strong\\u003e\\u003c/h1\\u003e\\u003cp\\u003eInvestors have been gathering AI chips to attract AI startups.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhat’s new:\\u003c/strong\\u003e Venture-capital firms are stockpiling high-end graphics processing units (GPUs), according to a \\u003ca href=\\\"https://www.theinformation.com/articles/andreessen-horowitz-is-building-a-stash-of-more-than-20-000-gpus-to-win-ai-deals?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003ereport\\u003c/u\\u003e\\u003c/a\\u003e by \\u003cem\\u003eThe Information\\u003c/em\\u003e. They’re using the hardware to provide processing power to their portfolio companies at reduced or no cost.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eHow it works:\\u003c/strong\\u003e Andreessen Horowitz (A16Z), a prominent Silicon Valley venture investment firm, has amassed the largest known stock of GPUs dedicated to venture-funded startups. The firm plans to acquire more than 20,000 GPUs including top-of-the-line Nvidia H100s, which can sell for tens of thousands of dollars each — roughly enough to train a competitive large language model.\\u0026nbsp;\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eA16Z offers access at below-market rates or in exchange for equity in startups it funds.\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eWhether A16Z purchased GPUs or ia paying a third-party cloud provider for access is not clear.\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eLuma AI, funded by A16Z, used the venture firm’s compute resources and, in June, released the \\u003ca href=\\\"https://www.deeplearning.ai/the-batch/claude-3-5-sonnet-is-powerful-inexpensive-and-speedy/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eDream Machine\\u003c/u\\u003e\\u003c/a\\u003e video generator. Luma AI CEO and co-founder Amit Jain said the company turned down funders who offered more lucrative terms because A16Z offered GPUs.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eBehind the news:\\u003c/strong\\u003e High-end GPUs were in \\u003ca href=\\\"https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eshort supply\\u003c/u\\u003e\\u003c/a\\u003e early last year. The shortage has \\u003ca href=\\\"https://www.tomshardware.com/pc-components/gpus/nvidias-h100-ai-gpu-shortages-ease-as-lead-times-drop-from-up-to-four-months-to-8-12-weeks?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eeased\\u003c/u\\u003e\\u003c/a\\u003e significantly, but getting access to enough processing power to train and run large models still isn’t easy. A16Z follows several other investors that have sought to fill the gap for startups.\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eEx-GitHub CEO Nat Friedman and Daniel Gross, who has provided capital to startups including Github, Character.ai, Perplexity.ai, and Uber, \\u003ca href=\\\"https://www.forbes.com/sites/kenrickcai/2024/02/14/ai-investors-are-wooing-startups-with-massive-computing-clusters/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eestablished\\u003c/u\\u003e\\u003c/a\\u003e the Andromeda Cluster, a group of supercomputers with more than 4,000 GPUs between them, including over 2,500 H100s. They offer access to startups in their portfolio at below-market rates.\\u003c/li\\u003e\\u003cli\\u003eLast year, Index Ventures \\u003ca href=\\\"https://techcrunch.com/2023/08/19/how-index-ventures-jumped-to-the-front-of-the-ai-gpu-line/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eagreed\\u003c/u\\u003e\\u003c/a\\u003e to pay Oracle for access to H100 and A100 GPUs. In turn, it made them available to portfolio companies for free.\\u003c/li\\u003e\\u003cli\\u003eMicrosoft \\u003ca href=\\\"https://blogs.microsoft.com/blog/2023/11/07/startups-to-access-high-performance-azure-infrastructure-accelerating-ai-breakthroughs/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eprovides\\u003c/u\\u003e\\u003c/a\\u003e free access to GPUs via its Azure cloud service to startups funded by its venture fund M12 and the venture accelerator Y Combinator.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eYes, but:\\u003c/strong\\u003e David Cahn, a partner at A16Z rival Sequoia Capital, \\u003ca href=\\\"https://www.sequoiacap.com/article/ais-600b-question/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eargues\\u003c/u\\u003e\\u003c/a\\u003e that stockpiling GPUs is a mistake that could leave venture funds holding large quantities of expensive, rapidly depreciating, hardware. Cahn believes startups and small developers soon may have an easier time getting their hands on the processing power they need. Nvidia recently \\u003ca href=\\\"https://www.deeplearning.ai/the-batch/all-about-nvidias-new-blackwell-architecture-and-b200-gpu/?ref=dl-staging-website.ghost.io\\\"\\u003e\\u003cu\\u003eannounced\\u003c/u\\u003e\\u003c/a\\u003e its new B100 and B200 GPUs, whose arrival should stanch demand for older units like the H100.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhy it matters:\\u003c/strong\\u003e AI startups are hot, and venture-capital firms compete for early equity in the most promising ones. In addition to funding, they frequently offer advice, contacts, office support — and now processing power to empower a startup to realize its vision.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWe’re thinking:\\u003c/strong\\u003e Venture investors who use GPUs to sweeten a deal give new meaning to the phrase “bargaining chips.”\\u003c/p\\u003e\\u003chr\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-24T144606.148.gif\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"600\\\" height=\\\"337\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-24T144606.148.gif 600w\\\"\\u003e\\u003c/figure\\u003e\\u003ch1 id=\\\"expressive-synthetic-talking-heads\\\"\\u003eExpressive Synthetic Talking Heads\\u003c/h1\\u003e\\u003cp\\u003ePrevious systems that produce a talking-head video from a photo and a spoken-word audio clip animate the lips and other parts of the face separately. An alternative approach achieves more expressive results by animating the head as a whole.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhat’s new:\\u003c/strong\\u003e\\u0026nbsp;Sicheng Xu and colleagues at Microsoft developed\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2404.10667?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003eVASA-1\\u003c/a\\u003e, a generative system that uses a facial portrait and spoken-word recording to produce a talking-head video with appropriately expressive motion. You can see its output\\u0026nbsp;\\u003ca href=\\\"https://www.microsoft.com/en-us/research/project/vasa-1/?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003ehere\\u003c/a\\u003e.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eKey insight:\\u003c/strong\\u003e\\u0026nbsp;When a person speaks, the facial expression and head position change over time, while the overall shapes of the face and head don’t. By learning to represent an image via separate embeddings for facial expression and head position — which change — as well as for facial structure in its 2D and 3D aspects — which don’t — a latent diffusion model can focus on the parts of the image that matter most. (\\u003ca href=\\\"https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003eLatent diffusion\\u003c/a\\u003e\\u0026nbsp;is a variant of diffusion that saves computation by processing a small, learned vector of an image instead of the image itself.)\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eHow it works:\\u0026nbsp;\\u003c/strong\\u003eVASA-1 comprises four image encoders (three 2D CNNs and one 3D CNN), one image decoder (another 2D CNN),\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2006.11477?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003eWav2Vec 2.0\\u003c/a\\u003e, and a latent diffusion image generator. The authors trained the system, given an image of a face and a recorded voice, to generate a series of video frames that conform to the voice. The training set was\\u0026nbsp;\\u003ca href=\\\"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003eVoxCeleb2\\u003c/a\\u003e, which includes over 1 million short videos of celebrities talking. The authors added labels for gaze direction, head-to-camera distance, and an emotional intensity score computed\\u0026nbsp;\\u003ca href=\\\"https://link.springer.com/article/10.3758/s13428-018-1133-5?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003eby\\u003c/a\\u003e\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/1903.08527?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003eseparate\\u003c/a\\u003e\\u0026nbsp;\\u003ca href=\\\"https://github.com/av-savchenko/face-emotion-recognition?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003esystems\\u003c/a\\u003e.\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eGiven an image of a face, the encoders\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/pdf/2207.07621?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003elearned\\u003c/a\\u003e\\u0026nbsp;to generate embeddings that represented the 2D facial structure (which the authors call “identity”), 3D contours (“appearance”), head position, and facial expression. Given the embeddings, the decoder reconstructed the image. The authors trained the encoders and decoder together using eight loss terms. For instance, one loss term encouraged the system to reconstruct the image. Another encouraged the system, when it processes a different image of the same person (with different head positions and facial expressions), to produce a similar identity embedding.\\u003c/li\\u003e\\u003cli\\u003eGiven a video, the trained encoders produced a sequence of paired head-position and facial-expression embeddings, which the authors call a “motion sequence.”\\u003c/li\\u003e\\u003cli\\u003eGiven the accompanying voice recording, a pretrained Wav2Vec2\\u0026nbsp; produced a sequence of audio embeddings.\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eGiven the audio embeddings that correspond to a series of consecutive frames, the latent diffusion model learned to generate the corresponding embeddings in the motion sequence. It also received other inputs including previous audio and motion sequence embeddings, gaze direction, head-to-camera distances, and emotional-intensity scores.\\u003c/li\\u003e\\u003cli\\u003eAt inference, given an arbitrary image of a face and an audio clip, VASA produced the appearance and identity embeddings. Then it produced audio embeddings and motion-sequence embeddings. It generated the final video by feeding the appearance, identity, and motion sequence embeddings to its decoder.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003e\\u003cstrong\\u003eResults:\\u003c/strong\\u003e\\u0026nbsp;The authors measured their results by training a model similar to\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2103.00020?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003eCLIP\\u003c/a\\u003e\\u0026nbsp;that produces a similarity score on how well spoken audio matches a video of a person speaking (higher is better). On the VoxCeleb2 test set, their approach produced a similarity score of 0.468 compared to 0.588 for real video. The nearest contender,\\u0026nbsp;\\u003ca href=\\\"https://arxiv.org/abs/2211.12194?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf\\\" rel=\\\"noopener\\\"\\u003eSadTalker\\u003c/a\\u003e, which generates lip, eye, and head motions separately, achieved a similarity score of 0.441.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWhy it matters:\\u003c/strong\\u003e\\u0026nbsp;By learning to embed different aspects of a face separately, the system maintained the face’s distinctive, unchanging features while generating appropriate motions. This also made the system more flexible at inference: The authors demonstrated its ability to extract a video’s facial expressions and head movements and apply them to different faces.\\u003c/p\\u003e\\u003cp\\u003e\\u003cstrong\\u003eWe’re thinking:\\u003c/strong\\u003e\\u0026nbsp;Never again will we take talking-head videos at face value!\\u003c/p\\u003e\\u003chr\\u003e\\u003ch2 id=\\\"a-message-from-workera\\\"\\u003eA MESSAGE FROM WORKERA\\u003c/h2\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003ca href=\\\"https://workera.ai/try-for-free?utm_source=pressrelease\\u0026utm_medium=paidsocial\\u0026utm_campaign=TryForFree\\u0026utm_term=TheBatch\\u0026utm_content=TheBatch\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-23T090621.368.png\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1200\\\" height=\\\"675\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/07/unnamed---2024-07-23T090621.368.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/07/unnamed---2024-07-23T090621.368.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-23T090621.368.png 1200w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/a\\u003e\\u003c/figure\\u003e\\u003cp\\u003eTest, benchmark, and grow your skills with new assessments from Workera! Available domains include AI Foundations, Machine Learning, GenAI, and MLOps.\\u0026nbsp;\\u003ca href=\\\"https://workera.ai/try-for-free?utm_source=pressrelease\\u0026utm_medium=paidsocial\\u0026utm_campaign=TryForFree\\u0026utm_term=TheBatch\\u0026utm_content=TheBatch\\\" rel=\\\"noreferrer\\\"\\u003eTry Workera today for $0!\\u003c/a\\u003e\\u003c/p\\u003e\",\"comment_id\":\"66a1587fee9afc0001640ade\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--75-.jpg\",\"featured\":true,\"visibility\":\"public\",\"created_at\":\"2024-07-24T12:39:43.000-07:00\",\"updated_at\":\"2024-08-12T07:42:42.000-07:00\",\"published_at\":\"2024-07-24T12:51:25.000-07:00\",\"custom_excerpt\":\"The Batch AI News and Insights: AI’s usefulness in a wide variety of applications creates many opportunities for entrepreneurship.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":null,\"tags\":[{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/the-batch/\"},{\"id\":\"66ba1f62718eb4000198dd69\",\"name\":\"issue-259\",\"slug\":\"issue-259\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/issue-259/\"},{\"id\":\"66da111c98bf2a0001c49920\",\"name\":\"Jul 24, 2024\",\"slug\":\"jul-24-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/jul-24-2024/\"}],\"primary_tag\":{\"id\":\"60bfddad274d5b003b10621c\",\"name\":\"The Batch Newsletter\",\"slug\":\"the-batch\",\"description\":\"Weekly AI news and perspective for engineers, executives, and enthusiasts.\",\"feature_image\":null,\"visibility\":\"public\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png\",\"og_title\":\"The Batch Newsletter | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png\",\"twitter_title\":\"The Batch Newsletter | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"meta_title\":\"The Batch Newsletter | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/the-batch/\"},\"url\":\"https://dl-staging-website.ghost.io/issue-259/\",\"excerpt\":\"The Batch AI News and Insights: AI’s usefulness in a wide variety of applications creates many opportunities for entrepreneurship.\",\"reading_time\":13,\"access\":true,\"comments\":false,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":\"OpenAI Shrinks GPT-4o, Meta Withholds Models From Europe, and more\",\"meta_description\":\"The Batch AI News and Insights: AI’s usefulness in a wide variety of applications creates many opportunities for entrepreneurship...\",\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null},{\"id\":\"65fb588e4ab76700012f3fc4\",\"uuid\":\"0ba3030e-c157-440e-afd5-f78dfb0b7c52\",\"title\":\"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\",\"slug\":\"how-agents-can-improve-llm-performance\",\"html\":\"\\u003cp\\u003eDear friends,\\u003c/p\\u003e\\u003cp\\u003eI think AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.\\u003c/p\\u003e\\u003cp\\u003eToday, we mostly use LLMs in zero-shot mode, prompting a model to generate final output token by token without revising its work. This is akin to asking someone to compose an essay from start to finish, typing straight through with no backspacing allowed, and expecting a high-quality result. Despite the difficulty, LLMs do amazingly well at this task!\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eWith an agent workflow, however, we can ask the LLM to iterate over a document many times. For example, it might take a sequence of steps such as:\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003ePlan an outline.\\u003c/li\\u003e\\u003cli\\u003eDecide what, if any, web searches are needed to gather more information.\\u003c/li\\u003e\\u003cli\\u003eWrite a first draft.\\u003c/li\\u003e\\u003cli\\u003eRead over the first draft to spot unjustified arguments or extraneous information.\\u003c/li\\u003e\\u003cli\\u003eRevise the draft taking into account any weaknesses spotted.\\u003c/li\\u003e\\u003cli\\u003eAnd so on.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003eThis iterative process is critical for most human writers to write good text. With AI, such an iterative workflow yields much better results than writing in a single pass.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003e\\u003ca href=\\\"https://www.cognition-labs.com/introducing-devin?utm_campaign=The%20Batch\\u0026utm_source=hs_email\\u0026utm_medium=email\\u0026_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK\\\" rel=\\\"noopener\\\"\\u003eDevin\\u003c/a\\u003e’s splashy demo recently received a lot of social media buzz. My team has been closely following the evolution of AI that writes code. We analyzed results from a number of research teams, focusing on an algorithm’s ability to do well on the widely used HumanEval coding benchmark. You can see our findings in the diagram below.\\u0026nbsp;\\u003c/p\\u003e\\u003cfigure class=\\\"kg-card kg-image-card\\\"\\u003e\\u003cimg src=\\\"https://dl-staging-website.ghost.io/content/images/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-20T192329.626-1.png\\\" class=\\\"kg-image\\\" alt=\\\"\\\" loading=\\\"lazy\\\" width=\\\"1680\\\" height=\\\"945\\\" srcset=\\\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-20T192329.626-1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-20T192329.626-1.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-20T192329.626-1.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-20T192329.626-1.png 1680w\\\" sizes=\\\"(min-width: 720px) 720px\\\"\\u003e\\u003c/figure\\u003e\\u003cp\\u003eGPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.\\u0026nbsp;\\u003c/p\\u003e\\u003cp\\u003eOpen source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.\\u003c/p\\u003e\\u003cul\\u003e\\u003cli\\u003eReflection: The LLM examines its own work to come up with ways to improve it.\\u0026nbsp;\\u003c/li\\u003e\\u003cli\\u003eTool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.\\u003c/li\\u003e\\u003cli\\u003ePlanning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).\\u003c/li\\u003e\\u003cli\\u003eMulti-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.\\u003c/li\\u003e\\u003c/ul\\u003e\\u003cp\\u003eNext week, I’ll elaborate on these design patterns and offer suggested readings for each.\\u003c/p\\u003e\\u003cp\\u003eKeep learning!\\u003c/p\\u003e\\u003cp\\u003eAndrew\\u003c/p\\u003e\\u003cp\\u003e\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?ref=dl-staging-website.ghost.io\\\" rel=\\\"noreferrer\\\"\\u003eRead \\\"Agentic Design Patterns Part 2: Reflection\\\"\\u003c/a\\u003e\\u003c/p\\u003e\\u003cp\\u003e\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io\\\" rel=\\\"noreferrer\\\"\\u003eRead \\\"Agentic Design Patterns Part 3, Tool Use\\\"\\u003c/a\\u003e\\u003c/p\\u003e\\u003cp\\u003e\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io\\\" rel=\\\"noreferrer\\\"\\u003eRead \\\"Agentic Design Patterns Part 4: Planning\\\"\\u003c/a\\u003e\\u003c/p\\u003e\\u003cp\\u003e\\u003ca href=\\\"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io\\\" rel=\\\"noreferrer\\\"\\u003eRead \\\"Agentic Design Patterns Part 5: Multi-Agent Collaboration\\\"\\u003c/a\\u003e\\u003c/p\\u003e\",\"comment_id\":\"65fb588e4ab76700012f3fc4\",\"feature_image\":\"https://dl-staging-website.ghost.io/content/images/2024/03/unnamed--55--2.jpg\",\"featured\":true,\"visibility\":\"public\",\"created_at\":\"2024-03-20T14:43:42.000-07:00\",\"updated_at\":\"2024-05-13T07:43:22.000-07:00\",\"published_at\":\"2024-03-20T14:45:48.000-07:00\",\"custom_excerpt\":\"I think AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"custom_template\":null,\"canonical_url\":null,\"tags\":[{\"id\":\"60bfddad274d5b003b106220\",\"name\":\"Letters\",\"slug\":\"letters\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":\"Letters from Andrew Ng | The Batch\",\"meta_description\":\"Personal messages to the AI community.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/letters/\"},{\"id\":\"60ccffc170a082003e13dddb\",\"name\":\"Technical Insights\",\"slug\":\"technical-insights\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/technical-insights/\"},{\"id\":\"65fb44914ab76700012f3f7c\",\"name\":\"Mar 20, 2024\",\"slug\":\"mar-20-2024\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":null,\"meta_description\":null,\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/mar-20-2024/\"}],\"primary_tag\":{\"id\":\"60bfddad274d5b003b106220\",\"name\":\"Letters\",\"slug\":\"letters\",\"description\":null,\"feature_image\":null,\"visibility\":\"public\",\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":\"Letters from Andrew Ng | The Batch\",\"meta_description\":\"Personal messages to the AI community.\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"canonical_url\":null,\"accent_color\":null,\"url\":\"https://dl-staging-website.ghost.io/tag/letters/\"},\"url\":\"https://dl-staging-website.ghost.io/how-agents-can-improve-llm-performance/\",\"excerpt\":\"I think AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.\",\"reading_time\":2,\"access\":true,\"comments\":false,\"og_image\":null,\"og_title\":null,\"og_description\":null,\"twitter_image\":null,\"twitter_title\":null,\"twitter_description\":null,\"meta_title\":\"Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance\",\"meta_description\":\"I think AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important...\",\"email_subject\":null,\"frontmatter\":null,\"feature_image_alt\":null,\"feature_image_caption\":null}],\"totalPages\":20,\"settings\":{\"processEnv\":{\"siteUrl\":\"https://www.deeplearning.ai\",\"platform\":\"vercel\",\"darkMode\":{\"defaultMode\":\"light\",\"overrideOS\":true},\"nextImages\":{\"feature\":true,\"inline\":false,\"quality\":80,\"source\":false},\"rssFeed\":true,\"memberSubscriptions\":false,\"commenting\":{\"system\":null,\"commentoUrl\":\"https://cdn.commento.io\",\"disqusShortname\":\"short-name-here\"},\"prism\":{\"enable\":true,\"ignoreMissing\":true},\"toc\":{\"enable\":false,\"maxDepth\":2},\"isr\":{\"enable\":false,\"revalidate\":10,\"maxNumberOfPosts\":20,\"maxNumberOfPages\":20},\"algoliaEnv\":\"production\"},\"title\":\"The Batch | DeepLearning.AI\",\"description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"logo\":\"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png\",\"icon\":\"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png\",\"accent_color\":\"#F65B66\",\"cover_image\":\"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg\",\"facebook\":\"DeepLearningAIHQ/\",\"twitter\":\"@DeepLearningAI\",\"lang\":\"en\",\"locale\":\"en\",\"timezone\":\"America/Los_Angeles\",\"codeinjection_head\":null,\"codeinjection_foot\":null,\"navigation\":[],\"secondary_navigation\":[],\"meta_title\":\"The Batch | DeepLearning.AI\",\"meta_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"og_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png\",\"og_title\":\"The Batch | DeepLearning.AI\",\"og_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"twitter_image\":\"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png\",\"twitter_title\":\"The Batch | DeepLearning.AI\",\"twitter_description\":\"Weekly AI news for engineers, executives, and enthusiasts.\",\"members_support_address\":\"noreply\",\"members_enabled\":true,\"allow_self_signup\":true,\"members_invite_only\":false,\"paid_members_enabled\":false,\"firstpromoter_account\":null,\"portal_button_style\":\"icon-and-text\",\"portal_button_signup_text\":\"Subscribe\",\"portal_button_icon\":\"icon-3\",\"portal_signup_terms_html\":null,\"portal_signup_checkbox_required\":false,\"portal_plans\":[\"free\",\"monthly\",\"yearly\"],\"portal_default_plan\":\"yearly\",\"portal_name\":false,\"portal_button\":true,\"comments_enabled\":\"off\",\"recommendations_enabled\":false,\"outbound_link_tagging\":true,\"default_email_address\":\"dl-staging-website@ghost.io\",\"support_email_address\":\"noreply@dl-staging-website.ghost.io\",\"editor_default_email_recipients\":\"disabled\",\"labs\":{},\"url\":\"https://dl-staging-website.ghost.io\",\"version\":\"5.105\",\"iconImage\":{\"url\":\"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png\",\"dimensions\":{\"width\":256,\"height\":256}},\"logoImage\":{\"url\":\"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png\",\"dimensions\":{\"width\":2677,\"height\":601}},\"coverImage\":{\"url\":\"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg\",\"dimensions\":{\"width\":2000,\"height\":1335}}},\"seoImage\":{\"url\":\"https://www.deeplearning.ai/site-meta.png\",\"dimensions\":{\"width\":2048,\"height\":1024}},\"announcementBanners\":{\"nodes\":[{\"title\":\"OpenAI C4 (o1)\",\"date\":\"2024-12-18T07:37:25\",\"databaseId\":35953,\"announcementBannerCustomFields\":{\"text\":\"✨ New course! Enroll in\",\"textColor\":\"#0c0c0c\",\"courseLink\":\"https://bit.ly/3ZXjdrf\",\"courseName\":\"Reasoning with o1\",\"backgroundColor\":\"#05256C\",\"backgroundGradientColor\":\"linear-gradient(318deg, rgba(249,186,26,1) 0%, rgba(247,223,87,1) 100%)\",\"isOpenInNewTab\":true}},{\"title\":\"OpenAI C3 (Canvas)\",\"date\":\"2024-12-04T06:00:00\",\"databaseId\":35835,\"announcementBannerCustomFields\":{\"text\":\"✨ New course! Enroll in\",\"textColor\":\"#FFFFFF\",\"courseLink\":\"https://bit.ly/3OrYgy3\",\"courseName\":\"Collaborative Writing and Coding with OpenAI Canvas\",\"backgroundColor\":\"#05256C\",\"backgroundGradientColor\":\"linear-gradient(318deg, rgba(252,112,101,1) 0%, rgba(254,155,45,1) 100%)\",\"isOpenInNewTab\":true}},{\"title\":\"Together-Dungeon C1\",\"date\":\"2024-11-20T06:26:27\",\"databaseId\":35752,\"announcementBannerCustomFields\":{\"text\":\"✨ New course! Enroll in\",\"textColor\":\"#FFFFFF\",\"courseLink\":\"https://bit.ly/3CCG1U2\",\"courseName\":\"Building an AI-Powered Game\",\"backgroundColor\":\"#05256C\",\"backgroundGradientColor\":\"linear-gradient(0deg, #1f232e 0%, #1f232e 100%)\",\"isOpenInNewTab\":true}},{\"title\":\"Guardrails C1\",\"date\":\"2024-11-13T06:19:41\",\"databaseId\":35645,\"announcementBannerCustomFields\":{\"text\":\"✨ New course! Enroll in\",\"textColor\":\"#FFFFFF\",\"courseLink\":\"https://bit.ly/3YSJrtw\",\"courseName\":\"Safe and Reliable AI via Guardrails\",\"backgroundColor\":\"#05256C\",\"backgroundGradientColor\":\"linear-gradient(318deg, rgba(46,46,46,1) 0%, rgba(0,0,0,1) 100%)\",\"isOpenInNewTab\":null}},{\"title\":\"MemGPT C1\",\"date\":\"2024-11-11T01:43:46\",\"databaseId\":35628,\"announcementBannerCustomFields\":{\"text\":\"✨ New course! Enroll in\",\"textColor\":\"#FFFFFF\",\"courseLink\":\"https://bit.ly/4eb7j0L\",\"courseName\":\"LLMs as Operating Systems: Agent Memory\",\"backgroundColor\":\"#8c1d0a\",\"backgroundGradientColor\":null,\"isOpenInNewTab\":null}}]}},\"__N_SSG\":true},\"page\":\"/the-batch\",\"query\":{},\"buildId\":\"F_BMQAVRJZAkZ3uV3_heV\",\"isFallback\":false,\"isExperimentalCompile\":false,\"gsp\":true,\"scriptLoader\":[]}</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'8fa87402def64127',t:'MTczNTYyOTA2Mi4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "base_url = \"https://www.deeplearning.ai/the-batch/\"\n",
    "\n",
    "def get_website_html(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "base_url_html = get_website_html(base_url)\n",
    "print(base_url_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- https://www.deeplearning.ai/the-batch/issue-281/\n",
      "1 -- https://www.deeplearning.ai/the-batch/issue-260/\n",
      "2 -- https://www.deeplearning.ai/the-batch/issue-259/\n",
      "3 -- https://www.deeplearning.ai/the-batch/issue-280/\n",
      "4 -- https://www.deeplearning.ai/the-batch/issue-279/\n",
      "5 -- https://www.deeplearning.ai/the-batch/issue-278/\n",
      "6 -- https://www.deeplearning.ai/the-batch/issue-277/\n",
      "7 -- https://www.deeplearning.ai/the-batch/issue-276/\n",
      "8 -- https://www.deeplearning.ai/the-batch/issue-275/\n",
      "9 -- https://www.deeplearning.ai/the-batch/issue-274/\n",
      "10 -- https://www.deeplearning.ai/the-batch/issue-273/\n",
      "11 -- https://www.deeplearning.ai/the-batch/issue-272/\n",
      "12 -- https://www.deeplearning.ai/the-batch/issue-271/\n",
      "13 -- https://www.deeplearning.ai/the-batch/issue-270/\n",
      "14 -- https://www.deeplearning.ai/the-batch/issue-269/\n",
      "15 -- https://www.deeplearning.ai/the-batch/issue-268/\n",
      "16 -- https://www.deeplearning.ai/the-batch/issue-267/\n",
      "17 -- https://www.deeplearning.ai/the-batch/issue-266/\n"
     ]
    }
   ],
   "source": [
    "def get_articles_links(base_url_html):\n",
    "    soup = BeautifulSoup(base_url_html, \"html.parser\")\n",
    "    article_links = []\n",
    "    \n",
    "    for a_tag in soup.find_all(\"a\", href = True):\n",
    "        href = a_tag['href']\n",
    "        if href.startswith(\"/the-batch/issue\"):\n",
    "            full_url = f\"https://www.deeplearning.ai{href}\"\n",
    "            if full_url not in article_links:\n",
    "                article_links.append(full_url)\n",
    "                time.sleep(0.5)\n",
    "    return article_links\n",
    "\n",
    "links = get_articles_links(base_url_html)\n",
    "\n",
    "for i, link in enumerate(links):\n",
    "    print(f\"{i} -- {link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Article Text Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: articles/article_0_the-batch_issue-281.txt\n",
      "Saved: articles/article_1_the-batch_issue-260.txt\n",
      "Saved: articles/article_2_the-batch_issue-259.txt\n",
      "Saved: articles/article_3_the-batch_issue-280.txt\n",
      "Saved: articles/article_4_the-batch_issue-279.txt\n",
      "Saved: articles/article_5_the-batch_issue-278.txt\n",
      "Saved: articles/article_6_the-batch_issue-277.txt\n",
      "Saved: articles/article_7_the-batch_issue-276.txt\n",
      "Saved: articles/article_8_the-batch_issue-275.txt\n",
      "Saved: articles/article_9_the-batch_issue-274.txt\n",
      "Saved: articles/article_10_the-batch_issue-273.txt\n",
      "Saved: articles/article_11_the-batch_issue-272.txt\n",
      "Saved: articles/article_12_the-batch_issue-271.txt\n",
      "Saved: articles/article_13_the-batch_issue-270.txt\n",
      "Saved: articles/article_14_the-batch_issue-269.txt\n",
      "Saved: articles/article_15_the-batch_issue-268.txt\n",
      "Saved: articles/article_16_the-batch_issue-267.txt\n",
      "Saved: articles/article_17_the-batch_issue-266.txt\n"
     ]
    }
   ],
   "source": [
    "# def get_article_text(url: str) -> str:\n",
    "#     \"\"\"Function to fetch all articles from the home page\"\"\"\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code != 200:\n",
    "#         print(f\"Failed to fetch response from {url}. Exited with error: {response.status_code}\")\n",
    "#         return \"\"\n",
    "\n",
    "#     article_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#     main_div = article_soup.find(\"div\", class_ = \"prose--styled justify-self-center post_postContent__wGZtc\")\n",
    "#     if not main_div:\n",
    "#         print(f\"Could not find main content container in {url}\")\n",
    "#         return \"\"\n",
    "    \n",
    "#     article_text = main_div.get_text(separator=\"\\n\", strip=True)\n",
    "#     return article_text\n",
    "\n",
    "\n",
    "# os.makedirs(\"articles\", exist_ok=True)\n",
    "\n",
    "# for i, link in enumerate(links):\n",
    "#     article_text = get_article_text(link)\n",
    "#     if not article_text:\n",
    "#         print(f\"Article text not found for url: {link}\")\n",
    "#         continue\n",
    "#     slug = re.sub(r'https?://[^/]+/', '', link)  # remove scheme and domain\n",
    "#     slug = slug.strip(\"/\").replace(\"/\", \"_\")     # turn '/the-batch/issue-281/' -> 'the-batch_issue-281'\n",
    "#     file_name = f\"article_{i}_{slug}.txt\"\n",
    "    \n",
    "#     file_path = os.path.join(\"articles\", file_name)\n",
    "    \n",
    "#     with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(article_text)\n",
    "    \n",
    "#     print(f\"Saved: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(links))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/the-batch/tag/dec-25-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-white text-slate-500\">Dec 25, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/dec-18-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Dec 18, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/dec-11-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Dec 11, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/dec-04-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Dec 04, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/nov-27-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Nov 27, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/nov-20-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Nov 20, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/nov-13-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Nov 13, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/nov-06-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Nov 06, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/oct-30-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 30, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/oct-23-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 23, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/oct-16-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 16, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/oct-09-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 09, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/oct-02-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Oct 02, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/sep-25-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Sep 25, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/sep-18-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Sep 18, 2024</div></a>\n",
      "<a href=\"/the-batch/tag/sep-11-2024/\"><div class=\"inline-flex rounded-md py-1 px-3 text-[13px] font-medium mb-3 relative z-10 bg-slate-100 text-slate-500\">Sep 11, 2024</div></a>\n",
      "Total titles: 16\n",
      "Top AI Stories of 2024! Agents Rise, Prices Fall, Models Shrink, Video Takes Off, Acquisitions Morph\n",
      "\n",
      "Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, Gemini 2.0 Flash Accelerates Multimodal Modeling, LLMs Propose Research Ideas\n",
      "\n",
      "Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs\n",
      "\n",
      "AI Agents Spend Real Money, Breaking Jailbreaks, Mistral Goes Big and Multimodal, AI’s Growing E-Waste Problem\n",
      "\n",
      "DeepSeek Takes On OpenAI, Robots Fold Laundry, Amazon and Anthropic Expand Partnership, More Efficient Object Detection\n",
      "\n",
      "Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, Transformer Training Streamlined\n",
      "\n",
      "Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot\n",
      "\n",
      "AI Controls Desktops, Agents Train Algorithms, Does Anyone Comply With the EU’s AI Act?, Robots on the Loading Dock\n",
      "\n",
      "Trick or treat! AI Devours Energy, Innovation Can’t Win, Models Collapse, Benchmark Tests Are Meaningless, No Work for Coders\n",
      "\n",
      "AI Giants Go Nuclear, A Tech Bromance Turns Turbulent, Mistral Sharpens the Edge, Cheaper Video Generation\n",
      "\n",
      "Bogus Apps, AI Boomtown, Better Embeddings, 2024 Highlights\n",
      "\n",
      "How Meta’s Movie Gen Does It, AI’s Criminal Underground, Court Says LAION is Legal, OpenAI’s New Voice API\n",
      "\n",
      "Llama Goes Multimodal, Pros Embrace Generative Video, Military AI Guidelines, LLMs That Read Spreadsheets\n",
      "\n",
      "Hollywood Embraces Video Gen, New Restrictions on Deepfakes, More Open Source Models, Robot Server\n",
      "\n",
      "Models Built for Reasoning, High Gear for Llama 3.1, Brains for Warehouse Robots, Stopping LLMs From Plagiarizing\n",
      "\n",
      "Nations Sign Binding AI Treaty, Waymo Reveals Safety Record, 2D to 3D Goes Mainstream, Balancing Web Data Distributions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_article_titles(base_url_html):\n",
    "    soup = BeautifulSoup(base_url_html, \"html.parser\")\n",
    "    articles_titles = []\n",
    "    article_cards = soup.select(\"div.p-6\")\n",
    "    for card in article_cards:\n",
    "        h2_tag = card.find(\"h2\")\n",
    "        if not h2_tag:\n",
    "            continue\n",
    "        # print(card)\n",
    "        link_tag = card.find(\"a\", href=True)\n",
    "        print(link_tag)\n",
    "        if not link_tag:\n",
    "            print(\"Article out of scope\")\n",
    "            continue\n",
    "\n",
    "        title = h2_tag.get_text(strip=True)\n",
    "        articles_titles.append(title)\n",
    "    return articles_titles\n",
    "\n",
    "titles = get_article_titles(base_url_html)\n",
    "print(f\"Total titles: {len(titles)}\")\n",
    "for title in titles:\n",
    "    print(f\"{title}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (128902662.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[219], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    Article Titles in Grid View:\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#     slug = re.sub(r'https?://[^/]+/', '', link)  # remove scheme and domain\n",
    "#     slug = slug.strip(\"/\").replace(\"/\", \"_\")     # turn '/the-batch/issue-281/' -> 'the-batch_issue-281'\n",
    "#     file_name = f\"article_{i}_{slug}.txt\"\n",
    "    \n",
    "#     file_path = os.path.join(\"articles\", file_name)\n",
    "    \n",
    "#     with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(article_text)\n",
    "    \n",
    "#     print(f\"Saved: {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Div class name for Article Titles in Grid View:\n",
    "# text-xl lg:text-2xl font-semibold tracking-tight leading-tight text-slate-800 font-primary mb-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid article link (It is probably a featured article)...continuing\n"
     ]
    }
   ],
   "source": [
    "def get_articles_links(base_url_html):\n",
    "    base_url = \"https://www.deeplearning.ai\"\n",
    "    soup = BeautifulSoup(base_url_html, \"html.parser\")\n",
    "    article_links = []\n",
    "    article_cards = soup.select(\"div.p-6\")\n",
    "    for card in article_cards:\n",
    "        a_tag = card.find_all(\"a\", href=True)\n",
    "        if len(a_tag) < 2:\n",
    "            print(\"Invalid article link (It is probably a featured article)...continuing\")\n",
    "            continue\n",
    "        article_links.append(base_url + a_tag[1][\"href\"])\n",
    "    return article_links\n",
    "       \n",
    "\n",
    "articles = get_articles_links(base_url_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.deeplearning.ai/the-batch/issue-281/\n"
     ]
    }
   ],
   "source": [
    "def get_featured_article_link(base_url_html):\n",
    "    base_url = \"https://www.deeplearning.ai\"\n",
    "    soup = BeautifulSoup(base_url_html, \"html.parser\")\n",
    "    featured_article_div = soup.find(\"div\", class_ = \"col-span-1 lg:col-span-2\")\n",
    "    link = featured_article_div.find_all(\"a\", href=True)\n",
    "    if len(link) < 2:\n",
    "        print(\"There was a problem fetching featured article's link\")\n",
    "        return \"\"\n",
    "    return base_url + link[1]['href']\n",
    "    \n",
    "\n",
    "\n",
    "featured_article_link = get_featured_article_link(base_url_html)\n",
    "print(featured_article_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.deeplearning.ai/the-batch/issue-280/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-279/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-278/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-277/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-276/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-275/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-274/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-273/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-272/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-271/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-270/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-269/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-268/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-267/',\n",
       " 'https://www.deeplearning.ai/the-batch/issue-266/']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUFF\n",
    "\n",
    "# get_featured_article_link return the link of the featured article only\n",
    "# get_article_links returns the links of all articles on the main page except for the featured article.\n",
    "# get_formatted_article_text saves the text of all articles (including the featured article) in the separate .txt files.\n",
    "\n",
    "# Next STUFF\n",
    "# Check wether get_article_titles are extracting all the titles and are in the order of the links extracted. Order is important for creating the metadatas later.\n",
    "# Refactoring\n",
    "# Create metadatas properly.\n",
    "# Chunk all articles properly\n",
    "# Store all articles in proper format in vector DB\n",
    "# RAG chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

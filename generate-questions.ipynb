{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the saved articles directory to get the article's text\n",
    "import re, os\n",
    "\n",
    "link = \"https://www.deeplearning.ai/the-batch/issue-272/\"\n",
    "slug = re.sub(r'https?://[^/]+/', '', link)  # remove scheme and domain\n",
    "slug = slug.strip(\"/\").replace(\"/\", \"_\")     # turn '/the-batch/issue-281/' -> 'the-batch_issue-281'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "list_of_files = os.listdir(\"saved_articles\")\n",
    "print(len(list_of_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found, retrieving its text!\n"
     ]
    }
   ],
   "source": [
    "def retrieve_article_text(article_link, directory = \"saved_articles\"):\n",
    "    slug = re.sub(r'https?://[^/]+/', '', article_link)  # remove scheme and domain\n",
    "    slug = slug.strip(\"/\").replace(\"/\", \"_\")     # turn '/the-batch/issue-281/' -> 'the-batch_issue-281'\n",
    "    for file in os.listdir(directory):\n",
    "            if file.endswith(f\"{slug}.txt\"):\n",
    "                print(\"File found, retrieving its text!\")\n",
    "                file_path = os.path.join(directory, file)\n",
    "                with open(file_path, 'r') as article_file:\n",
    "                     article_text = article_file.read()\n",
    "                     return article_text\n",
    "                \n",
    "    print(\"File cannot be found!\")\n",
    "    return \"\"\n",
    "\n",
    "article_text = retrieve_article_text(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "I will provide an article text. Please analyze it in the following way:\n",
    "\n",
    "1. First identify and list the key topics and main points of the article.\n",
    "\n",
    "2. Then generate 5-8 questions that:\n",
    "   - Cover different aspects of understanding (factual, conceptual, analytical)\n",
    "   - Are arranged from simpler to more complex understanding\n",
    "   - Include a mix of:\n",
    "     * Factual questions about specific information\n",
    "     * Conceptual questions about main ideas\n",
    "     * Questions that connect different parts of the article\n",
    "     * Questions that relate the content to broader implications\n",
    "\n",
    "3. For each question:\n",
    "   - Provide the correct answer\n",
    "   - Indicate what type of understanding it tests\n",
    "   - Include the relevant section of text that contains the answer\n",
    "\n",
    "Format your response like this:\n",
    "\n",
    "KEY TOPICS:\n",
    "- Topic 1\n",
    "- Topic 2\n",
    "[etc.]\n",
    "\n",
    "QUESTIONS:\n",
    "\n",
    "1. [Question Type: Factual]\n",
    "Q: [Question text]\n",
    "A: [Answer]\n",
    "Reference: \"[relevant text from article]\"\n",
    "\n",
    "2. [Question Type: Conceptual]\n",
    "[etc.]\n",
    "\n",
    "Please ensure the questions are clear, unambiguous, and directly answerable from the article content.\n",
    "\n",
    "Article text:\n",
    "\n",
    "{article_text}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', max_tokens = 1024)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "response = chain.invoke({\"article_text\": article_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**KEY TOPICS:**\n",
      "- Speed of execution in startups and large companies\n",
      "- Generative AI and its impact on prototyping\n",
      "- Importance of user feedback in product development\n",
      "- AI companies' investments in nuclear energy\n",
      "- The changing dynamics of the Microsoft-OpenAI partnership\n",
      "- Mistral AI's launch of new language models\n",
      "- Advances in video generation technology\n",
      "\n",
      "---\n",
      "\n",
      "**QUESTIONS:**\n",
      "\n",
      "1. **[Question Type: Factual]**\n",
      "   Q: What is the primary advantage of using generative AI in startups according to the article?\n",
      "   A: The primary advantage is the ability to quickly prototype AI capabilities, which can be built in days or hours instead of months.\n",
      "   Reference: \"Generative AI makes it possible to quickly prototype AI capabilities. AI capabilities that used to take months can sometimes be built in days or hours by simply prompting a large language model.\"\n",
      "\n",
      "2. **[Question Type: Conceptual]**\n",
      "   Q: How does the article suggest that the speed of prototyping with AI affects the product development cycle?\n",
      "   A: The speed of prototyping creates pressure to speed up other steps in the product development cycle, such as getting user feedback.\n",
      "   Reference: \"But the speed with which we can prototype AI creates significant pressure to speed up these other steps, too.\"\n",
      "\n",
      "3. **[Question Type: Analytical]**\n",
      "   Q: What is the significance of the “move fast and be responsible” mantra compared to the previous “move fast and break things” approach?\n",
      "   A: The new mantra emphasizes rapid execution while ensuring responsibility and safety, highlighting the ability to prototype and test quickly without causing harm.\n",
      "   Reference: \"A better mantra is 'move fast and be responsible.' There are many ways to prototype and test quickly without shipping a product that can cause significant harm.\"\n",
      "\n",
      "4. **[Question Type: Factual]**\n",
      "   Q: Which major AI companies are investing in nuclear power projects as mentioned in the article?\n",
      "   A: Amazon, Google, and Microsoft are investing in nuclear power projects.\n",
      "   Reference: \"Amazon, Google, and Microsoft announced substantial investments in nuclear power projects.\"\n",
      "\n",
      "5. **[Question Type: Conceptual]**\n",
      "   Q: Why is the partnership between Microsoft and OpenAI described as being under strain?\n",
      "   A: The partnership is strained due to demands for resources, friction between leaders, and each company's desire for greater independence.\n",
      "   Reference: \"Their collaboration... is now complicated by demands for resources, friction between leaders, and partnerships with other companies.\"\n",
      "\n",
      "6. **[Question Type: Analytical]**\n",
      "   Q: How do the new models launched by Mistral AI contribute to the landscape of AI language models?\n",
      "   A: Mistral AI's models outperform similar-sized models from competitors on various performance measures, making advanced AI capabilities accessible on smaller devices.\n",
      "   Reference: \"Ministral 3B and Ministral 8B... outperform Google’s and Meta’s similar-sized models on several measures of knowledge retrieval, common-sense reasoning, and multilingual understanding.\"\n",
      "\n",
      "7. **[Question Type: Conceptual]**\n",
      "   Q: What broader implications does the article suggest about the relationship between AI energy consumption and nuclear power investments?\n",
      "   A: The article implies that as AI demand surges, tech companies see nuclear power as a reliable, carbon-free energy source to meet their growing energy needs.\n",
      "   Reference: \"The tech industry’s growing interest in nuclear power is driven by surging demand for AI and corporate commitments to reduce carbon emissions.\"\n",
      "\n",
      "8. **[Question Type: Analytical]**\n",
      "   Q: In what ways does the article suggest that advancements in video generation technology could impact industries outside of tech?\n",
      "   A: The article indicates that Hollywood may consider using video generation technology in pre- and post-production, demonstrating its potential implications for the film industry.\n",
      "   Reference: \"Hollywood is interested in video generation. Studios reportedly are considering using the technology in pre- and post-production.\"\n"
     ]
    }
   ],
   "source": [
    "print(response.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM With Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "    question_type: str = Field(description=\"The type of question (Factual, Conceptual, Analytical).\")\n",
    "    question: str = Field(description=\"The question generated.\")\n",
    "    answer: str = Field(description=\"The answer of the question.\")\n",
    "    reference: str = Field(description=\"The reference text in the article from where the answer is generated.\")\n",
    "    \n",
    "\n",
    "class QuestionAnswers(BaseModel):\n",
    "    questions: List[Question] = Field(description=\"Set of questions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(QuestionAnswers)\n",
    "prompt = prompt_template.format(article_text = article_text)\n",
    "res = structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "\n",
    "for index, question in enumerate(res.questions):\n",
    "    quest = {}\n",
    "    quest[\"question_type\"] = question.question_type\n",
    "    quest[\"question\"] = question.question\n",
    "    quest[\"answer\"] = question.answer\n",
    "    quest[\"reference\"] = question.reference\n",
    "    questions.append(quest)\n",
    "    # print(f\"Question #0{index + 1}\")\n",
    "    # print(f\"Type: {question.question_type}\")\n",
    "    # print(f\"Q: {question.question}\")\n",
    "    # print(f\"Ans: {question.answer}\")\n",
    "    # print(f\"Ref: {question.reference}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question_type': 'Factual',\n",
       "  'question': 'What is the core part of the iterative workflow in designing and building a product according to the article?',\n",
       "  'answer': 'To build a prototype (or MVP, minimum viable product), get user feedback on it, and use that feedback to drive improvements.',\n",
       "  'reference': '\"A core part of the iterative workflow of designing and building a product ... is to build a prototype (or MVP, minimum viable product), get user feedback on it, and to use that feedback to drive improvements.\"'},\n",
       " {'question_type': 'Conceptual',\n",
       "  'question': 'Why is the speed of prototyping AI capabilities significant for startups and large companies?',\n",
       "  'answer': 'The speed of prototyping AI capabilities creates significant pressure to speed up other steps in product development, such as getting user feedback.',\n",
       "  'reference': '\"the speed with which we can prototype AI creates significant pressure to speed up these other steps, too.\"'},\n",
       " {'question_type': 'Factual',\n",
       "  'question': 'Which companies are investing in nuclear power projects according to the article?',\n",
       "  'answer': 'Amazon, Google, and Microsoft are investing in nuclear power projects.',\n",
       "  'reference': '\"Amazon, Google, and Microsoft announced substantial investments in nuclear power projects.\"'},\n",
       " {'question_type': 'Analytical',\n",
       "  'question': 'What are the implications of major tech companies investing in nuclear energy for AI infrastructure?',\n",
       "  'answer': 'Investing in nuclear energy provides a reliable, carbon-free source of power necessary to meet the surging demand for electricity in AI data centers.',\n",
       "  'reference': '\"Data centers that train and run AI models consume vast amounts of electricity, and nuclear energy offers a reliable, carbon-free source.\"'},\n",
       " {'question_type': 'Factual',\n",
       "  'question': 'What is the expected operation start year for the small modular reactors developed by Kairos Power in partnership with Google?',\n",
       "  'answer': 'The new plants are expected to begin operation in 2030.',\n",
       "  'reference': '\"Kairos expects the new plants to begin operation in 2030.\"'},\n",
       " {'question_type': 'Conceptual',\n",
       "  'question': 'How does Mistral AI aim to differentiate itself from U.S. tech giants in the AI market?',\n",
       "  'answer': 'Mistral AI launched models that are small enough to run on many edge devices, emphasizing accessibility and adaptability in AI technology.',\n",
       "  'reference': '\"Mistral AI launched two models that raise the bar for language models with 8 billion or fewer parameters, small enough to run on many edge devices.\"'},\n",
       " {'question_type': 'Analytical',\n",
       "  'question': 'What challenges does the partnership between Microsoft and OpenAI face, and what are the potential consequences?',\n",
       "  'answer': 'The partnership faces challenges due to demands for resources, friction between leaders, and the desire for greater independence, which could impact AI research and product development.',\n",
       "  'reference': '\"Their collaboration, which brought both companies great rewards, is now complicated by demands for resources, friction between leaders, and partnerships with other companies.\"'},\n",
       " {'question_type': 'Factual',\n",
       "  'question': 'What new method did researchers at Peking University propose to cut the cost of training video generators?',\n",
       "  'answer': 'They proposed a method called Pyramidal Flow Matching.',\n",
       "  'reference': '\"Yang Jin and colleagues ... proposed Pyramidal Flow Matching, a method that reduced the amount of processing required to train video generators.\"'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
